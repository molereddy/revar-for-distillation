Main Function with logger : Logger(dir=kd_results, use-tf=False, writer=None)
Arguments : -------------------------------
batch_size       : 800
class_num        : 100
cutout_length    : 16
data_path        : /home/prathamesh/code/data/cifar/
dataset          : cifar100
epochs           : 200
eval_batch_size  : 800
file_name        : KD_seed-1_cycles-4_KDfrac-0.5_T-2
global_rand_seed : -1
loss_kd_frac     : 0.5
lr               : 0.1
model_name       : ResNet10_s
momentum         : 0.9
pretrained_student : True
print_freq       : 100
print_freq_eval  : 100
rand_seed        : 1
save_dir         : ./kd_results/
sched_cycles     : 4
teacher          : ResNet10_l
temperature      : 2
wd               : 0.0005
workers          : 8
Python  Version  : 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0]
Pillow  Version  : 9.2.0
PyTorch Version  : 1.13.1
cuDNN   Version  : 8500
CUDA available   : True
CUDA GPU numbers : 1
CUDA_VISIBLE_DEVICES : 0
Namespace(batch_size=800, class_num=100, cutout_length=16, data_path='/home/prathamesh/code/data/cifar/', dataset='cifar100', epochs=200, eval_batch_size=800, file_name='KD_seed-1_cycles-4_KDfrac-0.5_T-2', global_rand_seed=-1, loss_kd_frac=0.5, lr=0.1, model_name='ResNet10_s', momentum=0.9, pretrained_student=True, print_freq=100, print_freq_eval=100, rand_seed=1, save_dir='./kd_results/', sched_cycles=4, teacher='ResNet10_l', temperature=2, wd=0.0005, workers=8)
Train:45000	, Valid:5000	, Test:10000

Student: ResNet10_s
using pretrained student model from /home/anmolreddy/ce_results/CE_with_seed-1_cycles-1_cifar100-ResNet10_smodel_best.pth.tar
***[2023-05-03 06:09:52]*** before training [Student(CE)] Test loss = 1.856782, accuracy@1 = 49.95, accuracy@5 = 79.46, error@1 = 50.05, error@5 = 20.54
Scheduling LR update to student 4 time at 50-epoch intervals
***[2023-05-03 06:09:53]*** [Teacher] Test loss = 1.045211, accuracy@1 = 70.71, accuracy@5 = 92.22, error@1 = 29.29, error@5 = 7.78
model information : EfficientNetV2_s (CIFAR)
--------------------------------------------------
[Student]Params=0.08 MB, FLOPs=4.16 M ... = 0.00 G
--------------------------------------------------

Started EPOCH:0
[TRAIN] E: [0][ 0/57]	Loss 2.3509e+00 (2.3509e+00)	Acc@1  39.38 ( 39.38)	Acc@5  67.25 ( 67.25)
[TRAIN] E: [0][56/57]	Loss 2.2600e+00 (2.3448e+00)	Acc@1  36.00 ( 36.62)	Acc@5  65.00 ( 66.75)
[EVAL] E: [0][0/7]	Loss 2.5827e+00 (2.5827e+00)	Acc@1  35.00 ( 35.00)	Acc@5  65.75 ( 65.75)
[EVAL] E: [0][6/7]	Loss 2.5206e+00 (2.5307e+00)	Acc@1  34.00 ( 36.84)	Acc@5  65.00 ( 66.16)
		 Valid evaluation at end of epoch: loss:2.5307	latest_acc:36.84	LR:0.00 -- best val acc so far 36.84

Started EPOCH:1
[TRAIN] E: [1][ 0/57]	Loss 2.2657e+00 (2.2657e+00)	Acc@1  39.12 ( 39.12)	Acc@5  68.50 ( 68.50)
[TRAIN] E: [1][56/57]	Loss 2.3747e+00 (2.3809e+00)	Acc@1  36.00 ( 35.77)	Acc@5  63.50 ( 65.99)
[EVAL] E: [1][0/7]	Loss 3.1910e+00 (3.1910e+00)	Acc@1  26.12 ( 26.12)	Acc@5  51.62 ( 51.62)
[EVAL] E: [1][6/7]	Loss 3.2982e+00 (3.1950e+00)	Acc@1  20.00 ( 24.50)	Acc@5  48.00 ( 51.68)
		 Valid evaluation at end of epoch: loss:3.1950	latest_acc:24.50	LR:0.08 -- best val acc so far 36.84

Started EPOCH:2
[TRAIN] E: [2][ 0/57]	Loss 2.3952e+00 (2.3952e+00)	Acc@1  34.62 ( 34.62)	Acc@5  65.50 ( 65.50)
[TRAIN] E: [2][56/57]	Loss 2.3110e+00 (2.3244e+00)	Acc@1  31.00 ( 36.17)	Acc@5  67.50 ( 66.37)
[EVAL] E: [2][0/7]	Loss 2.5804e+00 (2.5804e+00)	Acc@1  37.00 ( 37.00)	Acc@5  65.00 ( 65.00)
[EVAL] E: [2][6/7]	Loss 2.5098e+00 (2.6012e+00)	Acc@1  39.00 ( 35.10)	Acc@5  66.00 ( 64.44)
		 Valid evaluation at end of epoch: loss:2.6012	latest_acc:35.10	LR:0.04 -- best val acc so far 36.84

Started EPOCH:3
[TRAIN] E: [3][ 0/57]	Loss 2.3133e+00 (2.3133e+00)	Acc@1  39.38 ( 39.38)	Acc@5  69.88 ( 69.88)
[TRAIN] E: [3][56/57]	Loss 2.3277e+00 (2.4026e+00)	Acc@1  36.50 ( 34.84)	Acc@5  60.50 ( 65.13)
[EVAL] E: [3][0/7]	Loss 2.6973e+00 (2.6973e+00)	Acc@1  34.12 ( 34.12)	Acc@5  64.62 ( 64.62)
[EVAL] E: [3][6/7]	Loss 2.7384e+00 (2.7647e+00)	Acc@1  28.50 ( 31.74)	Acc@5  60.00 ( 61.86)
		 Valid evaluation at end of epoch: loss:2.7647	latest_acc:31.74	LR:0.04 -- best val acc so far 36.84

Started EPOCH:4
[TRAIN] E: [4][ 0/57]	Loss 2.2885e+00 (2.2885e+00)	Acc@1  34.00 ( 34.00)	Acc@5  66.25 ( 66.25)
[TRAIN] E: [4][56/57]	Loss 2.1278e+00 (2.2678e+00)	Acc@1  38.00 ( 36.78)	Acc@5  67.50 ( 67.06)
[EVAL] E: [4][0/7]	Loss 2.9081e+00 (2.9081e+00)	Acc@1  30.50 ( 30.50)	Acc@5  58.00 ( 58.00)
[EVAL] E: [4][6/7]	Loss 2.7782e+00 (2.8744e+00)	Acc@1  29.50 ( 30.80)	Acc@5  64.00 ( 59.90)
		 Valid evaluation at end of epoch: loss:2.8744	latest_acc:30.80	LR:0.08 -- best val acc so far 36.84

Started EPOCH:5
[TRAIN] E: [5][ 0/57]	Loss 2.4085e+00 (2.4085e+00)	Acc@1  34.25 ( 34.25)	Acc@5  64.62 ( 64.62)
[TRAIN] E: [5][56/57]	Loss 2.4262e+00 (2.3842e+00)	Acc@1  35.00 ( 35.17)	Acc@5  65.00 ( 65.08)
[EVAL] E: [5][0/7]	Loss 2.5328e+00 (2.5328e+00)	Acc@1  35.62 ( 35.62)	Acc@5  65.38 ( 65.38)
[EVAL] E: [5][6/7]	Loss 2.4694e+00 (2.5617e+00)	Acc@1  35.50 ( 35.26)	Acc@5  64.00 ( 65.10)
		 Valid evaluation at end of epoch: loss:2.5617	latest_acc:35.26	LR:0.01 -- best val acc so far 36.84

Started EPOCH:6
[TRAIN] E: [6][ 0/57]	Loss 2.2495e+00 (2.2495e+00)	Acc@1  36.00 ( 36.00)	Acc@5  65.75 ( 65.75)
[TRAIN] E: [6][56/57]	Loss 2.3345e+00 (2.2691e+00)	Acc@1  37.50 ( 37.22)	Acc@5  67.50 ( 67.10)
[EVAL] E: [6][0/7]	Loss 3.1368e+00 (3.1368e+00)	Acc@1  25.25 ( 25.25)	Acc@5  52.75 ( 52.75)
[EVAL] E: [6][6/7]	Loss 2.9861e+00 (3.1495e+00)	Acc@1  28.50 ( 26.80)	Acc@5  56.50 ( 54.22)
		 Valid evaluation at end of epoch: loss:3.1495	latest_acc:26.80	LR:0.10 -- best val acc so far 36.84

Started EPOCH:7
[TRAIN] E: [7][ 0/57]	Loss 2.4918e+00 (2.4918e+00)	Acc@1  33.88 ( 33.88)	Acc@5  61.38 ( 61.38)
[TRAIN] E: [7][56/57]	Loss 2.3451e+00 (2.3603e+00)	Acc@1  34.00 ( 35.53)	Acc@5  63.00 ( 65.74)
[EVAL] E: [7][0/7]	Loss 2.5665e+00 (2.5665e+00)	Acc@1  35.50 ( 35.50)	Acc@5  66.75 ( 66.75)
[EVAL] E: [7][6/7]	Loss 2.5235e+00 (2.5158e+00)	Acc@1  35.50 ( 36.04)	Acc@5  64.00 ( 66.78)
		 Valid evaluation at end of epoch: loss:2.5158	latest_acc:36.04	LR:0.00 -- best val acc so far 36.84

Started EPOCH:8
[TRAIN] E: [8][ 0/57]	Loss 2.2275e+00 (2.2275e+00)	Acc@1  37.25 ( 37.25)	Acc@5  67.62 ( 67.62)
[TRAIN] E: [8][56/57]	Loss 2.2611e+00 (2.3261e+00)	Acc@1  42.00 ( 36.24)	Acc@5  66.00 ( 66.77)
[EVAL] E: [8][0/7]	Loss 3.5139e+00 (3.5139e+00)	Acc@1  21.62 ( 21.62)	Acc@5  51.62 ( 51.62)
[EVAL] E: [8][6/7]	Loss 3.4370e+00 (3.5063e+00)	Acc@1  25.00 ( 22.64)	Acc@5  54.50 ( 49.68)
		 Valid evaluation at end of epoch: loss:3.5063	latest_acc:22.64	LR:0.08 -- best val acc so far 36.84

Started EPOCH:9
[TRAIN] E: [9][ 0/57]	Loss 2.4953e+00 (2.4953e+00)	Acc@1  34.62 ( 34.62)	Acc@5  63.75 ( 63.75)
[TRAIN] E: [9][56/57]	Loss 2.1411e+00 (2.2868e+00)	Acc@1  40.00 ( 36.56)	Acc@5  74.00 ( 67.08)
[EVAL] E: [9][0/7]	Loss 2.6293e+00 (2.6293e+00)	Acc@1  36.12 ( 36.12)	Acc@5  64.12 ( 64.12)
[EVAL] E: [9][6/7]	Loss 2.5579e+00 (2.6249e+00)	Acc@1  34.00 ( 34.72)	Acc@5  66.00 ( 63.78)
		 Valid evaluation at end of epoch: loss:2.6249	latest_acc:34.72	LR:0.03 -- best val acc so far 36.84

Started EPOCH:10
[TRAIN] E: [10][ 0/57]	Loss 2.1261e+00 (2.1261e+00)	Acc@1  41.38 ( 41.38)	Acc@5  71.12 ( 71.12)
[TRAIN] E: [10][56/57]	Loss 2.2955e+00 (2.3456e+00)	Acc@1  40.50 ( 35.78)	Acc@5  66.00 ( 65.85)
[EVAL] E: [10][0/7]	Loss 2.8626e+00 (2.8626e+00)	Acc@1  29.88 ( 29.88)	Acc@5  59.00 ( 59.00)
[EVAL] E: [10][6/7]	Loss 2.6704e+00 (2.8190e+00)	Acc@1  33.00 ( 30.30)	Acc@5  62.00 ( 60.64)
		 Valid evaluation at end of epoch: loss:2.8190	latest_acc:30.30	LR:0.04 -- best val acc so far 36.84

Started EPOCH:11
[TRAIN] E: [11][ 0/57]	Loss 2.2750e+00 (2.2750e+00)	Acc@1  34.50 ( 34.50)	Acc@5  67.12 ( 67.12)
