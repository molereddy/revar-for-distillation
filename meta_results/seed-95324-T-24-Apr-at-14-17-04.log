Main Function with logger : Logger(dir=meta_results, use-tf=False, writer=None)
Arguments : -------------------------------
batch_size       : 200
checkpoint_dir   : ./checkpoint
class_num        : 100
cutout_length    : 16
data_path        : /home/prathamesh/code/data/cifar/
dataset          : cifar100
epochs           : 200
eval_batch_size  : 200
eval_frequency   : 1
global_rand_seed : -1
input_size       : 32
inst_based       : True
log_dir          : ./log
lr               : 0.1
mcd_weight       : 0.01
meta_interval    : 1
meta_lr          : 0.01
meta_weight_decay : 0.0
model_name       : ResNet10_s
momentum         : 0.9
print_freq       : 100
print_freq_eval  : 100
rand_seed        : 95324
save_dir         : ./meta_results/
unsup_adapt      : False
wd               : 0.0005
workers          : 8
Python  Version  : 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0]
Pillow  Version  : 9.2.0
PyTorch Version  : 1.13.1
cuDNN   Version  : 8500
CUDA available   : True
CUDA GPU numbers : 1
CUDA_VISIBLE_DEVICES : 0
model information : EfficientNetV2_s (CIFAR)
--------------------------------------------------
[Student]Params=0.08 MB, FLOPs=4.16 M ... = 0.00 G
--------------------------------------------------
train_data : Dataset CIFAR100
    Number of datapoints: 50000
    Root location: /home/prathamesh/code/data/cifar/
    Split: Train
    StandardTransform
Transform: Compose(
               RandomCrop(size=(32, 32), padding=4)
               RandomHorizontalFlip(p=0.5)
               AutoAugment CIFAR10 Policy
               ToTensor()
               CUTOUT(length=16)
               Normalize(mean=[0.5070588235294118, 0.48666666666666664, 0.4407843137254902], std=[0.26745098039215687, 0.2564705882352941, 0.27607843137254906])
           )
valid_data : Dataset CIFAR100
    Number of datapoints: 10000
    Root location: /home/prathamesh/code/data/cifar/
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.5070588235294118, 0.48666666666666664, 0.4407843137254902], std=[0.26745098039215687, 0.2564705882352941, 0.27607843137254906])
           )
[TRAIN] E: [0][  0/250]	Loss 1.6315e-06 (1.6315e-06)	Acc@1  47.00 ( 47.00)	Acc@5  76.50 ( 76.50)
[TRAIN] E: [0][100/250]	Loss -1.0230e-07 (7.6173e-08)	Acc@1  45.50 ( 42.84)	Acc@5  75.00 ( 73.17)
[TRAIN] E: [0][200/250]	Loss 1.5512e-07 (7.1550e-08)	Acc@1  40.50 ( 42.77)	Acc@5  72.50 ( 72.96)
[TRAIN] E: [0][249/250]	Loss 5.8860e-08 (7.1293e-08)	Acc@1  37.00 ( 42.70)	Acc@5  66.50 ( 72.81)
[EVAL] E: [0][ 0/50]	Loss 1.6649e+00 (1.6649e+00)	Acc@1  60.00 ( 60.00)	Acc@5  80.50 ( 80.50)
[EVAL] E: [0][49/50]	Loss 1.6629e+00 (1.6947e+00)	Acc@1  55.00 ( 53.64)	Acc@5  83.50 ( 82.89)
		 LR=0.09990212389432412 -- best acc so far 53.64
***[2023-04-24 14:19:19]*** [Post-train] [Student] EVALUATION loss = 1.694716, accuracy@1 = 53.64, accuracy@5 = 82.89, error@1 = 46.36, error@5 = 17.11
[TRAIN] E: [1][  0/250]	Loss -4.8056e-08 (-4.8056e-08)	Acc@1  48.50 ( 48.50)	Acc@5  79.00 ( 79.00)
[TRAIN] E: [1][100/250]	Loss 2.1532e-08 (6.3242e-08)	Acc@1  40.50 ( 42.88)	Acc@5  70.00 ( 72.36)
[TRAIN] E: [1][200/250]	Loss 1.7025e-07 (7.1512e-08)	Acc@1  45.50 ( 42.94)	Acc@5  71.50 ( 72.63)
[TRAIN] E: [1][249/250]	Loss 1.1213e-07 (7.6274e-08)	Acc@1  41.50 ( 42.72)	Acc@5  66.50 ( 72.43)
[EVAL] E: [1][ 0/50]	Loss 1.7733e+00 (1.7733e+00)	Acc@1  60.00 ( 60.00)	Acc@5  80.50 ( 80.50)
[EVAL] E: [1][49/50]	Loss 1.7973e+00 (1.8254e+00)	Acc@1  56.00 ( 53.58)	Acc@5  84.50 ( 82.70)
		 LR=0.09960730848288585 -- best acc so far 53.64
***[2023-04-24 14:21:18]*** [Post-train] [Student] EVALUATION loss = 1.825375, accuracy@1 = 53.58, accuracy@5 = 82.70, error@1 = 46.42, error@5 = 17.30
[TRAIN] E: [2][  0/250]	Loss 9.5665e-08 (9.5665e-08)	Acc@1  50.50 ( 50.50)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [2][100/250]	Loss 2.0862e-09 (1.1386e-07)	Acc@1  41.50 ( 42.24)	Acc@5  74.00 ( 72.41)
[TRAIN] E: [2][200/250]	Loss 1.8626e-07 (1.1574e-07)	Acc@1  39.00 ( 42.93)	Acc@5  69.50 ( 72.79)
[TRAIN] E: [2][249/250]	Loss 2.0906e-07 (1.1424e-07)	Acc@1  44.00 ( 42.80)	Acc@5  70.00 ( 72.58)
[EVAL] E: [2][ 0/50]	Loss 1.9782e+00 (1.9782e+00)	Acc@1  59.50 ( 59.50)	Acc@5  79.50 ( 79.50)
[EVAL] E: [2][49/50]	Loss 2.0270e+00 (2.0416e+00)	Acc@1  55.50 ( 53.51)	Acc@5  84.00 ( 82.65)
		 LR=0.0991167156882891 -- best acc so far 53.64
***[2023-04-24 14:23:12]*** [Post-train] [Student] EVALUATION loss = 2.041645, accuracy@1 = 53.51, accuracy@5 = 82.65, error@1 = 46.49, error@5 = 17.35
[TRAIN] E: [3][  0/250]	Loss -3.1441e-08 (-3.1441e-08)	Acc@1  37.50 ( 37.50)	Acc@5  74.50 ( 74.50)
[TRAIN] E: [3][100/250]	Loss -1.2144e-07 (1.0830e-07)	Acc@1  40.50 ( 42.93)	Acc@5  70.00 ( 72.43)
[TRAIN] E: [3][200/250]	Loss -1.8179e-08 (1.1416e-07)	Acc@1  42.50 ( 42.68)	Acc@5  75.50 ( 72.41)
[TRAIN] E: [3][249/250]	Loss 5.0664e-08 (1.1834e-07)	Acc@1  45.00 ( 42.74)	Acc@5  69.00 ( 72.51)
[EVAL] E: [3][ 0/50]	Loss 2.2560e+00 (2.2560e+00)	Acc@1  59.50 ( 59.50)	Acc@5  80.00 ( 80.00)
[EVAL] E: [3][49/50]	Loss 2.3112e+00 (2.3233e+00)	Acc@1  56.00 ( 53.57)	Acc@5  84.00 ( 82.80)
		 LR=0.0984322816561636 -- best acc so far 53.64
***[2023-04-24 14:25:07]*** [Post-train] [Student] EVALUATION loss = 2.323255, accuracy@1 = 53.57, accuracy@5 = 82.80, error@1 = 46.43, error@5 = 17.20
[TRAIN] E: [4][  0/250]	Loss 1.6585e-07 (1.6585e-07)	Acc@1  44.50 ( 44.50)	Acc@5  74.50 ( 74.50)
[TRAIN] E: [4][100/250]	Loss 1.7107e-07 (1.1271e-07)	Acc@1  44.00 ( 43.34)	Acc@5  72.00 ( 73.18)
[TRAIN] E: [4][200/250]	Loss 4.9174e-08 (1.1586e-07)	Acc@1  41.50 ( 42.92)	Acc@5  68.50 ( 72.90)
[TRAIN] E: [4][249/250]	Loss 3.4004e-07 (1.2260e-07)	Acc@1  51.00 ( 42.75)	Acc@5  81.50 ( 72.76)
[EVAL] E: [4][ 0/50]	Loss 2.5752e+00 (2.5752e+00)	Acc@1  59.50 ( 59.50)	Acc@5  80.00 ( 80.00)
[EVAL] E: [4][49/50]	Loss 2.6327e+00 (2.6415e+00)	Acc@1  55.00 ( 53.61)	Acc@5  84.50 ( 82.74)
		 LR=0.09755670753494601 -- best acc so far 53.64
***[2023-04-24 14:26:58]*** [Post-train] [Student] EVALUATION loss = 2.641521, accuracy@1 = 53.61, accuracy@5 = 82.74, error@1 = 46.39, error@5 = 17.26
[TRAIN] E: [5][  0/250]	Loss 3.3230e-08 (3.3230e-08)	Acc@1  48.50 ( 48.50)	Acc@5  74.50 ( 74.50)
[TRAIN] E: [5][100/250]	Loss 2.0906e-07 (1.5650e-07)	Acc@1  49.00 ( 43.14)	Acc@5  79.00 ( 72.58)
[TRAIN] E: [5][200/250]	Loss 3.7014e-07 (1.4231e-07)	Acc@1  36.00 ( 42.54)	Acc@5  68.00 ( 72.09)
[TRAIN] E: [5][249/250]	Loss 1.0371e-07 (1.5054e-07)	Acc@1  42.00 ( 42.72)	Acc@5  75.00 ( 72.23)
[EVAL] E: [5][ 0/50]	Loss 2.8867e+00 (2.8867e+00)	Acc@1  58.50 ( 58.50)	Acc@5  80.00 ( 80.00)
[EVAL] E: [5][49/50]	Loss 2.9414e+00 (2.9485e+00)	Acc@1  56.00 ( 53.75)	Acc@5  83.50 ( 82.84)
		 LR=0.09649344881568099 -- best acc so far 53.75
***[2023-04-24 14:28:52]*** [Post-train] [Student] EVALUATION loss = 2.948520, accuracy@1 = 53.75, accuracy@5 = 82.84, error@1 = 46.25, error@5 = 17.16
[TRAIN] E: [6][  0/250]	Loss 2.5362e-07 (2.5362e-07)	Acc@1  42.00 ( 42.00)	Acc@5  75.00 ( 75.00)
[TRAIN] E: [6][100/250]	Loss 6.3330e-08 (1.4587e-07)	Acc@1  45.00 ( 42.09)	Acc@5  68.50 ( 72.44)
[TRAIN] E: [6][200/250]	Loss 4.3005e-07 (1.4546e-07)	Acc@1  44.00 ( 42.61)	Acc@5  75.50 ( 72.61)
[TRAIN] E: [6][249/250]	Loss 6.2883e-08 (1.3760e-07)	Acc@1  46.00 ( 42.72)	Acc@5  72.00 ( 72.70)
[EVAL] E: [6][ 0/50]	Loss 3.1831e+00 (3.1831e+00)	Acc@1  59.50 ( 59.50)	Acc@5  80.00 ( 80.00)
[EVAL] E: [6][49/50]	Loss 3.2293e+00 (3.2362e+00)	Acc@1  54.50 ( 53.52)	Acc@5  83.50 ( 82.73)
		 LR=0.09524670169477678 -- best acc so far 53.75
***[2023-04-24 14:30:48]*** [Post-train] [Student] EVALUATION loss = 3.236199, accuracy@1 = 53.52, accuracy@5 = 82.73, error@1 = 46.48, error@5 = 17.27
[TRAIN] E: [7][  0/250]	Loss 1.1206e-07 (1.1206e-07)	Acc@1  44.00 ( 44.00)	Acc@5  78.00 ( 78.00)
[TRAIN] E: [7][100/250]	Loss 3.8385e-07 (1.2695e-07)	Acc@1  39.50 ( 42.91)	Acc@5  68.50 ( 72.97)
[TRAIN] E: [7][200/250]	Loss 1.7196e-07 (1.3726e-07)	Acc@1  40.50 ( 42.85)	Acc@5  69.50 ( 72.67)
[TRAIN] E: [7][249/250]	Loss 1.7405e-07 (1.3813e-07)	Acc@1  47.50 ( 42.80)	Acc@5  72.50 ( 72.65)
[EVAL] E: [7][ 0/50]	Loss 3.4445e+00 (3.4445e+00)	Acc@1  59.00 ( 59.00)	Acc@5  80.00 ( 80.00)
[EVAL] E: [7][49/50]	Loss 3.4813e+00 (3.4877e+00)	Acc@1  55.00 ( 53.42)	Acc@5  83.00 ( 82.77)
		 LR=0.093821386513535 -- best acc so far 53.75
***[2023-04-24 14:32:42]*** [Post-train] [Student] EVALUATION loss = 3.487737, accuracy@1 = 53.42, accuracy@5 = 82.77, error@1 = 46.58, error@5 = 17.23
[TRAIN] E: [8][  0/250]	Loss 7.6592e-08 (7.6592e-08)	Acc@1  34.50 ( 34.50)	Acc@5  69.00 ( 69.00)
[TRAIN] E: [8][100/250]	Loss 1.9670e-07 (1.3250e-07)	Acc@1  45.00 ( 42.46)	Acc@5  73.00 ( 72.11)
[TRAIN] E: [8][200/250]	Loss 3.2187e-07 (1.3512e-07)	Acc@1  43.00 ( 42.57)	Acc@5  72.00 ( 72.27)
[TRAIN] E: [8][249/250]	Loss 3.9220e-07 (1.3775e-07)	Acc@1  45.50 ( 42.65)	Acc@5  71.00 ( 72.46)
[EVAL] E: [8][ 0/50]	Loss 3.6637e+00 (3.6637e+00)	Acc@1  59.00 ( 59.00)	Acc@5  80.00 ( 80.00)
[EVAL] E: [8][49/50]	Loss 3.6941e+00 (3.6994e+00)	Acc@1  55.50 ( 53.50)	Acc@5  83.00 ( 82.71)
		 LR=0.09222312833981147 -- best acc so far 53.75
***[2023-04-24 14:34:50]*** [Post-train] [Student] EVALUATION loss = 3.699372, accuracy@1 = 53.50, accuracy@5 = 82.71, error@1 = 46.50, error@5 = 17.29
[TRAIN] E: [9][  0/250]	Loss 2.3454e-07 (2.3454e-07)	Acc@1  41.50 ( 41.50)	Acc@5  72.00 ( 72.00)
[TRAIN] E: [9][100/250]	Loss 1.0937e-07 (1.3905e-07)	Acc@1  42.50 ( 42.34)	Acc@5  72.50 ( 72.80)
[TRAIN] E: [9][200/250]	Loss 1.6004e-07 (1.2169e-07)	Acc@1  37.00 ( 42.27)	Acc@5  67.50 ( 72.42)
[TRAIN] E: [9][249/250]	Loss 1.7643e-07 (1.1593e-07)	Acc@1  46.50 ( 42.45)	Acc@5  73.50 ( 72.42)
[EVAL] E: [9][ 0/50]	Loss 3.8464e+00 (3.8464e+00)	Acc@1  58.00 ( 58.00)	Acc@5  79.00 ( 79.00)
[EVAL] E: [9][49/50]	Loss 3.8713e+00 (3.8747e+00)	Acc@1  53.50 ( 53.16)	Acc@5  82.50 ( 82.54)
		 LR=0.09045823476844315 -- best acc so far 53.75
***[2023-04-24 14:37:41]*** [Post-train] [Student] EVALUATION loss = 3.874686, accuracy@1 = 53.16, accuracy@5 = 82.54, error@1 = 46.84, error@5 = 17.46
[TRAIN] E: [10][  0/250]	Loss 1.0014e-07 (1.0014e-07)	Acc@1  46.50 ( 46.50)	Acc@5  76.50 ( 76.50)
[TRAIN] E: [10][100/250]	Loss 1.7852e-07 (1.2642e-07)	Acc@1  40.50 ( 41.93)	Acc@5  69.00 ( 71.95)
[TRAIN] E: [10][200/250]	Loss -3.0100e-08 (1.1477e-07)	Acc@1  44.50 ( 42.34)	Acc@5  75.50 ( 72.24)
[TRAIN] E: [10][249/250]	Loss 3.6240e-07 (1.1917e-07)	Acc@1  42.50 ( 42.50)	Acc@5  73.00 ( 72.34)
[EVAL] E: [10][ 0/50]	Loss 3.9950e+00 (3.9950e+00)	Acc@1  58.50 ( 58.50)	Acc@5  78.50 ( 78.50)
[EVAL] E: [10][49/50]	Loss 4.0152e+00 (4.0180e+00)	Acc@1  53.50 ( 53.32)	Acc@5  82.50 ( 82.58)
		 LR=0.08853367102805307 -- best acc so far 53.75
***[2023-04-24 14:40:39]*** [Post-train] [Student] EVALUATION loss = 4.018021, accuracy@1 = 53.32, accuracy@5 = 82.58, error@1 = 46.68, error@5 = 17.42
[TRAIN] E: [11][  0/250]	Loss -1.4484e-07 (-1.4484e-07)	Acc@1  42.00 ( 42.00)	Acc@5  75.50 ( 75.50)
[TRAIN] E: [11][100/250]	Loss 2.2560e-07 (8.2378e-08)	Acc@1  37.50 ( 42.05)	Acc@5  75.00 ( 72.24)
[TRAIN] E: [11][200/250]	Loss 1.7822e-07 (1.0810e-07)	Acc@1  44.50 ( 41.93)	Acc@5  71.50 ( 72.15)
[TRAIN] E: [11][249/250]	Loss 2.4468e-07 (1.1162e-07)	Acc@1  41.00 ( 41.93)	Acc@5  71.00 ( 72.02)
[EVAL] E: [11][ 0/50]	Loss 4.1193e+00 (4.1193e+00)	Acc@1  59.00 ( 59.00)	Acc@5  78.50 ( 78.50)
[EVAL] E: [11][49/50]	Loss 4.1348e+00 (4.1370e+00)	Acc@1  54.00 ( 53.21)	Acc@5  82.50 ( 82.37)
		 LR=0.086457032492475 -- best acc so far 53.75
***[2023-04-24 14:43:29]*** [Post-train] [Student] EVALUATION loss = 4.137028, accuracy@1 = 53.21, accuracy@5 = 82.37, error@1 = 46.79, error@5 = 17.63
[TRAIN] E: [12][  0/250]	Loss 7.5996e-08 (7.5996e-08)	Acc@1  43.50 ( 43.50)	Acc@5  70.50 ( 70.50)
[TRAIN] E: [12][100/250]	Loss 3.4362e-07 (9.1894e-08)	Acc@1  45.00 ( 42.21)	Acc@5  74.50 ( 71.95)
[TRAIN] E: [12][200/250]	Loss -2.1219e-07 (8.6385e-08)	Acc@1  41.50 ( 42.14)	Acc@5  73.00 ( 71.86)
[TRAIN] E: [12][249/250]	Loss 7.3314e-08 (8.7509e-08)	Acc@1  40.50 ( 42.09)	Acc@5  69.50 ( 71.84)
[EVAL] E: [12][ 0/50]	Loss 4.2178e+00 (4.2178e+00)	Acc@1  58.50 ( 58.50)	Acc@5  79.50 ( 79.50)
[EVAL] E: [12][49/50]	Loss 4.2305e+00 (4.2320e+00)	Acc@1  54.50 ( 53.22)	Acc@5  82.50 ( 82.26)
		 LR=0.08423651470528296 -- best acc so far 53.75
***[2023-04-24 14:46:17]*** [Post-train] [Student] EVALUATION loss = 4.232033, accuracy@1 = 53.22, accuracy@5 = 82.26, error@1 = 46.78, error@5 = 17.74
[TRAIN] E: [13][  0/250]	Loss 3.8594e-07 (3.8594e-07)	Acc@1  43.00 ( 43.00)	Acc@5  70.50 ( 70.50)
[TRAIN] E: [13][100/250]	Loss -1.4246e-07 (9.4391e-08)	Acc@1  46.50 ( 41.85)	Acc@5  74.50 ( 71.66)
[TRAIN] E: [13][200/250]	Loss -4.5896e-08 (9.5419e-08)	Acc@1  38.00 ( 41.59)	Acc@5  66.50 ( 71.60)
[TRAIN] E: [13][249/250]	Loss -5.4836e-08 (9.3175e-08)	Acc@1  46.00 ( 41.52)	Acc@5  81.00 ( 71.60)
[EVAL] E: [13][ 0/50]	Loss 4.2984e+00 (4.2984e+00)	Acc@1  58.00 ( 58.00)	Acc@5  78.50 ( 78.50)
[EVAL] E: [13][49/50]	Loss 4.3088e+00 (4.3097e+00)	Acc@1  54.50 ( 52.81)	Acc@5  82.00 ( 81.87)
		 LR=0.08188088103572494 -- best acc so far 53.75
***[2023-04-24 14:49:04]*** [Post-train] [Student] EVALUATION loss = 4.309653, accuracy@1 = 52.81, accuracy@5 = 81.87, error@1 = 47.19, error@5 = 18.13
[TRAIN] E: [14][  0/250]	Loss -1.8835e-07 (-1.8835e-07)	Acc@1  43.00 ( 43.00)	Acc@5  67.50 ( 67.50)
[TRAIN] E: [14][100/250]	Loss 1.8895e-07 (7.7769e-08)	Acc@1  37.50 ( 41.45)	Acc@5  72.00 ( 71.70)
[TRAIN] E: [14][200/250]	Loss -1.7732e-07 (7.9225e-08)	Acc@1  41.00 ( 41.14)	Acc@5  72.50 ( 71.42)
[TRAIN] E: [14][249/250]	Loss 3.5167e-08 (7.4095e-08)	Acc@1  36.50 ( 41.04)	Acc@5  71.50 ( 71.24)
[EVAL] E: [14][ 0/50]	Loss 4.3637e+00 (4.3637e+00)	Acc@1  57.50 ( 57.50)	Acc@5  78.50 ( 78.50)
[EVAL] E: [14][49/50]	Loss 4.3716e+00 (4.3723e+00)	Acc@1  54.50 ( 52.41)	Acc@5  82.50 ( 81.81)
		 LR=0.079399428093708 -- best acc so far 53.75
***[2023-04-24 14:51:53]*** [Post-train] [Student] EVALUATION loss = 4.372292, accuracy@1 = 52.41, accuracy@5 = 81.81, error@1 = 47.59, error@5 = 18.19
[TRAIN] E: [15][  0/250]	Loss 3.9637e-08 (3.9637e-08)	Acc@1  42.00 ( 42.00)	Acc@5  65.00 ( 65.00)
[TRAIN] E: [15][100/250]	Loss 2.6762e-07 (4.8401e-08)	Acc@1  40.50 ( 40.70)	Acc@5  70.50 ( 70.97)
[TRAIN] E: [15][200/250]	Loss 1.7971e-07 (5.0393e-08)	Acc@1  46.50 ( 40.46)	Acc@5  76.00 ( 70.55)
[TRAIN] E: [15][249/250]	Loss -3.1590e-08 (5.0583e-08)	Acc@1  36.50 ( 40.42)	Acc@5  73.00 ( 70.56)
[EVAL] E: [15][ 0/50]	Loss 4.4168e+00 (4.4168e+00)	Acc@1  58.00 ( 58.00)	Acc@5  78.50 ( 78.50)
[EVAL] E: [15][49/50]	Loss 4.4233e+00 (4.4236e+00)	Acc@1  54.50 ( 51.77)	Acc@5  82.00 ( 81.53)
		 LR=0.07680194904032629 -- best acc so far 53.75
***[2023-04-24 14:54:47]*** [Post-train] [Student] EVALUATION loss = 4.423636, accuracy@1 = 51.77, accuracy@5 = 81.53, error@1 = 48.23, error@5 = 18.47
[TRAIN] E: [16][  0/250]	Loss -2.0146e-07 (-2.0146e-07)	Acc@1  41.50 ( 41.50)	Acc@5  65.50 ( 65.50)
[TRAIN] E: [16][100/250]	Loss -1.1772e-07 (3.8920e-09)	Acc@1  42.00 ( 39.43)	Acc@5  70.00 ( 69.41)
[TRAIN] E: [16][200/250]	Loss 1.3649e-07 (2.3118e-08)	Acc@1  37.00 ( 39.39)	Acc@5  73.00 ( 69.54)
[TRAIN] E: [16][249/250]	Loss -6.1989e-08 (1.2273e-08)	Acc@1  38.50 ( 39.29)	Acc@5  65.00 ( 69.50)
[EVAL] E: [16][ 0/50]	Loss 4.4607e+00 (4.4607e+00)	Acc@1  56.50 ( 56.50)	Acc@5  78.50 ( 78.50)
[EVAL] E: [16][49/50]	Loss 4.4657e+00 (4.4659e+00)	Acc@1  51.00 ( 50.89)	Acc@5  81.00 ( 80.76)
		 LR=0.07409869493872821 -- best acc so far 53.75
***[2023-04-24 14:57:38]*** [Post-train] [Student] EVALUATION loss = 4.465858, accuracy@1 = 50.89, accuracy@5 = 80.76, error@1 = 49.11, error@5 = 19.24
[TRAIN] E: [17][  0/250]	Loss 5.1856e-08 (5.1856e-08)	Acc@1  38.50 ( 38.50)	Acc@5  69.50 ( 69.50)
[TRAIN] E: [17][100/250]	Loss 1.3471e-07 (-1.0286e-08)	Acc@1  37.50 ( 38.47)	Acc@5  69.00 ( 68.70)
[TRAIN] E: [17][200/250]	Loss -8.0466e-09 (-2.2432e-08)	Acc@1  38.50 ( 38.26)	Acc@5  70.00 ( 68.27)
[TRAIN] E: [17][249/250]	Loss 5.6922e-08 (-2.3228e-08)	Acc@1  38.00 ( 38.13)	Acc@5  67.00 ( 67.97)
[EVAL] E: [17][ 0/50]	Loss 4.4957e+00 (4.4957e+00)	Acc@1  57.50 ( 57.50)	Acc@5  79.50 ( 79.50)
[EVAL] E: [17][49/50]	Loss 4.4997e+00 (4.4996e+00)	Acc@1  50.50 ( 49.61)	Acc@5  80.00 ( 79.77)
		 LR=0.07130033429785342 -- best acc so far 53.75
***[2023-04-24 15:00:26]*** [Post-train] [Student] EVALUATION loss = 4.499611, accuracy@1 = 49.61, accuracy@5 = 79.77, error@1 = 50.39, error@5 = 20.23
[TRAIN] E: [18][  0/250]	Loss -9.3281e-08 (-9.3281e-08)	Acc@1  33.50 ( 33.50)	Acc@5  70.50 ( 70.50)
[TRAIN] E: [18][100/250]	Loss -4.9770e-08 (-4.1390e-08)	Acc@1  40.00 ( 36.59)	Acc@5  66.00 ( 66.47)
[TRAIN] E: [18][200/250]	Loss -1.8984e-07 (-4.2522e-08)	Acc@1  33.50 ( 36.06)	Acc@5  67.00 ( 66.20)
[TRAIN] E: [18][249/250]	Loss -2.1517e-07 (-5.1382e-08)	Acc@1  33.00 ( 35.81)	Acc@5  57.50 ( 65.82)
[EVAL] E: [18][ 0/50]	Loss 4.5238e+00 (4.5238e+00)	Acc@1  54.00 ( 54.00)	Acc@5  79.50 ( 79.50)
[EVAL] E: [18][49/50]	Loss 4.5268e+00 (4.5265e+00)	Acc@1  46.00 ( 47.15)	Acc@5  79.00 ( 77.93)
		 LR=0.06841791096870209 -- best acc so far 53.75
***[2023-04-24 15:03:15]*** [Post-train] [Student] EVALUATION loss = 4.526500, accuracy@1 = 47.15, accuracy@5 = 77.93, error@1 = 52.85, error@5 = 22.07
[TRAIN] E: [19][  0/250]	Loss -2.3544e-07 (-2.3544e-07)	Acc@1  31.00 ( 31.00)	Acc@5  60.50 ( 60.50)
[TRAIN] E: [19][100/250]	Loss -3.3081e-07 (-8.0729e-08)	Acc@1  32.50 ( 33.14)	Acc@5  66.00 ( 63.11)
[TRAIN] E: [19][200/250]	Loss 7.4506e-09 (-6.9908e-08)	Acc@1  35.50 ( 32.41)	Acc@5  64.00 ( 62.11)
[TRAIN] E: [19][249/250]	Loss 1.2785e-07 (-7.5328e-08)	Acc@1  30.00 ( 32.24)	Acc@5  61.00 ( 61.60)
[EVAL] E: [19][ 0/50]	Loss 4.5469e+00 (4.5469e+00)	Acc@1  49.00 ( 49.00)	Acc@5  78.50 ( 78.50)
[EVAL] E: [19][49/50]	Loss 4.5490e+00 (4.5486e+00)	Acc@1  41.00 ( 42.81)	Acc@5  75.00 ( 74.31)
		 LR=0.06546280055930045 -- best acc so far 53.75
***[2023-04-24 15:06:08]*** [Post-train] [Student] EVALUATION loss = 4.548616, accuracy@1 = 42.81, accuracy@5 = 74.31, error@1 = 57.19, error@5 = 25.69
[TRAIN] E: [20][  0/250]	Loss -7.3612e-08 (-7.3612e-08)	Acc@1  37.00 ( 37.00)	Acc@5  63.50 ( 63.50)
[TRAIN] E: [20][100/250]	Loss 1.2785e-07 (-6.1372e-08)	Acc@1  32.00 ( 29.90)	Acc@5  55.00 ( 59.05)
[TRAIN] E: [20][200/250]	Loss -1.3381e-07 (-7.1091e-08)	Acc@1  29.00 ( 28.34)	Acc@5  53.50 ( 56.73)
[TRAIN] E: [20][249/250]	Loss 8.0466e-08 (-7.5526e-08)	Acc@1  26.00 ( 27.66)	Acc@5  51.00 ( 55.76)
[EVAL] E: [20][ 0/50]	Loss 4.5648e+00 (4.5648e+00)	Acc@1  39.00 ( 39.00)	Acc@5  73.00 ( 73.00)
[EVAL] E: [20][49/50]	Loss 4.5662e+00 (4.5658e+00)	Acc@1  34.50 ( 36.52)	Acc@5  67.00 ( 68.05)
		 LR=0.06244666554037285 -- best acc so far 53.75
***[2023-04-24 15:08:57]*** [Post-train] [Student] EVALUATION loss = 4.565793, accuracy@1 = 36.52, accuracy@5 = 68.05, error@1 = 63.48, error@5 = 31.95
[TRAIN] E: [21][  0/250]	Loss 1.2040e-07 (1.2040e-07)	Acc@1  21.50 ( 21.50)	Acc@5  44.00 ( 44.00)
[TRAIN] E: [21][100/250]	Loss -2.5064e-07 (-5.5350e-08)	Acc@1  20.50 ( 23.82)	Acc@5  45.00 ( 50.11)
[TRAIN] E: [21][200/250]	Loss 1.2189e-07 (-5.4900e-08)	Acc@1  19.00 ( 22.14)	Acc@5  42.00 ( 47.59)
[TRAIN] E: [21][249/250]	Loss 1.2159e-07 (-5.0743e-08)	Acc@1  21.50 ( 21.43)	Acc@5  48.00 ( 46.59)
[EVAL] E: [21][ 0/50]	Loss 4.5783e+00 (4.5783e+00)	Acc@1  28.00 ( 28.00)	Acc@5  60.50 ( 60.50)
[EVAL] E: [21][49/50]	Loss 4.5791e+00 (4.5787e+00)	Acc@1  26.50 ( 28.57)	Acc@5  54.00 ( 58.25)
		 LR=0.059381409218897986 -- best acc so far 53.75
***[2023-04-24 15:11:45]*** [Post-train] [Student] EVALUATION loss = 4.578737, accuracy@1 = 28.57, accuracy@5 = 58.25, error@1 = 71.43, error@5 = 41.75
[TRAIN] E: [22][  0/250]	Loss -4.0025e-07 (-4.0025e-07)	Acc@1  19.00 ( 19.00)	Acc@5  41.50 ( 41.50)
[TRAIN] E: [22][100/250]	Loss 3.9041e-08 (-5.8162e-08)	Acc@1  12.00 ( 16.61)	Acc@5  34.00 ( 38.63)
[TRAIN] E: [22][200/250]	Loss -1.0252e-07 (-4.0110e-08)	Acc@1  11.00 ( 15.24)	Acc@5  29.00 ( 36.42)
[TRAIN] E: [22][249/250]	Loss -7.5102e-08 (-4.1838e-08)	Acc@1  15.00 ( 14.68)	Acc@5  28.00 ( 35.38)
[EVAL] E: [22][ 0/50]	Loss 4.5881e+00 (4.5881e+00)	Acc@1  18.00 ( 18.00)	Acc@5  47.50 ( 47.50)
[EVAL] E: [22][49/50]	Loss 4.5884e+00 (4.5881e+00)	Acc@1  19.00 ( 19.08)	Acc@5  40.50 ( 45.37)
		 LR=0.05627912876119434 -- best acc so far 53.75
***[2023-04-24 15:14:50]*** [Post-train] [Student] EVALUATION loss = 4.588133, accuracy@1 = 19.08, accuracy@5 = 45.37, error@1 = 80.92, error@5 = 54.63
[TRAIN] E: [23][  0/250]	Loss -3.4094e-07 (-3.4094e-07)	Acc@1  12.50 ( 12.50)	Acc@5  30.00 ( 30.00)
[TRAIN] E: [23][100/250]	Loss -4.2558e-07 (-4.5276e-08)	Acc@1  13.50 ( 10.61)	Acc@5  26.50 ( 27.96)
[TRAIN] E: [23][200/250]	Loss 1.5289e-07 (-4.0571e-08)	Acc@1   8.50 (  9.86)	Acc@5  23.00 ( 26.07)
[TRAIN] E: [23][249/250]	Loss -1.7971e-07 (-3.1639e-08)	Acc@1   8.00 (  9.44)	Acc@5  19.00 ( 25.22)
[EVAL] E: [23][ 0/50]	Loss 4.5947e+00 (4.5947e+00)	Acc@1  10.00 ( 10.00)	Acc@5  30.00 ( 30.00)
[EVAL] E: [23][49/50]	Loss 4.5947e+00 (4.5945e+00)	Acc@1  12.00 ( 10.90)	Acc@5  30.00 ( 32.22)
		 LR=0.05315206745093131 -- best acc so far 53.75
***[2023-04-24 15:18:00]*** [Post-train] [Student] EVALUATION loss = 4.594486, accuracy@1 = 10.90, accuracy@5 = 32.22, error@1 = 89.10, error@5 = 67.78
[TRAIN] E: [24][  0/250]	Loss -6.2585e-09 (-6.2585e-09)	Acc@1   4.00 (  4.00)	Acc@5  14.00 ( 14.00)
[TRAIN] E: [24][100/250]	Loss 1.0371e-07 (1.2939e-08)	Acc@1   6.00 (  6.40)	Acc@5  13.50 ( 18.21)
[TRAIN] E: [24][200/250]	Loss 3.0994e-07 (2.4248e-08)	Acc@1   5.50 (  6.07)	Acc@5  14.50 ( 16.83)
[TRAIN] E: [24][249/250]	Loss 1.7524e-07 (2.7735e-08)	Acc@1   6.50 (  5.72)	Acc@5  13.50 ( 16.07)
[EVAL] E: [24][ 0/50]	Loss 4.5993e+00 (4.5993e+00)	Acc@1   6.00 (  6.00)	Acc@5  17.50 ( 17.50)
[EVAL] E: [24][49/50]	Loss 4.5990e+00 (4.5989e+00)	Acc@1   6.00 (  5.61)	Acc@5  15.50 ( 18.91)
		 LR=0.05001256637048207 -- best acc so far 53.75
***[2023-04-24 15:21:09]*** [Post-train] [Student] EVALUATION loss = 4.598876, accuracy@1 = 5.61, accuracy@5 = 18.91, error@1 = 94.39, error@5 = 81.09
[TRAIN] E: [25][  0/250]	Loss 6.0797e-08 (6.0797e-08)	Acc@1   2.50 (  2.50)	Acc@5  13.00 ( 13.00)
[TRAIN] E: [25][100/250]	Loss 3.5822e-07 (3.6040e-08)	Acc@1   3.00 (  4.01)	Acc@5  12.00 ( 11.53)
[TRAIN] E: [25][200/250]	Loss 3.6955e-08 (4.5624e-08)	Acc@1   2.00 (  3.53)	Acc@5   7.50 ( 10.44)
[TRAIN] E: [25][249/250]	Loss -5.7220e-08 (4.2630e-08)	Acc@1   1.50 (  3.35)	Acc@5   6.50 ( 10.05)
[EVAL] E: [25][ 0/50]	Loss 4.6023e+00 (4.6023e+00)	Acc@1   4.00 (  4.00)	Acc@5   9.50 (  9.50)
[EVAL] E: [25][49/50]	Loss 4.6018e+00 (4.6018e+00)	Acc@1   1.50 (  2.64)	Acc@5  10.50 ( 10.16)
		 LR=0.04687301569630958 -- best acc so far 53.75
***[2023-04-24 15:24:21]*** [Post-train] [Student] EVALUATION loss = 4.601768, accuracy@1 = 2.64, accuracy@5 = 10.16, error@1 = 97.36, error@5 = 89.84
[TRAIN] E: [26][  0/250]	Loss 2.0772e-07 (2.0772e-07)	Acc@1   2.00 (  2.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [26][100/250]	Loss -1.9878e-07 (8.1567e-08)	Acc@1   0.50 (  2.22)	Acc@5   4.00 (  7.71)
[TRAIN] E: [26][200/250]	Loss 2.4408e-07 (7.7402e-08)	Acc@1   0.50 (  1.98)	Acc@5   6.50 (  7.20)
[TRAIN] E: [26][249/250]	Loss 8.5235e-08 (7.7521e-08)	Acc@1   0.50 (  1.87)	Acc@5   4.50 (  7.04)
[EVAL] E: [26][ 0/50]	Loss 4.6040e+00 (4.6040e+00)	Acc@1   2.00 (  2.00)	Acc@5   8.50 (  8.50)
[EVAL] E: [26][49/50]	Loss 4.6035e+00 (4.6035e+00)	Acc@1   1.50 (  1.51)	Acc@5   6.50 (  6.57)
		 LR=0.04374580580060053 -- best acc so far 53.75
***[2023-04-24 15:27:35]*** [Post-train] [Student] EVALUATION loss = 4.603467, accuracy@1 = 1.51, accuracy@5 = 6.57, error@1 = 98.49, error@5 = 93.43
[TRAIN] E: [27][  0/250]	Loss -7.1526e-08 (-7.1526e-08)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [27][100/250]	Loss 2.7388e-07 (8.3287e-08)	Acc@1   0.50 (  1.32)	Acc@5   4.50 (  6.06)
[TRAIN] E: [27][200/250]	Loss 1.1355e-07 (8.5171e-08)	Acc@1   2.00 (  1.21)	Acc@5   7.00 (  5.85)
[TRAIN] E: [27][249/250]	Loss 1.2696e-07 (8.6113e-08)	Acc@1   1.00 (  1.15)	Acc@5   4.50 (  5.77)
[EVAL] E: [27][ 0/50]	Loss 4.6049e+00 (4.6049e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [27][49/50]	Loss 4.6044e+00 (4.6044e+00)	Acc@1   1.50 (  1.05)	Acc@5   5.50 (  5.28)
		 LR=0.04064327835212695 -- best acc so far 53.75
***[2023-04-24 15:30:44]*** [Post-train] [Student] EVALUATION loss = 4.604400, accuracy@1 = 1.05, accuracy@5 = 5.28, error@1 = 98.95, error@5 = 94.72
[TRAIN] E: [28][  0/250]	Loss 7.3314e-08 (7.3314e-08)	Acc@1   0.50 (  0.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [28][100/250]	Loss 2.2769e-07 (1.2888e-07)	Acc@1   2.50 (  0.91)	Acc@5   6.50 (  5.43)
[TRAIN] E: [28][200/250]	Loss -1.3888e-07 (1.0295e-07)	Acc@1   2.00 (  1.02)	Acc@5   5.50 (  5.41)
[TRAIN] E: [28][249/250]	Loss 1.8060e-07 (1.0091e-07)	Acc@1   2.00 (  1.00)	Acc@5   6.00 (  5.30)
[EVAL] E: [28][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [28][49/50]	Loss 4.6048e+00 (4.6048e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.04)
		 LR=0.03757767760931802 -- best acc so far 53.75
***[2023-04-24 15:33:32]*** [Post-train] [Student] EVALUATION loss = 4.604841, accuracy@1 = 1.00, accuracy@5 = 5.04, error@1 = 99.00, error@5 = 94.96
[TRAIN] E: [29][  0/250]	Loss 2.7299e-07 (2.7299e-07)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [29][100/250]	Loss 1.3769e-07 (1.1099e-07)	Acc@1   2.00 (  1.02)	Acc@5   6.00 (  5.06)
[TRAIN] E: [29][200/250]	Loss 1.4484e-07 (1.0960e-07)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.18)
[TRAIN] E: [29][249/250]	Loss -7.8678e-08 (1.0637e-07)	Acc@1   0.00 (  1.00)	Acc@5   4.00 (  5.14)
[EVAL] E: [29][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [29][49/50]	Loss 4.6050e+00 (4.6050e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.03)
		 LR=0.034561102097765854 -- best acc so far 53.75
***[2023-04-24 15:36:11]*** [Post-train] [Student] EVALUATION loss = 4.605023, accuracy@1 = 1.00, accuracy@5 = 5.03, error@1 = 99.00, error@5 = 94.97
[TRAIN] E: [30][  0/250]	Loss 2.2411e-07 (2.2411e-07)	Acc@1   0.00 (  0.00)	Acc@5   2.50 (  2.50)
[TRAIN] E: [30][100/250]	Loss 1.3471e-07 (1.4837e-07)	Acc@1   1.00 (  0.98)	Acc@5   5.00 (  5.05)
[TRAIN] E: [30][200/250]	Loss 2.9951e-07 (1.3360e-07)	Acc@1   0.00 (  1.00)	Acc@5   3.50 (  5.12)
[TRAIN] E: [30][249/250]	Loss 3.4809e-07 (1.3998e-07)	Acc@1   0.00 (  1.00)	Acc@5   4.50 (  5.10)
[EVAL] E: [30][ 0/50]	Loss 4.6056e+00 (4.6056e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [30][49/50]	Loss 4.6051e+00 (4.6051e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.04)
		 LR=0.0316054568628723 -- best acc so far 53.75
***[2023-04-24 15:38:54]*** [Post-train] [Student] EVALUATION loss = 4.605098, accuracy@1 = 1.00, accuracy@5 = 5.04, error@1 = 99.00, error@5 = 94.96
[TRAIN] E: [31][  0/250]	Loss 2.1040e-07 (2.1040e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [31][100/250]	Loss 3.0637e-07 (1.2703e-07)	Acc@1   1.00 (  0.94)	Acc@5   3.50 (  4.99)
[TRAIN] E: [31][200/250]	Loss 6.5267e-08 (1.3541e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.01)
[TRAIN] E: [31][249/250]	Loss 4.2498e-07 (1.3557e-07)	Acc@1   0.00 (  1.00)	Acc@5   5.00 (  5.09)
[EVAL] E: [31][ 0/50]	Loss 4.6056e+00 (4.6056e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [31][49/50]	Loss 4.6051e+00 (4.6051e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.05)
		 LR=0.028722406486073566 -- best acc so far 53.75
***[2023-04-24 15:41:36]*** [Post-train] [Student] EVALUATION loss = 4.605132, accuracy@1 = 1.00, accuracy@5 = 5.05, error@1 = 99.00, error@5 = 94.95
[TRAIN] E: [32][  0/250]	Loss 8.1062e-08 (8.1062e-08)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [32][100/250]	Loss 1.6749e-07 (1.4324e-07)	Acc@1   2.00 (  1.05)	Acc@5   6.00 (  5.14)
[TRAIN] E: [32][200/250]	Loss 1.6034e-07 (1.3817e-07)	Acc@1   2.00 (  1.00)	Acc@5   5.50 (  5.10)
[TRAIN] E: [32][249/250]	Loss 1.6510e-07 (1.3693e-07)	Acc@1   0.50 (  1.00)	Acc@5   8.50 (  5.07)
[EVAL] E: [32][ 0/50]	Loss 4.6056e+00 (4.6056e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [32][49/50]	Loss 4.6052e+00 (4.6051e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.09)
		 LR=0.02592332905006647 -- best acc so far 53.75
***[2023-04-24 15:44:27]*** [Post-train] [Student] EVALUATION loss = 4.605150, accuracy@1 = 1.00, accuracy@5 = 5.09, error@1 = 99.00, error@5 = 94.91
[TRAIN] E: [33][  0/250]	Loss 1.2577e-07 (1.2577e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [33][100/250]	Loss 3.3587e-07 (1.4100e-07)	Acc@1   1.00 (  1.08)	Acc@5   6.00 (  5.09)
[TRAIN] E: [33][200/250]	Loss 2.6345e-07 (1.5933e-07)	Acc@1   1.50 (  1.03)	Acc@5   4.00 (  4.99)
[TRAIN] E: [33][249/250]	Loss 2.4885e-07 (1.5773e-07)	Acc@1   0.00 (  1.00)	Acc@5   6.00 (  5.07)
[EVAL] E: [33][ 0/50]	Loss 4.6056e+00 (4.6056e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [33][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.11)
		 LR=0.02321927123471414 -- best acc so far 53.75
***[2023-04-24 15:47:10]*** [Post-train] [Student] EVALUATION loss = 4.605159, accuracy@1 = 1.00, accuracy@5 = 5.11, error@1 = 99.00, error@5 = 94.89
[TRAIN] E: [34][  0/250]	Loss -1.1951e-07 (-1.1951e-07)	Acc@1   0.00 (  0.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [34][100/250]	Loss 1.9997e-07 (1.8014e-07)	Acc@1   0.50 (  1.03)	Acc@5   6.50 (  5.35)
[TRAIN] E: [34][200/250]	Loss 1.5885e-07 (1.5357e-07)	Acc@1   1.00 (  1.02)	Acc@5   4.50 (  5.23)
[TRAIN] E: [34][249/250]	Loss 1.6689e-07 (1.6026e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.12)
[EVAL] E: [34][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   7.00 (  7.00)
[EVAL] E: [34][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   4.50 (  5.26)
		 LR=0.020620904720847207 -- best acc so far 53.75
***[2023-04-24 15:49:55]*** [Post-train] [Student] EVALUATION loss = 4.605165, accuracy@1 = 1.00, accuracy@5 = 5.26, error@1 = 99.00, error@5 = 94.74
[TRAIN] E: [35][  0/250]	Loss -2.4438e-08 (-2.4438e-08)	Acc@1   0.00 (  0.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [35][100/250]	Loss 1.7792e-07 (2.0248e-07)	Acc@1   0.00 (  0.97)	Acc@5   7.00 (  5.06)
