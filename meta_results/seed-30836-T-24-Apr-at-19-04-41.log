Main Function with logger : Logger(dir=meta_results, use-tf=False, writer=None)
Arguments : -------------------------------
batch_size       : 500
checkpoint_dir   : ./checkpoint
class_num        : 100
cutout_length    : 16
data_path        : /home/prathamesh/code/data/cifar/
dataset          : cifar100
epochs           : 200
eval_batch_size  : 500
eval_frequency   : 1
global_rand_seed : -1
input_size       : 32
inst_based       : True
log_dir          : ./log
lr               : 0.1
mcd_weight       : 0.01
meta_interval    : 1
meta_lr          : 0.01
meta_weight_decay : 0.0
model_name       : ResNet10_s
momentum         : 0.9
print_freq       : 100
print_freq_eval  : 100
rand_seed        : 30836
save_dir         : ./meta_results/
unsup_adapt      : False
wd               : 0.0005
workers          : 8
Python  Version  : 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0]
Pillow  Version  : 9.2.0
PyTorch Version  : 1.13.1
cuDNN   Version  : 8500
CUDA available   : True
CUDA GPU numbers : 1
CUDA_VISIBLE_DEVICES : 0
model information : EfficientNetV2_s (CIFAR)
--------------------------------------------------
[Student]Params=0.08 MB, FLOPs=4.16 M ... = 0.00 G
--------------------------------------------------
train_data : Dataset CIFAR100
    Number of datapoints: 50000
    Root location: /home/prathamesh/code/data/cifar/
    Split: Train
    StandardTransform
Transform: Compose(
               RandomCrop(size=(32, 32), padding=4)
               RandomHorizontalFlip(p=0.5)
               AutoAugment CIFAR10 Policy
               ToTensor()
               CUTOUT(length=16)
               Normalize(mean=[0.5070588235294118, 0.48666666666666664, 0.4407843137254902], std=[0.26745098039215687, 0.2564705882352941, 0.27607843137254906])
           )
valid_data : Dataset CIFAR100
    Number of datapoints: 10000
    Root location: /home/prathamesh/code/data/cifar/
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.5070588235294118, 0.48666666666666664, 0.4407843137254902], std=[0.26745098039215687, 0.2564705882352941, 0.27607843137254906])
           )
[TRAIN] E: [0][  0/100]	Loss 3.9743e-07 (3.9743e-07)	Acc@1  44.40 ( 44.40)	Acc@5  76.80 ( 76.80)
[TRAIN] E: [0][ 99/100]	Loss 8.3916e-08 (6.0668e-08)	Acc@1  44.80 ( 43.00)	Acc@5  74.20 ( 72.86)
[EVAL] E: [0][ 0/20]	Loss 1.6492e+00 (1.6492e+00)	Acc@1  57.20 ( 57.20)	Acc@5  83.00 ( 83.00)
[EVAL] E: [0][19/20]	Loss 1.6133e+00 (1.6663e+00)	Acc@1  55.80 ( 53.75)	Acc@5  84.80 ( 82.89)
		 LR=0.09990329919350381 -- best acc so far 53.75000057220459
***[2023-04-24 19:05:49]*** [Post-train] [Student] EVALUATION loss = 1.666279, accuracy@1 = 53.75, accuracy@5 = 82.89, error@1 = 46.25, error@5 = 17.11
[TRAIN] E: [1][  0/100]	Loss -3.3066e-08 (-3.3066e-08)	Acc@1  42.00 ( 42.00)	Acc@5  74.80 ( 74.80)
[TRAIN] E: [1][ 99/100]	Loss 2.2370e-07 (6.4734e-08)	Acc@1  40.20 ( 42.67)	Acc@5  71.00 ( 72.66)
[EVAL] E: [1][ 0/20]	Loss 1.6659e+00 (1.6659e+00)	Acc@1  57.80 ( 57.80)	Acc@5  82.80 ( 82.80)
[EVAL] E: [1][19/20]	Loss 1.6395e+00 (1.6842e+00)	Acc@1  56.20 ( 53.68)	Acc@5  84.20 ( 82.80)
		 LR=0.09960966273334369 -- best acc so far 53.75000057220459
***[2023-04-24 19:06:47]*** [Post-train] [Student] EVALUATION loss = 1.684155, accuracy@1 = 53.68, accuracy@5 = 82.80, error@1 = 46.32, error@5 = 17.20
[TRAIN] E: [2][  0/100]	Loss 7.0199e-08 (7.0199e-08)	Acc@1  40.20 ( 40.20)	Acc@5  73.20 ( 73.20)
[TRAIN] E: [2][ 99/100]	Loss 1.5518e-07 (7.8175e-08)	Acc@1  45.20 ( 42.67)	Acc@5  72.00 ( 72.65)
[EVAL] E: [2][ 0/20]	Loss 1.6968e+00 (1.6968e+00)	Acc@1  57.20 ( 57.20)	Acc@5  83.20 ( 83.20)
[EVAL] E: [2][19/20]	Loss 1.6750e+00 (1.7129e+00)	Acc@1  56.40 ( 53.68)	Acc@5  84.80 ( 82.90)
		 LR=0.09912023959887407 -- best acc so far 53.75000057220459
***[2023-04-24 19:07:45]*** [Post-train] [Student] EVALUATION loss = 1.712934, accuracy@1 = 53.68, accuracy@5 = 82.90, error@1 = 46.32, error@5 = 17.10
[TRAIN] E: [3][  0/100]	Loss 6.9290e-08 (6.9290e-08)	Acc@1  43.60 ( 43.60)	Acc@5  74.00 ( 74.00)
[TRAIN] E: [3][ 99/100]	Loss 2.9832e-08 (7.2549e-08)	Acc@1  42.60 ( 42.94)	Acc@5  73.60 ( 72.91)
[EVAL] E: [3][ 0/20]	Loss 1.7490e+00 (1.7490e+00)	Acc@1  57.40 ( 57.40)	Acc@5  82.80 ( 82.80)
[EVAL] E: [3][19/20]	Loss 1.7304e+00 (1.7619e+00)	Acc@1  55.80 ( 53.68)	Acc@5  84.80 ( 82.88)
		 LR=0.09843696131961058 -- best acc so far 53.75000057220459
***[2023-04-24 19:08:44]*** [Post-train] [Student] EVALUATION loss = 1.761892, accuracy@1 = 53.68, accuracy@5 = 82.88, error@1 = 46.32, error@5 = 17.12
[TRAIN] E: [4][  0/100]	Loss -1.8686e-08 (-1.8686e-08)	Acc@1  42.40 ( 42.40)	Acc@5  72.20 ( 72.20)
[TRAIN] E: [4][ 99/100]	Loss -3.0890e-08 (8.8188e-08)	Acc@1  45.60 ( 42.73)	Acc@5  72.40 ( 72.69)
[EVAL] E: [4][ 0/20]	Loss 1.8114e+00 (1.8114e+00)	Acc@1  57.60 ( 57.60)	Acc@5  82.20 ( 82.20)
[EVAL] E: [4][19/20]	Loss 1.7970e+00 (1.8221e+00)	Acc@1  55.80 ( 53.62)	Acc@5  84.40 ( 82.66)
		 LR=0.09756252448276127 -- best acc so far 53.75000057220459
***[2023-04-24 19:09:43]*** [Post-train] [Student] EVALUATION loss = 1.822093, accuracy@1 = 53.62, accuracy@5 = 82.66, error@1 = 46.38, error@5 = 17.34
[TRAIN] E: [5][  0/100]	Loss 1.5560e-07 (1.5560e-07)	Acc@1  44.40 ( 44.40)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [5][ 99/100]	Loss 8.4609e-08 (1.0969e-07)	Acc@1  41.60 ( 42.77)	Acc@5  73.20 ( 72.58)
[EVAL] E: [5][ 0/20]	Loss 1.8864e+00 (1.8864e+00)	Acc@1  56.80 ( 56.80)	Acc@5  82.60 ( 82.60)
[EVAL] E: [5][19/20]	Loss 1.8755e+00 (1.8948e+00)	Acc@1  56.00 ( 53.59)	Acc@5  84.60 ( 82.92)
		 LR=0.09650038009102904 -- best acc so far 53.75000057220459
***[2023-04-24 19:10:41]*** [Post-train] [Student] EVALUATION loss = 1.894762, accuracy@1 = 53.59, accuracy@5 = 82.92, error@1 = 46.41, error@5 = 17.08
[TRAIN] E: [6][  0/100]	Loss 6.6459e-08 (6.6459e-08)	Acc@1  41.60 ( 41.60)	Acc@5  73.20 ( 73.20)
[TRAIN] E: [6][ 99/100]	Loss 1.7026e-07 (8.3646e-08)	Acc@1  42.40 ( 42.72)	Acc@5  73.00 ( 72.72)
[EVAL] E: [6][ 0/20]	Loss 1.9736e+00 (1.9736e+00)	Acc@1  57.00 ( 57.00)	Acc@5  82.60 ( 82.60)
[EVAL] E: [6][19/20]	Loss 1.9632e+00 (1.9794e+00)	Acc@1  56.40 ( 53.65)	Acc@5  84.60 ( 82.77)
		 LR=0.09525471994308041 -- best acc so far 53.75000057220459
***[2023-04-24 19:11:39]*** [Post-train] [Student] EVALUATION loss = 1.979437, accuracy@1 = 53.65, accuracy@5 = 82.77, error@1 = 46.35, error@5 = 17.23
[TRAIN] E: [7][  0/100]	Loss 2.4822e-07 (2.4822e-07)	Acc@1  41.00 ( 41.00)	Acc@5  72.40 ( 72.40)
[TRAIN] E: [7][ 99/100]	Loss 1.2103e-07 (1.1908e-07)	Acc@1  46.00 ( 42.81)	Acc@5  75.20 ( 72.86)
[EVAL] E: [7][ 0/20]	Loss 2.0784e+00 (2.0784e+00)	Acc@1  57.20 ( 57.20)	Acc@5  82.40 ( 82.40)
[EVAL] E: [7][19/20]	Loss 2.0680e+00 (2.0809e+00)	Acc@1  56.40 ( 53.57)	Acc@5  84.60 ( 82.72)
		 LR=0.09383046009043135 -- best acc so far 53.75000057220459
***[2023-04-24 19:12:37]*** [Post-train] [Student] EVALUATION loss = 2.080926, accuracy@1 = 53.57, accuracy@5 = 82.72, error@1 = 46.43, error@5 = 17.28
[TRAIN] E: [8][  0/100]	Loss 2.5868e-08 (2.5868e-08)	Acc@1  46.20 ( 46.20)	Acc@5  73.80 ( 73.80)
[TRAIN] E: [8][ 99/100]	Loss 7.2777e-08 (1.1672e-07)	Acc@1  40.60 ( 43.03)	Acc@5  70.00 ( 72.89)
[EVAL] E: [8][ 0/20]	Loss 2.1776e+00 (2.1776e+00)	Acc@1  57.40 ( 57.40)	Acc@5  82.80 ( 82.80)
[EVAL] E: [8][19/20]	Loss 2.1666e+00 (2.1773e+00)	Acc@1  56.40 ( 53.71)	Acc@5  84.60 ( 82.80)
		 LR=0.09223322143603785 -- best acc so far 53.75000057220459
***[2023-04-24 19:13:33]*** [Post-train] [Student] EVALUATION loss = 2.177297, accuracy@1 = 53.71, accuracy@5 = 82.80, error@1 = 46.29, error@5 = 17.20
[TRAIN] E: [9][  0/100]	Loss 8.9049e-08 (8.9049e-08)	Acc@1  46.40 ( 46.40)	Acc@5  79.80 ( 79.80)
[TRAIN] E: [9][ 99/100]	Loss 2.2537e-07 (1.2213e-07)	Acc@1  46.00 ( 42.79)	Acc@5  74.60 ( 72.90)
[EVAL] E: [9][ 0/20]	Loss 2.2936e+00 (2.2936e+00)	Acc@1  57.00 ( 57.00)	Acc@5  82.80 ( 82.80)
[EVAL] E: [9][19/20]	Loss 2.2832e+00 (2.2910e+00)	Acc@1  56.00 ( 53.62)	Acc@5  84.40 ( 82.78)
		 LR=0.09046930755115985 -- best acc so far 53.75000057220459
***[2023-04-24 19:14:32]*** [Post-train] [Student] EVALUATION loss = 2.291026, accuracy@1 = 53.62, accuracy@5 = 82.78, error@1 = 46.38, error@5 = 17.22
[TRAIN] E: [10][  0/100]	Loss 2.2829e-08 (2.2829e-08)	Acc@1  42.60 ( 42.60)	Acc@5  71.80 ( 71.80)
[TRAIN] E: [10][ 99/100]	Loss 1.0532e-07 (1.1202e-07)	Acc@1  41.00 ( 43.02)	Acc@5  73.60 ( 72.90)
[EVAL] E: [10][ 0/20]	Loss 2.4016e+00 (2.4016e+00)	Acc@1  57.60 ( 57.60)	Acc@5  82.80 ( 82.80)
[EVAL] E: [10][19/20]	Loss 2.3895e+00 (2.3968e+00)	Acc@1  56.00 ( 53.74)	Acc@5  84.40 ( 82.82)
		 LR=0.08854567979804538 -- best acc so far 53.75000057220459
***[2023-04-24 19:15:32]*** [Post-train] [Student] EVALUATION loss = 2.396772, accuracy@1 = 53.74, accuracy@5 = 82.82, error@1 = 46.26, error@5 = 17.18
[TRAIN] E: [11][  0/100]	Loss 1.4484e-07 (1.4484e-07)	Acc@1  44.00 ( 44.00)	Acc@5  75.00 ( 75.00)
[TRAIN] E: [11][ 99/100]	Loss 1.9395e-07 (1.2172e-07)	Acc@1  45.00 ( 43.11)	Acc@5  73.40 ( 72.78)
[EVAL] E: [11][ 0/20]	Loss 2.5139e+00 (2.5139e+00)	Acc@1  57.40 ( 57.40)	Acc@5  82.80 ( 82.80)
[EVAL] E: [11][19/20]	Loss 2.5015e+00 (2.5076e+00)	Acc@1  56.40 ( 53.72)	Acc@5  84.60 ( 82.93)
		 LR=0.08646992985661404 -- best acc so far 53.75000057220459
***[2023-04-24 19:16:29]*** [Post-train] [Student] EVALUATION loss = 2.507648, accuracy@1 = 53.72, accuracy@5 = 82.93, error@1 = 46.28, error@5 = 17.07
[TRAIN] E: [12][  0/100]	Loss 1.6546e-07 (1.6546e-07)	Acc@1  42.80 ( 42.80)	Acc@5  70.40 ( 70.40)
[TRAIN] E: [12][ 99/100]	Loss -1.3947e-08 (1.2833e-07)	Acc@1  45.60 ( 43.16)	Acc@5  73.80 ( 72.84)
[EVAL] E: [12][ 0/20]	Loss 2.6265e+00 (2.6265e+00)	Acc@1  57.20 ( 57.20)	Acc@5  83.00 ( 83.00)
[EVAL] E: [12][19/20]	Loss 2.6125e+00 (2.6179e+00)	Acc@1  56.60 ( 53.70)	Acc@5  84.60 ( 82.88)
		 LR=0.08425024976356474 -- best acc so far 53.75000057220459
***[2023-04-24 19:17:26]*** [Post-train] [Student] EVALUATION loss = 2.617936, accuracy@1 = 53.70, accuracy@5 = 82.88, error@1 = 46.30, error@5 = 17.12
[TRAIN] E: [13][  0/100]	Loss 1.9968e-07 (1.9968e-07)	Acc@1  43.40 ( 43.40)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [13][ 99/100]	Loss 2.0540e-07 (1.3962e-07)	Acc@1  46.80 ( 42.94)	Acc@5  74.60 ( 72.76)
[EVAL] E: [13][ 0/20]	Loss 2.7356e+00 (2.7356e+00)	Acc@1  56.60 ( 56.60)	Acc@5  83.20 ( 83.20)
[EVAL] E: [13][19/20]	Loss 2.7210e+00 (2.7262e+00)	Acc@1  56.80 ( 53.61)	Acc@5  84.40 ( 82.91)
		 LR=0.08189539958214935 -- best acc so far 53.75000057220459
***[2023-04-24 19:18:25]*** [Post-train] [Student] EVALUATION loss = 2.726249, accuracy@1 = 53.61, accuracy@5 = 82.91, error@1 = 46.39, error@5 = 17.09
[TRAIN] E: [14][  0/100]	Loss 1.3471e-07 (1.3471e-07)	Acc@1  44.00 ( 44.00)	Acc@5  77.00 ( 77.00)
[TRAIN] E: [14][ 99/100]	Loss 2.1976e-07 (1.3442e-07)	Acc@1  47.00 ( 42.86)	Acc@5  74.20 ( 72.89)
[EVAL] E: [14][ 0/20]	Loss 2.8408e+00 (2.8408e+00)	Acc@1  56.40 ( 56.40)	Acc@5  82.60 ( 82.60)
[EVAL] E: [14][19/20]	Loss 2.8269e+00 (2.8310e+00)	Acc@1  56.40 ( 53.65)	Acc@5  84.60 ( 82.77)
		 LR=0.0794146728302052 -- best acc so far 53.75000057220459
***[2023-04-24 19:19:21]*** [Post-train] [Student] EVALUATION loss = 2.831018, accuracy@1 = 53.65, accuracy@5 = 82.77, error@1 = 46.35, error@5 = 17.23
[TRAIN] E: [15][  0/100]	Loss 1.2070e-07 (1.2070e-07)	Acc@1  43.00 ( 43.00)	Acc@5  72.20 ( 72.20)
[TRAIN] E: [15][ 99/100]	Loss 3.0935e-08 (1.4264e-07)	Acc@1  47.60 ( 43.24)	Acc@5  75.20 ( 72.81)
[EVAL] E: [15][ 0/20]	Loss 2.9373e+00 (2.9373e+00)	Acc@1  56.00 ( 56.00)	Acc@5  82.80 ( 82.80)
[EVAL] E: [15][19/20]	Loss 2.9222e+00 (2.9264e+00)	Acc@1  56.40 ( 53.61)	Acc@5  84.60 ( 82.82)
		 LR=0.07681785980288601 -- best acc so far 53.75000057220459
***[2023-04-24 19:20:19]*** [Post-train] [Student] EVALUATION loss = 2.926446, accuracy@1 = 53.61, accuracy@5 = 82.82, error@1 = 46.39, error@5 = 17.18
[TRAIN] E: [16][  0/100]	Loss 9.4771e-08 (9.4771e-08)	Acc@1  41.40 ( 41.40)	Acc@5  71.00 ( 71.00)
[TRAIN] E: [16][ 99/100]	Loss 2.1130e-07 (1.4711e-07)	Acc@1  43.00 ( 42.87)	Acc@5  72.40 ( 72.62)
[EVAL] E: [16][ 0/20]	Loss 3.0336e+00 (3.0336e+00)	Acc@1  56.00 ( 56.00)	Acc@5  83.00 ( 83.00)
[EVAL] E: [16][19/20]	Loss 3.0181e+00 (3.0224e+00)	Acc@1  56.60 ( 53.63)	Acc@5  84.20 ( 82.84)
		 LR=0.07411520893483951 -- best acc so far 53.75000057220459
***[2023-04-24 19:21:18]*** [Post-train] [Student] EVALUATION loss = 3.022393, accuracy@1 = 53.63, accuracy@5 = 82.84, error@1 = 46.37, error@5 = 17.16
[TRAIN] E: [17][  0/100]	Loss -6.8784e-08 (-6.8784e-08)	Acc@1  45.00 ( 45.00)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [17][ 99/100]	Loss 2.9922e-08 (1.0861e-07)	Acc@1  41.60 ( 42.97)	Acc@5  69.60 ( 72.72)
[EVAL] E: [17][ 0/20]	Loss 3.1212e+00 (3.1212e+00)	Acc@1  56.60 ( 56.60)	Acc@5  82.80 ( 82.80)
[EVAL] E: [17][19/20]	Loss 3.1054e+00 (3.1099e+00)	Acc@1  56.40 ( 53.67)	Acc@5  84.20 ( 82.77)
		 LR=0.07131738635431821 -- best acc so far 53.75000057220459
***[2023-04-24 19:22:17]*** [Post-train] [Student] EVALUATION loss = 3.109918, accuracy@1 = 53.67, accuracy@5 = 82.77, error@1 = 46.33, error@5 = 17.23
[TRAIN] E: [18][  0/100]	Loss 8.3387e-08 (8.3387e-08)	Acc@1  42.40 ( 42.40)	Acc@5  73.40 ( 73.40)
[TRAIN] E: [18][ 99/100]	Loss 2.7388e-07 (1.3932e-07)	Acc@1  44.20 ( 42.90)	Acc@5  72.80 ( 72.74)
[EVAL] E: [18][ 0/20]	Loss 3.2052e+00 (3.2052e+00)	Acc@1  56.40 ( 56.40)	Acc@5  82.80 ( 82.80)
[EVAL] E: [18][19/20]	Loss 3.1892e+00 (3.1932e+00)	Acc@1  56.20 ( 53.56)	Acc@5  84.20 ( 82.84)
		 LR=0.06843543378884386 -- best acc so far 53.75000057220459
***[2023-04-24 19:23:16]*** [Post-train] [Student] EVALUATION loss = 3.193203, accuracy@1 = 53.56, accuracy@5 = 82.84, error@1 = 46.44, error@5 = 17.16
[TRAIN] E: [19][  0/100]	Loss 7.6175e-08 (7.6175e-08)	Acc@1  40.00 ( 40.00)	Acc@5  70.40 ( 70.40)
[TRAIN] E: [19][ 99/100]	Loss 1.7905e-07 (1.3443e-07)	Acc@1  42.60 ( 42.91)	Acc@5  74.40 ( 72.76)
[EVAL] E: [19][ 0/20]	Loss 3.2762e+00 (3.2762e+00)	Acc@1  56.20 ( 56.20)	Acc@5  82.80 ( 82.80)
[EVAL] E: [19][19/20]	Loss 3.2609e+00 (3.2644e+00)	Acc@1  56.20 ( 53.73)	Acc@5  84.20 ( 82.75)
		 LR=0.0654807249885535 -- best acc so far 53.75000057220459
***[2023-04-24 19:24:14]*** [Post-train] [Student] EVALUATION loss = 3.264356, accuracy@1 = 53.73, accuracy@5 = 82.75, error@1 = 46.27, error@5 = 17.25
[TRAIN] E: [20][  0/100]	Loss 9.5129e-08 (9.5129e-08)	Acc@1  44.40 ( 44.40)	Acc@5  74.20 ( 74.20)
[TRAIN] E: [20][ 99/100]	Loss 1.5283e-07 (1.4019e-07)	Acc@1  47.80 ( 42.88)	Acc@5  74.20 ( 73.00)
[EVAL] E: [20][ 0/20]	Loss 3.3528e+00 (3.3528e+00)	Acc@1  56.00 ( 56.00)	Acc@5  82.60 ( 82.60)
[EVAL] E: [20][19/20]	Loss 3.3368e+00 (3.3407e+00)	Acc@1  56.20 ( 53.55)	Acc@5  84.40 ( 82.75)
		 LR=0.0624649208392038 -- best acc so far 53.75000057220459
***[2023-04-24 19:25:13]*** [Post-train] [Student] EVALUATION loss = 3.340663, accuracy@1 = 53.55, accuracy@5 = 82.75, error@1 = 46.45, error@5 = 17.25
[TRAIN] E: [21][  0/100]	Loss 1.4412e-07 (1.4412e-07)	Acc@1  45.00 ( 45.00)	Acc@5  76.60 ( 76.60)
[TRAIN] E: [21][ 99/100]	Loss 1.1182e-07 (1.1541e-07)	Acc@1  43.80 ( 42.55)	Acc@5  73.40 ( 72.65)
[EVAL] E: [21][ 0/20]	Loss 3.4177e+00 (3.4177e+00)	Acc@1  56.00 ( 56.00)	Acc@5  82.60 ( 82.60)
[EVAL] E: [21][19/20]	Loss 3.4023e+00 (3.4059e+00)	Acc@1  55.80 ( 53.68)	Acc@5  84.00 ( 82.69)
		 LR=0.059399923341982436 -- best acc so far 53.75000057220459
***[2023-04-24 19:26:11]*** [Post-train] [Student] EVALUATION loss = 3.405891, accuracy@1 = 53.68, accuracy@5 = 82.69, error@1 = 46.32, error@5 = 17.31
[TRAIN] E: [22][  0/100]	Loss 7.8201e-08 (7.8201e-08)	Acc@1  43.40 ( 43.40)	Acc@5  73.80 ( 73.80)
[TRAIN] E: [22][ 99/100]	Loss 1.8394e-07 (1.5418e-07)	Acc@1  40.00 ( 42.75)	Acc@5  75.60 ( 72.53)
[EVAL] E: [22][ 0/20]	Loss 3.4723e+00 (3.4723e+00)	Acc@1  55.80 ( 55.80)	Acc@5  83.00 ( 83.00)
[EVAL] E: [22][19/20]	Loss 3.4578e+00 (3.4605e+00)	Acc@1  56.40 ( 53.56)	Acc@5  84.20 ( 82.80)
		 LR=0.05629782864174672 -- best acc so far 53.75000057220459
***[2023-04-24 19:27:13]*** [Post-train] [Student] EVALUATION loss = 3.460547, accuracy@1 = 53.56, accuracy@5 = 82.80, error@1 = 46.44, error@5 = 17.20
[TRAIN] E: [23][  0/100]	Loss 1.6916e-07 (1.6916e-07)	Acc@1  41.60 ( 41.60)	Acc@5  72.00 ( 72.00)
[TRAIN] E: [23][ 99/100]	Loss 1.3185e-07 (1.2980e-07)	Acc@1  43.00 ( 42.82)	Acc@5  74.80 ( 72.97)
[EVAL] E: [23][ 0/20]	Loss 3.5265e+00 (3.5265e+00)	Acc@1  55.80 ( 55.80)	Acc@5  83.40 ( 83.40)
[EVAL] E: [23][19/20]	Loss 3.5123e+00 (3.5152e+00)	Acc@1  55.20 ( 53.42)	Acc@5  84.20 ( 82.81)
		 LR=0.05317087928906627 -- best acc so far 53.75000057220459
***[2023-04-24 19:28:14]*** [Post-train] [Student] EVALUATION loss = 3.515202, accuracy@1 = 53.42, accuracy@5 = 82.81, error@1 = 46.58, error@5 = 17.19
[TRAIN] E: [24][  0/100]	Loss 1.1849e-07 (1.1849e-07)	Acc@1  43.80 ( 43.80)	Acc@5  72.00 ( 72.00)
[TRAIN] E: [24][ 99/100]	Loss 2.4867e-07 (1.3518e-07)	Acc@1  44.80 ( 42.87)	Acc@5  71.80 ( 72.70)
[EVAL] E: [24][ 0/20]	Loss 3.5749e+00 (3.5749e+00)	Acc@1  56.00 ( 56.00)	Acc@5  83.00 ( 83.00)
[EVAL] E: [24][19/20]	Loss 3.5604e+00 (3.5636e+00)	Acc@1  56.00 ( 53.58)	Acc@5  84.20 ( 82.77)
		 LR=0.05003141592446882 -- best acc so far 53.75000057220459
***[2023-04-24 19:29:11]*** [Post-train] [Student] EVALUATION loss = 3.563631, accuracy@1 = 53.58, accuracy@5 = 82.77, error@1 = 46.42, error@5 = 17.23
[TRAIN] E: [25][  0/100]	Loss 1.2040e-07 (1.2040e-07)	Acc@1  39.60 ( 39.60)	Acc@5  67.60 ( 67.60)
[TRAIN] E: [25][ 99/100]	Loss 1.8358e-07 (1.3669e-07)	Acc@1  38.60 ( 42.79)	Acc@5  70.60 ( 72.79)
[EVAL] E: [25][ 0/20]	Loss 3.6170e+00 (3.6170e+00)	Acc@1  56.20 ( 56.20)	Acc@5  83.00 ( 83.00)
[EVAL] E: [25][19/20]	Loss 3.6030e+00 (3.6061e+00)	Acc@1  55.60 ( 53.63)	Acc@5  84.20 ( 82.76)
		 LR=0.04689182857557008 -- best acc so far 53.75000057220459
***[2023-04-24 19:30:09]*** [Post-train] [Student] EVALUATION loss = 3.606124, accuracy@1 = 53.63, accuracy@5 = 82.76, error@1 = 46.37, error@5 = 17.24
[TRAIN] E: [26][  0/100]	Loss 1.1110e-07 (1.1110e-07)	Acc@1  44.20 ( 44.20)	Acc@5  72.80 ( 72.80)
[TRAIN] E: [26][ 99/100]	Loss 7.0691e-08 (1.3310e-07)	Acc@1  38.60 ( 42.68)	Acc@5  70.80 ( 72.54)
[EVAL] E: [26][ 0/20]	Loss 3.6600e+00 (3.6600e+00)	Acc@1  56.40 ( 56.40)	Acc@5  82.40 ( 82.40)
[EVAL] E: [26][19/20]	Loss 3.6466e+00 (3.6493e+00)	Acc@1  55.60 ( 53.60)	Acc@5  84.20 ( 82.72)
		 LR=0.04376450775929509 -- best acc so far 53.75000057220459
***[2023-04-24 19:31:09]*** [Post-train] [Student] EVALUATION loss = 3.649291, accuracy@1 = 53.60, accuracy@5 = 82.72, error@1 = 46.40, error@5 = 17.28
[TRAIN] E: [27][  0/100]	Loss 1.2875e-07 (1.2875e-07)	Acc@1  46.20 ( 46.20)	Acc@5  75.40 ( 75.40)
[TRAIN] E: [27][ 99/100]	Loss 1.1444e-07 (1.4568e-07)	Acc@1  38.00 ( 42.67)	Acc@5  71.00 ( 72.57)
[EVAL] E: [27][ 0/20]	Loss 3.6963e+00 (3.6963e+00)	Acc@1  56.40 ( 56.40)	Acc@5  82.60 ( 82.60)
[EVAL] E: [27][19/20]	Loss 3.6827e+00 (3.6854e+00)	Acc@1  55.20 ( 53.63)	Acc@5  84.60 ( 82.73)
		 LR=0.04066179558216874 -- best acc so far 53.75000057220459
***[2023-04-24 19:32:09]*** [Post-train] [Student] EVALUATION loss = 3.685380, accuracy@1 = 53.63, accuracy@5 = 82.73, error@1 = 46.37, error@5 = 17.27
[TRAIN] E: [28][  0/100]	Loss 2.0349e-07 (2.0349e-07)	Acc@1  41.60 ( 41.60)	Acc@5  73.80 ( 73.80)
[TRAIN] E: [28][ 99/100]	Loss 1.2720e-07 (1.5094e-07)	Acc@1  40.00 ( 42.58)	Acc@5  71.00 ( 72.61)
[EVAL] E: [28][ 0/20]	Loss 3.7260e+00 (3.7260e+00)	Acc@1  55.80 ( 55.80)	Acc@5  82.60 ( 82.60)
[EVAL] E: [28][19/20]	Loss 3.7133e+00 (3.7156e+00)	Acc@1  56.00 ( 53.69)	Acc@5  84.20 ( 82.78)
		 LR=0.037595937031659775 -- best acc so far 53.75000057220459
***[2023-04-24 19:33:07]*** [Post-train] [Student] EVALUATION loss = 3.715581, accuracy@1 = 53.69, accuracy@5 = 82.78, error@1 = 46.31, error@5 = 17.22
[TRAIN] E: [29][  0/100]	Loss 1.7691e-07 (1.7691e-07)	Acc@1  39.80 ( 39.80)	Acc@5  71.60 ( 71.60)
[TRAIN] E: [29][ 99/100]	Loss 3.9339e-08 (1.2520e-07)	Acc@1  39.80 ( 42.50)	Acc@5  73.60 ( 72.46)
[EVAL] E: [29][ 0/20]	Loss 3.7571e+00 (3.7571e+00)	Acc@1  55.80 ( 55.80)	Acc@5  82.80 ( 82.80)
[EVAL] E: [29][19/20]	Loss 3.7449e+00 (3.7470e+00)	Acc@1  55.40 ( 53.48)	Acc@5  84.20 ( 82.69)
		 LR=0.03457903165080953 -- best acc so far 53.75000057220459
***[2023-04-24 19:34:06]*** [Post-train] [Student] EVALUATION loss = 3.747050, accuracy@1 = 53.48, accuracy@5 = 82.69, error@1 = 46.52, error@5 = 17.31
[TRAIN] E: [30][  0/100]	Loss 1.6105e-07 (1.6105e-07)	Acc@1  43.00 ( 43.00)	Acc@5  73.80 ( 73.80)
[TRAIN] E: [30][ 99/100]	Loss 1.9693e-07 (1.4072e-07)	Acc@1  40.60 ( 42.81)	Acc@5  74.60 ( 72.56)
[EVAL] E: [30][ 0/20]	Loss 3.7842e+00 (3.7842e+00)	Acc@1  56.00 ( 56.00)	Acc@5  82.60 ( 82.60)
[EVAL] E: [30][19/20]	Loss 3.7722e+00 (3.7742e+00)	Acc@1  55.40 ( 53.47)	Acc@5  84.20 ( 82.72)
		 LR=0.031622985786863234 -- best acc so far 53.75000057220459
***[2023-04-24 19:35:03]*** [Post-train] [Student] EVALUATION loss = 3.774162, accuracy@1 = 53.47, accuracy@5 = 82.72, error@1 = 46.53, error@5 = 17.28
[TRAIN] E: [31][  0/100]	Loss 6.6638e-08 (6.6638e-08)	Acc@1  48.40 ( 48.40)	Acc@5  73.80 ( 73.80)
[TRAIN] E: [31][ 99/100]	Loss 1.3936e-07 (1.3061e-07)	Acc@1  43.80 ( 42.81)	Acc@5  71.80 ( 72.80)
[EVAL] E: [31][ 0/20]	Loss 3.8073e+00 (3.8073e+00)	Acc@1  55.80 ( 55.80)	Acc@5  82.60 ( 82.60)
[EVAL] E: [31][19/20]	Loss 3.7955e+00 (3.7977e+00)	Acc@1  55.20 ( 53.53)	Acc@5  84.20 ( 82.70)
		 LR=0.028739465602357014 -- best acc so far 53.75000057220459
***[2023-04-24 19:36:00]*** [Post-train] [Student] EVALUATION loss = 3.797685, accuracy@1 = 53.53, accuracy@5 = 82.70, error@1 = 46.47, error@5 = 17.30
[TRAIN] E: [32][  0/100]	Loss -3.5763e-09 (-3.5763e-09)	Acc@1  41.20 ( 41.20)	Acc@5  70.20 ( 70.20)
[TRAIN] E: [32][ 99/100]	Loss 2.0742e-07 (1.3493e-07)	Acc@1  41.00 ( 42.51)	Acc@5  70.40 ( 72.61)
[EVAL] E: [32][ 0/20]	Loss 3.8265e+00 (3.8265e+00)	Acc@1  55.60 ( 55.60)	Acc@5  82.40 ( 82.40)
[EVAL] E: [32][19/20]	Loss 3.8158e+00 (3.8172e+00)	Acc@1  55.80 ( 53.57)	Acc@5  84.20 ( 82.71)
		 LR=0.025939851034104035 -- best acc so far 53.75000057220459
***[2023-04-24 19:36:59]*** [Post-train] [Student] EVALUATION loss = 3.817167, accuracy@1 = 53.57, accuracy@5 = 82.71, error@1 = 46.43, error@5 = 17.29
[TRAIN] E: [33][  0/100]	Loss 1.5461e-07 (1.5461e-07)	Acc@1  41.60 ( 41.60)	Acc@5  71.40 ( 71.40)
[TRAIN] E: [33][ 99/100]	Loss 1.5759e-07 (1.3600e-07)	Acc@1  47.40 ( 42.84)	Acc@5  77.60 ( 72.61)
[EVAL] E: [33][ 0/20]	Loss 3.8443e+00 (3.8443e+00)	Acc@1  55.60 ( 55.60)	Acc@5  82.60 ( 82.60)
[EVAL] E: [33][19/20]	Loss 3.8330e+00 (3.8349e+00)	Acc@1  55.20 ( 53.48)	Acc@5  84.40 ( 82.70)
		 LR=0.023235190881782965 -- best acc so far 53.75000057220459
***[2023-04-24 19:38:01]*** [Post-train] [Student] EVALUATION loss = 3.834939, accuracy@1 = 53.48, accuracy@5 = 82.70, error@1 = 46.52, error@5 = 17.30
[TRAIN] E: [34][  0/100]	Loss 3.1805e-07 (3.1805e-07)	Acc@1  44.40 ( 44.40)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [34][ 99/100]	Loss 1.5926e-07 (1.4324e-07)	Acc@1  39.60 ( 42.77)	Acc@5  70.00 ( 72.52)
[EVAL] E: [34][ 0/20]	Loss 3.8617e+00 (3.8617e+00)	Acc@1  55.40 ( 55.40)	Acc@5  82.60 ( 82.60)
[EVAL] E: [34][19/20]	Loss 3.8511e+00 (3.8526e+00)	Acc@1  55.40 ( 53.50)	Acc@5  84.20 ( 82.71)
		 LR=0.02063615920337333 -- best acc so far 53.75000057220459
***[2023-04-24 19:38:57]*** [Post-train] [Student] EVALUATION loss = 3.852617, accuracy@1 = 53.50, accuracy@5 = 82.71, error@1 = 46.50, error@5 = 17.29
[TRAIN] E: [35][  0/100]	Loss 1.9562e-07 (1.9562e-07)	Acc@1  42.40 ( 42.40)	Acc@5  72.00 ( 72.00)
[TRAIN] E: [35][ 99/100]	Loss 2.1720e-07 (1.1915e-07)	Acc@1  43.80 ( 42.46)	Acc@5  73.80 ( 72.52)
[EVAL] E: [35][ 0/20]	Loss 3.8765e+00 (3.8765e+00)	Acc@1  55.80 ( 55.80)	Acc@5  82.60 ( 82.60)
[EVAL] E: [35][19/20]	Loss 3.8658e+00 (3.8676e+00)	Acc@1  55.20 ( 53.55)	Acc@5  83.80 ( 82.57)
		 LR=0.018153013189525176 -- best acc so far 53.75000057220459
***[2023-04-24 19:39:58]*** [Post-train] [Student] EVALUATION loss = 3.867600, accuracy@1 = 53.55, accuracy@5 = 82.57, error@1 = 46.45, error@5 = 17.43
[TRAIN] E: [36][  0/100]	Loss 2.2638e-07 (2.2638e-07)	Acc@1  46.80 ( 46.80)	Acc@5  72.40 ( 72.40)
[TRAIN] E: [36][ 99/100]	Loss 3.4690e-07 (1.2937e-07)	Acc@1  44.60 ( 42.67)	Acc@5  71.80 ( 72.58)
[EVAL] E: [36][ 0/20]	Loss 3.8883e+00 (3.8883e+00)	Acc@1  55.80 ( 55.80)	Acc@5  82.40 ( 82.40)
[EVAL] E: [36][19/20]	Loss 3.8777e+00 (3.8794e+00)	Acc@1  54.60 ( 53.38)	Acc@5  84.00 ( 82.55)
		 LR=0.015795552683113678 -- best acc so far 53.75000057220459
***[2023-04-24 19:40:57]*** [Post-train] [Student] EVALUATION loss = 3.879402, accuracy@1 = 53.38, accuracy@5 = 82.55, error@1 = 46.62, error@5 = 17.45
[TRAIN] E: [37][  0/100]	Loss 3.4928e-08 (3.4928e-08)	Acc@1  42.80 ( 42.80)	Acc@5  72.60 ( 72.60)
[TRAIN] E: [37][ 99/100]	Loss 4.9233e-08 (1.1973e-07)	Acc@1  42.60 ( 42.70)	Acc@5  73.20 ( 72.46)
[EVAL] E: [37][ 0/20]	Loss 3.8992e+00 (3.8992e+00)	Acc@1  56.00 ( 56.00)	Acc@5  82.80 ( 82.80)
[EVAL] E: [37][19/20]	Loss 3.8889e+00 (3.8904e+00)	Acc@1  55.60 ( 53.54)	Acc@5  84.20 ( 82.65)
		 LR=0.013573081503736362 -- best acc so far 53.75000057220459
***[2023-04-24 19:41:56]*** [Post-train] [Student] EVALUATION loss = 3.890394, accuracy@1 = 53.54, accuracy@5 = 82.65, error@1 = 46.46, error@5 = 17.35
[TRAIN] E: [38][  0/100]	Loss 9.8348e-08 (9.8348e-08)	Acc@1  45.00 ( 45.00)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [38][ 99/100]	Loss 4.8161e-08 (1.2992e-07)	Acc@1  43.80 ( 42.86)	Acc@5  74.20 ( 72.61)
[EVAL] E: [38][ 0/20]	Loss 3.9063e+00 (3.9063e+00)	Acc@1  55.80 ( 55.80)	Acc@5  82.80 ( 82.80)
[EVAL] E: [38][19/20]	Loss 3.8961e+00 (3.8975e+00)	Acc@1  55.00 ( 53.58)	Acc@5  84.00 ( 82.75)
		 LR=0.011494370729787729 -- best acc so far 53.75000057220459
***[2023-04-24 19:42:54]*** [Post-train] [Student] EVALUATION loss = 3.897520, accuracy@1 = 53.58, accuracy@5 = 82.75, error@1 = 46.42, error@5 = 17.25
[TRAIN] E: [39][  0/100]	Loss 1.4555e-07 (1.4555e-07)	Acc@1  44.40 ( 44.40)	Acc@5  72.80 ( 72.80)
[TRAIN] E: [39][ 99/100]	Loss 9.0837e-08 (1.2685e-07)	Acc@1  43.80 ( 42.41)	Acc@5  70.20 ( 72.37)
[EVAL] E: [39][ 0/20]	Loss 3.9158e+00 (3.9158e+00)	Acc@1  56.00 ( 56.00)	Acc@5  82.60 ( 82.60)
[EVAL] E: [39][19/20]	Loss 3.9056e+00 (3.9071e+00)	Acc@1  55.20 ( 53.57)	Acc@5  83.80 ( 82.72)
		 LR=0.009567624083019949 -- best acc so far 53.75000057220459
***[2023-04-24 19:43:53]*** [Post-train] [Student] EVALUATION loss = 3.907102, accuracy@1 = 53.57, accuracy@5 = 82.72, error@1 = 46.43, error@5 = 17.28
[TRAIN] E: [40][  0/100]	Loss 1.1003e-07 (1.1003e-07)	Acc@1  44.20 ( 44.20)	Acc@5  70.60 ( 70.60)
[TRAIN] E: [40][ 99/100]	Loss 2.1136e-07 (1.2204e-07)	Acc@1  37.20 ( 42.52)	Acc@5  66.80 ( 72.36)
[EVAL] E: [40][ 0/20]	Loss 3.9188e+00 (3.9188e+00)	Acc@1  55.60 ( 55.60)	Acc@5  82.60 ( 82.60)
[EVAL] E: [40][19/20]	Loss 3.9089e+00 (3.9104e+00)	Acc@1  55.20 ( 53.51)	Acc@5  84.00 ( 82.64)
		 LR=0.007800445552201014 -- best acc so far 53.75000057220459
***[2023-04-24 19:44:54]*** [Post-train] [Student] EVALUATION loss = 3.910422, accuracy@1 = 53.51, accuracy@5 = 82.64, error@1 = 46.49, error@5 = 17.36
[TRAIN] E: [41][  0/100]	Loss 1.8001e-07 (1.8001e-07)	Acc@1  41.20 ( 41.20)	Acc@5  71.40 ( 71.40)
