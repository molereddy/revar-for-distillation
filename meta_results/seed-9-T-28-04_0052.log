Main Function with logger : Logger(dir=meta_results, use-tf=False, writer=None)
Arguments : -------------------------------
batch_size       : 1600
class_num        : 100
cutout_length    : 16
data_path        : /home/prathamesh/code/data/cifar/
dataset          : cifar100
epochs           : 200
eval_batch_size  : 1600
global_rand_seed : -1
input_size       : 32
inst_based       : True
label            : 
loss_kd_frac     : 0.5
lr               : 0.1
mcd_weight       : 0.1
meta_interval    : 1
meta_lr          : 0.01
meta_weight_decay : 0.0
model_name       : ResNet10_s
momentum         : 0.9
pretrained_student : True
print_freq       : 100
print_freq_eval  : 100
rand_seed        : 9
save_dir         : ./meta_results/
temperature      : 2
unsup_adapt      : False
wd               : 0.0005
workers          : 8
Python  Version  : 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0]
Pillow  Version  : 9.2.0
PyTorch Version  : 1.13.1
cuDNN   Version  : 8500
CUDA available   : True
CUDA GPU numbers : 1
CUDA_VISIBLE_DEVICES : 0
Namespace(batch_size=1600, class_num=100, cutout_length=16, data_path='/home/prathamesh/code/data/cifar/', dataset='cifar100', epochs=200, eval_batch_size=1600, global_rand_seed=-1, input_size=32, inst_based=True, label='', loss_kd_frac=0.5, lr=0.1, mcd_weight=0.1, meta_interval=1, meta_lr=0.01, meta_weight_decay=0.0, model_name='ResNet10_s', momentum=0.9, pretrained_student=True, print_freq=100, print_freq_eval=100, rand_seed=9, save_dir='./meta_results/', temperature=2, unsup_adapt=False, wd=0.0005, workers=8)
Train:50000	, Valid:5000	, Test:5000

--------------------------------------------------
using pretrained student model from /home/anmolreddy/pretrained/disk-CE-cifar100-ResNet10_s-model_best.pth.tar
***[2023-04-27 19:22:13]*** [Teacher] Test loss = 0.912514, accuracy@1 = 73.70, accuracy@5 = 93.74, error@1 = 26.30, error@5 = 6.26
model information : EfficientNetV2_s (CIFAR)
--------------------------------------------------
[Student]Params=0.08 MB, FLOPs=4.16 M ... = 0.00 G
[TRAIN] E: [0][ 0/32]	Loss 5.4561e-03 (5.4561e-03)	Acc@1  41.31 ( 41.31)	Acc@5  72.56 ( 72.56)
[TRAIN] E: [0][31/32]	Loss 0.0000e+00 (5.5915e-04)	Acc@1  41.00 ( 42.99)	Acc@5  73.50 ( 72.80)
[EVAL] E: [0][0/4]	Loss 1.6640e+00 (1.6640e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.56 ( 83.56)
[EVAL] E: [0][3/4]	Loss 1.7036e+00 (1.6721e+00)	Acc@1  51.50 ( 53.22)	Acc@5  83.00 ( 83.34)
		 Test evaluation at end of epoch: latest_acc:53.22 LR=0.09381533400219318 -- best acc so far 53.22
Training epoch
[TRAIN] E: [1][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.31 ( 43.31)	Acc@5  73.88 ( 73.88)
[TRAIN] E: [1][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 43.09)	Acc@5  73.50 ( 73.18)
[EVAL] E: [1][0/4]	Loss 1.6620e+00 (1.6620e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.62 ( 83.62)
[EVAL] E: [1][3/4]	Loss 1.7006e+00 (1.6704e+00)	Acc@1  52.00 ( 53.14)	Acc@5  83.00 ( 83.30)
		 Test evaluation at end of epoch: latest_acc:53.14 LR=0.07679133974894983 -- best acc so far 53.22
Training epoch
[TRAIN] E: [2][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.12 ( 44.12)	Acc@5  73.75 ( 73.75)
[TRAIN] E: [2][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.75 ( 43.23)	Acc@5  72.75 ( 73.01)
[EVAL] E: [2][0/4]	Loss 1.6595e+00 (1.6595e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.62 ( 83.62)
[EVAL] E: [2][3/4]	Loss 1.7039e+00 (1.6680e+00)	Acc@1  52.00 ( 53.22)	Acc@5  83.00 ( 83.36)
		 Test evaluation at end of epoch: latest_acc:53.22 LR=0.05313952597646568 -- best acc so far 53.22
Training epoch
[TRAIN] E: [3][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.12 ( 43.12)	Acc@5  72.44 ( 72.44)
[TRAIN] E: [3][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.75 ( 42.82)	Acc@5  72.00 ( 72.90)
[EVAL] E: [3][0/4]	Loss 1.6578e+00 (1.6578e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.44 ( 83.44)
[EVAL] E: [3][3/4]	Loss 1.7054e+00 (1.6656e+00)	Acc@1  52.00 ( 53.32)	Acc@5  82.50 ( 83.32)
		 Test evaluation at end of epoch: latest_acc:53.32 LR=0.02871103542174637 -- best acc so far 53.32
Training epoch
[TRAIN] E: [4][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.00 ( 44.00)	Acc@5  74.56 ( 74.56)
[TRAIN] E: [4][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.00 ( 43.16)	Acc@5  74.75 ( 73.10)
[EVAL] E: [4][0/4]	Loss 1.6581e+00 (1.6581e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.62 ( 83.62)
[EVAL] E: [4][3/4]	Loss 1.7073e+00 (1.6658e+00)	Acc@1  52.00 ( 53.32)	Acc@5  82.50 ( 83.26)
		 Test evaluation at end of epoch: latest_acc:53.32 LR=0.009549150281252633 -- best acc so far 53.32
Training epoch
[TRAIN] E: [5][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.62 ( 44.62)	Acc@5  74.00 ( 74.00)
[TRAIN] E: [5][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  47.25 ( 43.00)	Acc@5  73.75 ( 73.03)
[EVAL] E: [5][0/4]	Loss 1.6584e+00 (1.6584e+00)	Acc@1  52.50 ( 52.50)	Acc@5  83.69 ( 83.69)
[EVAL] E: [5][3/4]	Loss 1.7099e+00 (1.6653e+00)	Acc@1  52.50 ( 53.52)	Acc@5  82.50 ( 83.38)
		 Test evaluation at end of epoch: latest_acc:53.52 LR=0.0003942649342761118 -- best acc so far 53.52
Training epoch
[TRAIN] E: [6][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.75 ( 39.75)	Acc@5  72.25 ( 72.25)
[TRAIN] E: [6][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.25 ( 43.03)	Acc@5  71.00 ( 73.13)
[EVAL] E: [6][0/4]	Loss 1.6664e+00 (1.6664e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.69 ( 83.69)
[EVAL] E: [6][3/4]	Loss 1.7050e+00 (1.6755e+00)	Acc@1  52.50 ( 52.98)	Acc@5  83.50 ( 83.36)
		 Test evaluation at end of epoch: latest_acc:52.98 LR=0.09648882429441258 -- best acc so far 53.52
Training epoch
[TRAIN] E: [7][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.88 ( 44.88)	Acc@5  74.94 ( 74.94)
[TRAIN] E: [7][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.00 ( 43.32)	Acc@5  72.75 ( 73.12)
[EVAL] E: [7][0/4]	Loss 1.6680e+00 (1.6680e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.75 ( 83.75)
[EVAL] E: [7][3/4]	Loss 1.7084e+00 (1.6780e+00)	Acc@1  52.50 ( 53.20)	Acc@5  83.00 ( 83.38)
		 Test evaluation at end of epoch: latest_acc:53.2 LR=0.08187119948743449 -- best acc so far 53.52
Training epoch
[TRAIN] E: [8][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.75 ( 42.75)	Acc@5  72.56 ( 72.56)
[TRAIN] E: [8][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.25 ( 42.98)	Acc@5  70.25 ( 72.83)
[EVAL] E: [8][0/4]	Loss 1.6694e+00 (1.6694e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.38 ( 83.38)
[EVAL] E: [8][3/4]	Loss 1.7109e+00 (1.6796e+00)	Acc@1  52.50 ( 53.14)	Acc@5  83.00 ( 83.28)
		 Test evaluation at end of epoch: latest_acc:53.14 LR=0.05936906572928624 -- best acc so far 53.52
Training epoch
[TRAIN] E: [9][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.06 ( 42.06)	Acc@5  72.06 ( 72.06)
[TRAIN] E: [9][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 43.03)	Acc@5  70.50 ( 72.72)
[EVAL] E: [9][0/4]	Loss 1.6681e+00 (1.6681e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.56 ( 83.56)
[EVAL] E: [9][3/4]	Loss 1.7145e+00 (1.6777e+00)	Acc@1  52.50 ( 53.38)	Acc@5  82.50 ( 83.42)
		 Test evaluation at end of epoch: latest_acc:53.38 LR=0.03454915028125265 -- best acc so far 53.52
Training epoch
[TRAIN] E: [10][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.75 ( 41.75)	Acc@5  72.88 ( 72.88)
[TRAIN] E: [10][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.00 ( 42.72)	Acc@5  72.50 ( 72.75)
[EVAL] E: [10][0/4]	Loss 1.6680e+00 (1.6680e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.50 ( 83.50)
[EVAL] E: [10][3/4]	Loss 1.7152e+00 (1.6769e+00)	Acc@1  53.00 ( 53.50)	Acc@5  82.50 ( 83.28)
		 Test evaluation at end of epoch: latest_acc:53.5 LR=0.013551568628929435 -- best acc so far 53.52
Training epoch
[TRAIN] E: [11][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.94 ( 41.94)	Acc@5  71.69 ( 71.69)
[TRAIN] E: [11][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.50 ( 43.06)	Acc@5  71.50 ( 72.85)
[EVAL] E: [11][0/4]	Loss 1.6674e+00 (1.6674e+00)	Acc@1  52.44 ( 52.44)	Acc@5  83.44 ( 83.44)
[EVAL] E: [11][3/4]	Loss 1.7179e+00 (1.6765e+00)	Acc@1  53.00 ( 53.54)	Acc@5  83.00 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.54 LR=0.0015708419435684518 -- best acc so far 53.54
Training epoch
[TRAIN] E: [12][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.50 ( 43.50)	Acc@5  72.38 ( 72.38)
[TRAIN] E: [12][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.75 ( 43.05)	Acc@5  69.25 ( 72.84)
[EVAL] E: [12][0/4]	Loss 1.6777e+00 (1.6777e+00)	Acc@1  51.88 ( 51.88)	Acc@5  83.62 ( 83.62)
[EVAL] E: [12][3/4]	Loss 1.7188e+00 (1.6886e+00)	Acc@1  52.50 ( 53.16)	Acc@5  83.50 ( 83.36)
		 Test evaluation at end of epoch: latest_acc:53.16 LR=0.09842915805643156 -- best acc so far 53.54
Training epoch
[TRAIN] E: [13][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.69 ( 41.69)	Acc@5  71.31 ( 71.31)
[TRAIN] E: [13][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.75 ( 42.85)	Acc@5  73.00 ( 72.59)
[EVAL] E: [13][0/4]	Loss 1.6888e+00 (1.6888e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.56 ( 83.56)
[EVAL] E: [13][3/4]	Loss 1.7310e+00 (1.7005e+00)	Acc@1  52.50 ( 53.20)	Acc@5  83.00 ( 83.18)
		 Test evaluation at end of epoch: latest_acc:53.2 LR=0.08644843137107058 -- best acc so far 53.54
Training epoch
[TRAIN] E: [14][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.69 ( 43.69)	Acc@5  73.56 ( 73.56)
[TRAIN] E: [14][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.25 ( 42.93)	Acc@5  72.50 ( 72.94)
[EVAL] E: [14][0/4]	Loss 1.6928e+00 (1.6928e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.50 ( 83.50)
[EVAL] E: [14][3/4]	Loss 1.7349e+00 (1.7040e+00)	Acc@1  52.50 ( 53.22)	Acc@5  83.00 ( 83.22)
		 Test evaluation at end of epoch: latest_acc:53.22 LR=0.06545084971874737 -- best acc so far 53.54
Training epoch
[TRAIN] E: [15][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.69 ( 42.69)	Acc@5  74.25 ( 74.25)
[TRAIN] E: [15][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.50 ( 43.15)	Acc@5  76.00 ( 73.10)
[EVAL] E: [15][0/4]	Loss 1.6949e+00 (1.6949e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.62 ( 83.62)
[EVAL] E: [15][3/4]	Loss 1.7409e+00 (1.7066e+00)	Acc@1  52.50 ( 53.34)	Acc@5  83.00 ( 83.52)
		 Test evaluation at end of epoch: latest_acc:53.34 LR=0.04063093427071377 -- best acc so far 53.54
Training epoch
[TRAIN] E: [16][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 43.25)	Acc@5  73.31 ( 73.31)
[TRAIN] E: [16][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 43.24)	Acc@5  76.75 ( 73.19)
[EVAL] E: [16][0/4]	Loss 1.6958e+00 (1.6958e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.56 ( 83.56)
[EVAL] E: [16][3/4]	Loss 1.7445e+00 (1.7068e+00)	Acc@1  53.00 ( 53.46)	Acc@5  83.00 ( 83.30)
		 Test evaluation at end of epoch: latest_acc:53.46 LR=0.018128800512565515 -- best acc so far 53.54
Training epoch
[TRAIN] E: [17][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.38 ( 43.38)	Acc@5  72.00 ( 72.00)
[TRAIN] E: [17][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.25 ( 42.81)	Acc@5  69.00 ( 72.61)
[EVAL] E: [17][0/4]	Loss 1.6948e+00 (1.6948e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.44 ( 83.44)
[EVAL] E: [17][3/4]	Loss 1.7458e+00 (1.7060e+00)	Acc@1  53.00 ( 53.52)	Acc@5  83.00 ( 83.28)
		 Test evaluation at end of epoch: latest_acc:53.52 LR=0.0035111757055874327 -- best acc so far 53.54
Training epoch
[TRAIN] E: [18][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.75)	Acc@5  73.50 ( 73.50)
[TRAIN] E: [18][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 43.17)	Acc@5  74.00 ( 72.96)
[EVAL] E: [18][0/4]	Loss 1.7035e+00 (1.7035e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.19 ( 83.19)
[EVAL] E: [18][3/4]	Loss 1.7503e+00 (1.7158e+00)	Acc@1  51.50 ( 53.24)	Acc@5  84.00 ( 83.32)
		 Test evaluation at end of epoch: latest_acc:53.24 LR=0.0996057350657239 -- best acc so far 53.54
Training epoch
[TRAIN] E: [19][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.75 ( 40.75)	Acc@5  72.94 ( 72.94)
[TRAIN] E: [19][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.75 ( 43.21)	Acc@5  71.25 ( 73.08)
[EVAL] E: [19][0/4]	Loss 1.7214e+00 (1.7214e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.81 ( 83.81)
[EVAL] E: [19][3/4]	Loss 1.7628e+00 (1.7349e+00)	Acc@1  52.50 ( 53.26)	Acc@5  83.00 ( 83.40)
		 Test evaluation at end of epoch: latest_acc:53.26 LR=0.09045084971874738 -- best acc so far 53.54
Training epoch
[TRAIN] E: [20][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.88 ( 41.88)	Acc@5  72.12 ( 72.12)
[TRAIN] E: [20][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.24)	Acc@5  75.00 ( 73.03)
[EVAL] E: [20][0/4]	Loss 1.7334e+00 (1.7334e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.75 ( 83.75)
[EVAL] E: [20][3/4]	Loss 1.7768e+00 (1.7472e+00)	Acc@1  52.50 ( 53.14)	Acc@5  83.50 ( 83.46)
		 Test evaluation at end of epoch: latest_acc:53.14 LR=0.07128896457825364 -- best acc so far 53.54
Training epoch
[TRAIN] E: [21][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.31 ( 44.31)	Acc@5  73.19 ( 73.19)
[TRAIN] E: [21][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.25 ( 43.29)	Acc@5  72.75 ( 73.03)
[EVAL] E: [21][0/4]	Loss 1.7370e+00 (1.7370e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.56 ( 83.56)
[EVAL] E: [21][3/4]	Loss 1.7840e+00 (1.7506e+00)	Acc@1  52.50 ( 53.30)	Acc@5  83.50 ( 83.48)
		 Test evaluation at end of epoch: latest_acc:53.3 LR=0.04686047402353433 -- best acc so far 53.54
Training epoch
[TRAIN] E: [22][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.56 ( 42.56)	Acc@5  71.12 ( 71.12)
[TRAIN] E: [22][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.25 ( 43.26)	Acc@5  76.75 ( 73.18)
[EVAL] E: [22][0/4]	Loss 1.7407e+00 (1.7407e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.44 ( 83.44)
[EVAL] E: [22][3/4]	Loss 1.7881e+00 (1.7541e+00)	Acc@1  53.00 ( 53.38)	Acc@5  83.00 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.38 LR=0.02320866025105016 -- best acc so far 53.54
Training epoch
[TRAIN] E: [23][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.50 ( 44.50)	Acc@5  72.62 ( 72.62)
[TRAIN] E: [23][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.00 ( 43.06)	Acc@5  71.00 ( 72.97)
[EVAL] E: [23][0/4]	Loss 1.7407e+00 (1.7407e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.50 ( 83.50)
[EVAL] E: [23][3/4]	Loss 1.7913e+00 (1.7542e+00)	Acc@1  52.50 ( 53.44)	Acc@5  83.00 ( 83.26)
		 Test evaluation at end of epoch: latest_acc:53.44 LR=0.006184665997806821 -- best acc so far 53.54
Training epoch
[TRAIN] E: [24][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.44 ( 43.44)	Acc@5  74.06 ( 74.06)
[TRAIN] E: [24][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.75 ( 42.91)	Acc@5  75.50 ( 72.87)
[EVAL] E: [24][0/4]	Loss 1.7403e+00 (1.7403e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.38 ( 83.38)
[EVAL] E: [24][3/4]	Loss 1.7927e+00 (1.7536e+00)	Acc@1  53.00 ( 53.48)	Acc@5  83.00 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.48 LR=0.1 -- best acc so far 53.54
Training epoch
[TRAIN] E: [25][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.44 ( 43.44)	Acc@5  72.56 ( 72.56)
[TRAIN] E: [25][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.50 ( 43.04)	Acc@5  70.50 ( 72.99)
[EVAL] E: [25][0/4]	Loss 1.7733e+00 (1.7733e+00)	Acc@1  51.88 ( 51.88)	Acc@5  83.62 ( 83.62)
[EVAL] E: [25][3/4]	Loss 1.8159e+00 (1.7887e+00)	Acc@1  52.50 ( 53.06)	Acc@5  83.50 ( 83.34)
		 Test evaluation at end of epoch: latest_acc:53.06 LR=0.09381533400219318 -- best acc so far 53.54
Training epoch
[TRAIN] E: [26][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.44 ( 42.44)	Acc@5  71.69 ( 71.69)
[TRAIN] E: [26][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.17)	Acc@5  68.75 ( 72.91)
[EVAL] E: [26][0/4]	Loss 1.7881e+00 (1.7881e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.62 ( 83.62)
[EVAL] E: [26][3/4]	Loss 1.8319e+00 (1.8038e+00)	Acc@1  52.50 ( 53.16)	Acc@5  84.00 ( 83.40)
		 Test evaluation at end of epoch: latest_acc:53.16 LR=0.07679133974894983 -- best acc so far 53.54
Training epoch
[TRAIN] E: [27][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.62 ( 44.62)	Acc@5  72.19 ( 72.19)
[TRAIN] E: [27][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 43.24)	Acc@5  72.00 ( 73.18)
[EVAL] E: [27][0/4]	Loss 1.7970e+00 (1.7970e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.38 ( 83.38)
[EVAL] E: [27][3/4]	Loss 1.8425e+00 (1.8127e+00)	Acc@1  52.50 ( 53.32)	Acc@5  83.00 ( 83.30)
		 Test evaluation at end of epoch: latest_acc:53.32 LR=0.05313952597646568 -- best acc so far 53.54
Training epoch
[TRAIN] E: [28][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.12 ( 43.12)	Acc@5  70.75 ( 70.75)
[TRAIN] E: [28][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.25 ( 42.89)	Acc@5  70.75 ( 72.97)
[EVAL] E: [28][0/4]	Loss 1.8021e+00 (1.8021e+00)	Acc@1  52.25 ( 52.25)	Acc@5  83.44 ( 83.44)
[EVAL] E: [28][3/4]	Loss 1.8503e+00 (1.8176e+00)	Acc@1  53.00 ( 53.36)	Acc@5  83.50 ( 83.34)
		 Test evaluation at end of epoch: latest_acc:53.36 LR=0.02871103542174637 -- best acc so far 53.54
Training epoch
[TRAIN] E: [29][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.25 ( 45.25)	Acc@5  73.88 ( 73.88)
[TRAIN] E: [29][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.50 ( 43.46)	Acc@5  70.00 ( 73.00)
[EVAL] E: [29][0/4]	Loss 1.8028e+00 (1.8028e+00)	Acc@1  52.62 ( 52.62)	Acc@5  83.75 ( 83.75)
[EVAL] E: [29][3/4]	Loss 1.8533e+00 (1.8182e+00)	Acc@1  53.50 ( 53.54)	Acc@5  83.00 ( 83.48)
		 Test evaluation at end of epoch: latest_acc:53.54 LR=0.009549150281252633 -- best acc so far 53.54
Training epoch
[TRAIN] E: [30][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.19 ( 43.19)	Acc@5  72.62 ( 72.62)
[TRAIN] E: [30][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.25 ( 42.68)	Acc@5  71.25 ( 72.93)
[EVAL] E: [30][0/4]	Loss 1.8020e+00 (1.8020e+00)	Acc@1  52.44 ( 52.44)	Acc@5  83.44 ( 83.44)
[EVAL] E: [30][3/4]	Loss 1.8519e+00 (1.8169e+00)	Acc@1  53.00 ( 53.44)	Acc@5  82.50 ( 83.20)
		 Test evaluation at end of epoch: latest_acc:53.44 LR=0.0003942649342761118 -- best acc so far 53.54
Training epoch
[TRAIN] E: [31][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.00 ( 41.00)	Acc@5  71.19 ( 71.19)
[TRAIN] E: [31][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 43.30)	Acc@5  76.50 ( 72.97)
[EVAL] E: [31][0/4]	Loss 1.8353e+00 (1.8353e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.38 ( 83.38)
[EVAL] E: [31][3/4]	Loss 1.8805e+00 (1.8528e+00)	Acc@1  52.00 ( 53.12)	Acc@5  83.50 ( 83.20)
		 Test evaluation at end of epoch: latest_acc:53.12 LR=0.09648882429441258 -- best acc so far 53.54
Training epoch
[TRAIN] E: [32][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.19 ( 43.19)	Acc@5  73.69 ( 73.69)
[TRAIN] E: [32][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 43.03)	Acc@5  74.50 ( 72.91)
[EVAL] E: [32][0/4]	Loss 1.8580e+00 (1.8580e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.50 ( 83.50)
[EVAL] E: [32][3/4]	Loss 1.9029e+00 (1.8756e+00)	Acc@1  52.50 ( 53.18)	Acc@5  83.00 ( 83.30)
		 Test evaluation at end of epoch: latest_acc:53.18 LR=0.08187119948743449 -- best acc so far 53.54
Training epoch
[TRAIN] E: [33][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.19 ( 44.19)	Acc@5  74.00 ( 74.00)
[TRAIN] E: [33][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 43.30)	Acc@5  71.00 ( 73.25)
[EVAL] E: [33][0/4]	Loss 1.8699e+00 (1.8699e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.38 ( 83.38)
[EVAL] E: [33][3/4]	Loss 1.9171e+00 (1.8880e+00)	Acc@1  52.50 ( 53.20)	Acc@5  83.50 ( 83.36)
		 Test evaluation at end of epoch: latest_acc:53.2 LR=0.05936906572928624 -- best acc so far 53.54
Training epoch
[TRAIN] E: [34][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.94 ( 43.94)	Acc@5  73.56 ( 73.56)
[TRAIN] E: [34][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.75 ( 43.42)	Acc@5  73.25 ( 73.24)
[EVAL] E: [34][0/4]	Loss 1.8785e+00 (1.8785e+00)	Acc@1  51.88 ( 51.88)	Acc@5  83.31 ( 83.31)
[EVAL] E: [34][3/4]	Loss 1.9275e+00 (1.8965e+00)	Acc@1  53.00 ( 53.22)	Acc@5  83.50 ( 83.20)
		 Test evaluation at end of epoch: latest_acc:53.22 LR=0.03454915028125265 -- best acc so far 53.54
Training epoch
[TRAIN] E: [35][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.19 ( 41.19)	Acc@5  71.75 ( 71.75)
[TRAIN] E: [35][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.50 ( 43.20)	Acc@5  73.25 ( 73.18)
[EVAL] E: [35][0/4]	Loss 1.8802e+00 (1.8802e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.62 ( 83.62)
[EVAL] E: [35][3/4]	Loss 1.9310e+00 (1.8979e+00)	Acc@1  52.50 ( 53.48)	Acc@5  83.50 ( 83.32)
		 Test evaluation at end of epoch: latest_acc:53.48 LR=0.013551568628929435 -- best acc so far 53.54
Training epoch
[TRAIN] E: [36][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.12 ( 44.12)	Acc@5  74.88 ( 74.88)
[TRAIN] E: [36][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.75 ( 43.02)	Acc@5  69.25 ( 72.91)
[EVAL] E: [36][0/4]	Loss 1.8783e+00 (1.8783e+00)	Acc@1  52.56 ( 52.56)	Acc@5  83.69 ( 83.69)
[EVAL] E: [36][3/4]	Loss 1.9324e+00 (1.8962e+00)	Acc@1  52.50 ( 53.54)	Acc@5  83.00 ( 83.30)
		 Test evaluation at end of epoch: latest_acc:53.54 LR=0.0015708419435684518 -- best acc so far 53.54
Training epoch
[TRAIN] E: [37][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.25 ( 40.25)	Acc@5  72.62 ( 72.62)
[TRAIN] E: [37][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.00 ( 42.87)	Acc@5  76.00 ( 72.95)
[EVAL] E: [37][0/4]	Loss 1.9112e+00 (1.9112e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.50 ( 83.50)
[EVAL] E: [37][3/4]	Loss 1.9558e+00 (1.9298e+00)	Acc@1  52.50 ( 53.12)	Acc@5  83.50 ( 83.36)
		 Test evaluation at end of epoch: latest_acc:53.12 LR=0.09842915805643156 -- best acc so far 53.54
Training epoch
[TRAIN] E: [38][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.44 ( 43.44)	Acc@5  71.31 ( 71.31)
[TRAIN] E: [38][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.00 ( 42.78)	Acc@5  77.50 ( 72.76)
[EVAL] E: [38][0/4]	Loss 1.9400e+00 (1.9400e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.56 ( 83.56)
[EVAL] E: [38][3/4]	Loss 1.9859e+00 (1.9596e+00)	Acc@1  52.50 ( 53.14)	Acc@5  83.50 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.14 LR=0.08644843137107058 -- best acc so far 53.54
Training epoch
[TRAIN] E: [39][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.12 ( 42.12)	Acc@5  69.88 ( 69.88)
[TRAIN] E: [39][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.00 ( 43.08)	Acc@5  69.75 ( 72.81)
[EVAL] E: [39][0/4]	Loss 1.9578e+00 (1.9578e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.56 ( 83.56)
[EVAL] E: [39][3/4]	Loss 2.0034e+00 (1.9774e+00)	Acc@1  53.00 ( 53.20)	Acc@5  83.50 ( 83.34)
		 Test evaluation at end of epoch: latest_acc:53.2 LR=0.06545084971874737 -- best acc so far 53.54
Training epoch
[TRAIN] E: [40][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.56 ( 44.56)	Acc@5  74.31 ( 74.31)
[TRAIN] E: [40][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  37.00 ( 43.22)	Acc@5  66.50 ( 73.15)
[EVAL] E: [40][0/4]	Loss 1.9672e+00 (1.9672e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.19 ( 83.19)
[EVAL] E: [40][3/4]	Loss 2.0156e+00 (1.9868e+00)	Acc@1  53.00 ( 53.24)	Acc@5  84.00 ( 83.34)
		 Test evaluation at end of epoch: latest_acc:53.24 LR=0.04063093427071377 -- best acc so far 53.54
Training epoch
[TRAIN] E: [41][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.38 ( 42.38)	Acc@5  72.81 ( 72.81)
[TRAIN] E: [41][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.75 ( 43.06)	Acc@5  74.00 ( 72.86)
[EVAL] E: [41][0/4]	Loss 1.9705e+00 (1.9705e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.44 ( 83.44)
[EVAL] E: [41][3/4]	Loss 2.0207e+00 (1.9899e+00)	Acc@1  52.50 ( 53.34)	Acc@5  84.00 ( 83.28)
		 Test evaluation at end of epoch: latest_acc:53.34 LR=0.018128800512565515 -- best acc so far 53.54
Training epoch
[TRAIN] E: [42][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.19 ( 42.19)	Acc@5  73.31 ( 73.31)
[TRAIN] E: [42][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.75 ( 42.86)	Acc@5  75.00 ( 72.84)
[EVAL] E: [42][0/4]	Loss 1.9722e+00 (1.9722e+00)	Acc@1  52.56 ( 52.56)	Acc@5  83.62 ( 83.62)
[EVAL] E: [42][3/4]	Loss 2.0243e+00 (1.9918e+00)	Acc@1  53.00 ( 53.46)	Acc@5  82.50 ( 83.28)
		 Test evaluation at end of epoch: latest_acc:53.46 LR=0.0035111757055874327 -- best acc so far 53.54
Training epoch
[TRAIN] E: [43][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.56 ( 41.56)	Acc@5  71.81 ( 71.81)
[TRAIN] E: [43][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 42.98)	Acc@5  72.00 ( 72.90)
[EVAL] E: [43][0/4]	Loss 1.9907e+00 (1.9907e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.31 ( 83.31)
[EVAL] E: [43][3/4]	Loss 2.0380e+00 (2.0107e+00)	Acc@1  53.50 ( 53.32)	Acc@5  84.00 ( 83.28)
		 Test evaluation at end of epoch: latest_acc:53.32 LR=0.0996057350657239 -- best acc so far 53.54
Training epoch
[TRAIN] E: [44][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.06 ( 44.06)	Acc@5  75.56 ( 75.56)
[TRAIN] E: [44][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.00 ( 43.14)	Acc@5  71.75 ( 72.72)
[EVAL] E: [44][0/4]	Loss 2.0336e+00 (2.0336e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.62 ( 83.62)
[EVAL] E: [44][3/4]	Loss 2.0788e+00 (2.0547e+00)	Acc@1  52.50 ( 53.14)	Acc@5  84.00 ( 83.38)
		 Test evaluation at end of epoch: latest_acc:53.14 LR=0.09045084971874738 -- best acc so far 53.54
Training epoch
[TRAIN] E: [45][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.69 ( 44.69)	Acc@5  74.44 ( 74.44)
[TRAIN] E: [45][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  47.50 ( 43.23)	Acc@5  74.50 ( 72.87)
[EVAL] E: [45][0/4]	Loss 2.0556e+00 (2.0556e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.44 ( 83.44)
[EVAL] E: [45][3/4]	Loss 2.1035e+00 (2.0769e+00)	Acc@1  52.50 ( 53.28)	Acc@5  84.00 ( 83.38)
		 Test evaluation at end of epoch: latest_acc:53.28 LR=0.07128896457825364 -- best acc so far 53.54
Training epoch
[TRAIN] E: [46][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.56 ( 43.56)	Acc@5  72.25 ( 72.25)
[TRAIN] E: [46][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.45)	Acc@5  71.50 ( 73.23)
[EVAL] E: [46][0/4]	Loss 2.0685e+00 (2.0685e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.25 ( 83.25)
[EVAL] E: [46][3/4]	Loss 2.1169e+00 (2.0899e+00)	Acc@1  53.00 ( 53.28)	Acc@5  84.00 ( 83.26)
		 Test evaluation at end of epoch: latest_acc:53.28 LR=0.04686047402353433 -- best acc so far 53.54
Training epoch
[TRAIN] E: [47][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.88 ( 40.88)	Acc@5  72.38 ( 72.38)
[TRAIN] E: [47][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 43.16)	Acc@5  73.25 ( 73.06)
[EVAL] E: [47][0/4]	Loss 2.0752e+00 (2.0752e+00)	Acc@1  52.25 ( 52.25)	Acc@5  83.25 ( 83.25)
[EVAL] E: [47][3/4]	Loss 2.1256e+00 (2.0964e+00)	Acc@1  53.00 ( 53.46)	Acc@5  84.00 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.46 LR=0.02320866025105016 -- best acc so far 53.54
Training epoch
[TRAIN] E: [48][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.62 ( 41.62)	Acc@5  71.56 ( 71.56)
[TRAIN] E: [48][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.00 ( 42.86)	Acc@5  77.00 ( 73.01)
[EVAL] E: [48][0/4]	Loss 2.0780e+00 (2.0780e+00)	Acc@1  52.62 ( 52.62)	Acc@5  83.69 ( 83.69)
[EVAL] E: [48][3/4]	Loss 2.1308e+00 (2.0994e+00)	Acc@1  52.50 ( 53.52)	Acc@5  83.50 ( 83.38)
		 Test evaluation at end of epoch: latest_acc:53.52 LR=0.006184665997806821 -- best acc so far 53.54
Training epoch
[TRAIN] E: [49][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.06 ( 44.06)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [49][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.75 ( 43.13)	Acc@5  74.50 ( 73.06)
[EVAL] E: [49][0/4]	Loss 2.0769e+00 (2.0769e+00)	Acc@1  52.56 ( 52.56)	Acc@5  83.50 ( 83.50)
[EVAL] E: [49][3/4]	Loss 2.1292e+00 (2.0980e+00)	Acc@1  53.50 ( 53.58)	Acc@5  82.50 ( 83.20)
		 Test evaluation at end of epoch: latest_acc:53.58 LR=0.1 -- best acc so far 53.58
Training epoch
[TRAIN] E: [50][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.38 ( 44.38)	Acc@5  72.81 ( 72.81)
[TRAIN] E: [50][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.00 ( 42.90)	Acc@5  76.25 ( 72.90)
[EVAL] E: [50][0/4]	Loss 2.1365e+00 (2.1365e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.75 ( 83.75)
[EVAL] E: [50][3/4]	Loss 2.1817e+00 (2.1585e+00)	Acc@1  52.50 ( 53.12)	Acc@5  83.50 ( 83.30)
		 Test evaluation at end of epoch: latest_acc:53.12 LR=0.09381533400219318 -- best acc so far 53.58
Training epoch
[TRAIN] E: [51][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.00 ( 44.00)	Acc@5  73.69 ( 73.69)
[TRAIN] E: [51][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.75 ( 42.78)	Acc@5  74.50 ( 72.68)
[EVAL] E: [51][0/4]	Loss 2.1609e+00 (2.1609e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.38 ( 83.38)
[EVAL] E: [51][3/4]	Loss 2.2067e+00 (2.1836e+00)	Acc@1  52.50 ( 53.18)	Acc@5  83.50 ( 83.26)
		 Test evaluation at end of epoch: latest_acc:53.18 LR=0.07679133974894983 -- best acc so far 53.58
Training epoch
[TRAIN] E: [52][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.12 ( 43.12)	Acc@5  72.94 ( 72.94)
[TRAIN] E: [52][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 43.42)	Acc@5  74.75 ( 73.08)
[EVAL] E: [52][0/4]	Loss 2.1830e+00 (2.1830e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.31 ( 83.31)
[EVAL] E: [52][3/4]	Loss 2.2300e+00 (2.2057e+00)	Acc@1  53.50 ( 53.26)	Acc@5  83.50 ( 83.20)
		 Test evaluation at end of epoch: latest_acc:53.26 LR=0.05313952597646568 -- best acc so far 53.58
Training epoch
[TRAIN] E: [53][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.06 ( 41.06)	Acc@5  71.44 ( 71.44)
[TRAIN] E: [53][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  37.75 ( 43.01)	Acc@5  72.50 ( 72.99)
[EVAL] E: [53][0/4]	Loss 2.1907e+00 (2.1907e+00)	Acc@1  52.44 ( 52.44)	Acc@5  83.25 ( 83.25)
[EVAL] E: [53][3/4]	Loss 2.2402e+00 (2.2136e+00)	Acc@1  52.50 ( 53.42)	Acc@5  84.00 ( 83.22)
		 Test evaluation at end of epoch: latest_acc:53.42 LR=0.02871103542174637 -- best acc so far 53.58
Training epoch
[TRAIN] E: [54][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.50 ( 44.50)	Acc@5  74.12 ( 74.12)
[TRAIN] E: [54][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 42.64)	Acc@5  71.00 ( 72.83)
[EVAL] E: [54][0/4]	Loss 2.1904e+00 (2.1904e+00)	Acc@1  52.69 ( 52.69)	Acc@5  83.38 ( 83.38)
[EVAL] E: [54][3/4]	Loss 2.2402e+00 (2.2127e+00)	Acc@1  54.00 ( 53.62)	Acc@5  83.50 ( 83.34)
		 Test evaluation at end of epoch: latest_acc:53.62 LR=0.009549150281252633 -- best acc so far 53.62
Training epoch
[TRAIN] E: [55][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.50 ( 44.50)	Acc@5  73.31 ( 73.31)
[TRAIN] E: [55][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.25 ( 43.31)	Acc@5  69.75 ( 72.85)
[EVAL] E: [55][0/4]	Loss 2.1907e+00 (2.1907e+00)	Acc@1  52.88 ( 52.88)	Acc@5  83.25 ( 83.25)
[EVAL] E: [55][3/4]	Loss 2.2420e+00 (2.2134e+00)	Acc@1  53.50 ( 53.60)	Acc@5  82.50 ( 83.14)
		 Test evaluation at end of epoch: latest_acc:53.6 LR=0.0003942649342761118 -- best acc so far 53.62
Training epoch
[TRAIN] E: [56][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.75)	Acc@5  72.75 ( 72.75)
[TRAIN] E: [56][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.75 ( 43.20)	Acc@5  72.50 ( 72.77)
[EVAL] E: [56][0/4]	Loss 2.2467e+00 (2.2467e+00)	Acc@1  52.25 ( 52.25)	Acc@5  83.44 ( 83.44)
[EVAL] E: [56][3/4]	Loss 2.2905e+00 (2.2695e+00)	Acc@1  52.50 ( 53.12)	Acc@5  84.00 ( 83.34)
		 Test evaluation at end of epoch: latest_acc:53.12 LR=0.09648882429441258 -- best acc so far 53.62
Training epoch
[TRAIN] E: [57][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.75 ( 41.75)	Acc@5  72.56 ( 72.56)
[TRAIN] E: [57][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.00 ( 42.89)	Acc@5  71.50 ( 73.12)
[EVAL] E: [57][0/4]	Loss 2.2811e+00 (2.2811e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.50 ( 83.50)
[EVAL] E: [57][3/4]	Loss 2.3258e+00 (2.3046e+00)	Acc@1  53.00 ( 53.28)	Acc@5  84.50 ( 83.30)
		 Test evaluation at end of epoch: latest_acc:53.28 LR=0.08187119948743449 -- best acc so far 53.62
Training epoch
[TRAIN] E: [58][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.31 ( 42.31)	Acc@5  74.00 ( 74.00)
[TRAIN] E: [58][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.50 ( 42.92)	Acc@5  72.00 ( 72.93)
[EVAL] E: [58][0/4]	Loss 2.3009e+00 (2.3009e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.38 ( 83.38)
[EVAL] E: [58][3/4]	Loss 2.3470e+00 (2.3248e+00)	Acc@1  53.00 ( 53.16)	Acc@5  83.50 ( 83.26)
		 Test evaluation at end of epoch: latest_acc:53.16 LR=0.05936906572928624 -- best acc so far 53.62
Training epoch
[TRAIN] E: [59][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.31 ( 45.31)	Acc@5  73.56 ( 73.56)
[TRAIN] E: [59][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 43.19)	Acc@5  71.00 ( 72.93)
[EVAL] E: [59][0/4]	Loss 2.3138e+00 (2.3138e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.25 ( 83.25)
[EVAL] E: [59][3/4]	Loss 2.3614e+00 (2.3371e+00)	Acc@1  53.50 ( 53.32)	Acc@5  83.50 ( 83.30)
		 Test evaluation at end of epoch: latest_acc:53.32 LR=0.03454915028125265 -- best acc so far 53.62
Training epoch
[TRAIN] E: [60][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.25 ( 40.25)	Acc@5  70.56 ( 70.56)
[TRAIN] E: [60][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 42.91)	Acc@5  70.75 ( 73.06)
[EVAL] E: [60][0/4]	Loss 2.3176e+00 (2.3176e+00)	Acc@1  52.50 ( 52.50)	Acc@5  83.38 ( 83.38)
[EVAL] E: [60][3/4]	Loss 2.3667e+00 (2.3412e+00)	Acc@1  52.50 ( 53.40)	Acc@5  83.50 ( 83.20)
		 Test evaluation at end of epoch: latest_acc:53.4 LR=0.013551568628929435 -- best acc so far 53.62
Training epoch
[TRAIN] E: [61][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 43.00)	Acc@5  72.25 ( 72.25)
[TRAIN] E: [61][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.00 ( 42.93)	Acc@5  71.50 ( 72.71)
[EVAL] E: [61][0/4]	Loss 2.3163e+00 (2.3163e+00)	Acc@1  52.94 ( 52.94)	Acc@5  83.19 ( 83.19)
[EVAL] E: [61][3/4]	Loss 2.3653e+00 (2.3394e+00)	Acc@1  53.50 ( 53.56)	Acc@5  83.00 ( 83.18)
		 Test evaluation at end of epoch: latest_acc:53.56 LR=0.0015708419435684518 -- best acc so far 53.62
Training epoch
[TRAIN] E: [62][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.38 ( 41.38)	Acc@5  72.44 ( 72.44)
[TRAIN] E: [62][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.25 ( 43.17)	Acc@5  73.00 ( 72.90)
[EVAL] E: [62][0/4]	Loss 2.3607e+00 (2.3607e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.38 ( 83.38)
[EVAL] E: [62][3/4]	Loss 2.4039e+00 (2.3843e+00)	Acc@1  52.00 ( 53.18)	Acc@5  84.00 ( 83.22)
		 Test evaluation at end of epoch: latest_acc:53.18 LR=0.09842915805643156 -- best acc so far 53.62
Training epoch
[TRAIN] E: [63][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.62 ( 41.62)	Acc@5  70.25 ( 70.25)
[TRAIN] E: [63][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 42.77)	Acc@5  74.25 ( 72.68)
[EVAL] E: [63][0/4]	Loss 2.3990e+00 (2.3990e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.44 ( 83.44)
[EVAL] E: [63][3/4]	Loss 2.4423e+00 (2.4230e+00)	Acc@1  53.00 ( 53.14)	Acc@5  83.00 ( 83.22)
		 Test evaluation at end of epoch: latest_acc:53.14 LR=0.08644843137107058 -- best acc so far 53.62
Training epoch
[TRAIN] E: [64][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.31 ( 41.31)	Acc@5  71.12 ( 71.12)
[TRAIN] E: [64][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.00 ( 43.13)	Acc@5  71.75 ( 73.25)
[EVAL] E: [64][0/4]	Loss 2.4271e+00 (2.4271e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.38 ( 83.38)
[EVAL] E: [64][3/4]	Loss 2.4707e+00 (2.4510e+00)	Acc@1  52.50 ( 53.26)	Acc@5  84.00 ( 83.30)
		 Test evaluation at end of epoch: latest_acc:53.26 LR=0.06545084971874737 -- best acc so far 53.62
Training epoch
[TRAIN] E: [65][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.06 ( 41.06)	Acc@5  70.62 ( 70.62)
[TRAIN] E: [65][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.25 ( 43.24)	Acc@5  69.00 ( 72.94)
[EVAL] E: [65][0/4]	Loss 2.4428e+00 (2.4428e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.19 ( 83.19)
[EVAL] E: [65][3/4]	Loss 2.4872e+00 (2.4666e+00)	Acc@1  53.00 ( 53.26)	Acc@5  84.00 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.26 LR=0.04063093427071377 -- best acc so far 53.62
Training epoch
[TRAIN] E: [66][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.75 ( 44.75)	Acc@5  75.25 ( 75.25)
[TRAIN] E: [66][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.75 ( 43.28)	Acc@5  74.75 ( 72.93)
[EVAL] E: [66][0/4]	Loss 2.4458e+00 (2.4458e+00)	Acc@1  52.50 ( 52.50)	Acc@5  83.25 ( 83.25)
[EVAL] E: [66][3/4]	Loss 2.4929e+00 (2.4697e+00)	Acc@1  53.50 ( 53.42)	Acc@5  83.50 ( 83.22)
		 Test evaluation at end of epoch: latest_acc:53.42 LR=0.018128800512565515 -- best acc so far 53.62
Training epoch
[TRAIN] E: [67][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.75 ( 42.75)	Acc@5  72.38 ( 72.38)
[TRAIN] E: [67][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  47.50 ( 42.77)	Acc@5  74.00 ( 72.93)
[EVAL] E: [67][0/4]	Loss 2.4480e+00 (2.4480e+00)	Acc@1  52.62 ( 52.62)	Acc@5  83.12 ( 83.12)
[EVAL] E: [67][3/4]	Loss 2.4964e+00 (2.4721e+00)	Acc@1  53.00 ( 53.48)	Acc@5  83.50 ( 83.18)
		 Test evaluation at end of epoch: latest_acc:53.48 LR=0.0035111757055874327 -- best acc so far 53.62
Training epoch
[TRAIN] E: [68][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.94 ( 43.94)	Acc@5  72.56 ( 72.56)
[TRAIN] E: [68][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 42.97)	Acc@5  70.75 ( 73.09)
[EVAL] E: [68][0/4]	Loss 2.4737e+00 (2.4737e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.19 ( 83.19)
[EVAL] E: [68][3/4]	Loss 2.5174e+00 (2.4977e+00)	Acc@1  53.00 ( 53.30)	Acc@5  84.00 ( 83.26)
		 Test evaluation at end of epoch: latest_acc:53.3 LR=0.0996057350657239 -- best acc so far 53.62
Training epoch
[TRAIN] E: [69][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.25 ( 42.25)	Acc@5  72.88 ( 72.88)
[TRAIN] E: [69][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.75 ( 42.84)	Acc@5  75.25 ( 72.71)
[EVAL] E: [69][0/4]	Loss 2.5218e+00 (2.5218e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.31 ( 83.31)
[EVAL] E: [69][3/4]	Loss 2.5634e+00 (2.5460e+00)	Acc@1  53.00 ( 53.32)	Acc@5  82.50 ( 83.16)
		 Test evaluation at end of epoch: latest_acc:53.32 LR=0.09045084971874738 -- best acc so far 53.62
Training epoch
[TRAIN] E: [70][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.56 ( 42.56)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [70][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 43.30)	Acc@5  68.75 ( 73.00)
[EVAL] E: [70][0/4]	Loss 2.5541e+00 (2.5541e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.44 ( 83.44)
[EVAL] E: [70][3/4]	Loss 2.5955e+00 (2.5781e+00)	Acc@1  52.50 ( 53.14)	Acc@5  83.50 ( 83.28)
		 Test evaluation at end of epoch: latest_acc:53.14 LR=0.07128896457825364 -- best acc so far 53.62
Training epoch
[TRAIN] E: [71][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.81 ( 42.81)	Acc@5  72.00 ( 72.00)
[TRAIN] E: [71][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.75 ( 42.91)	Acc@5  74.00 ( 72.77)
[EVAL] E: [71][0/4]	Loss 2.5721e+00 (2.5721e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.25 ( 83.25)
[EVAL] E: [71][3/4]	Loss 2.6153e+00 (2.5961e+00)	Acc@1  53.00 ( 53.28)	Acc@5  83.50 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.28 LR=0.04686047402353433 -- best acc so far 53.62
Training epoch
[TRAIN] E: [72][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.12 ( 43.12)	Acc@5  73.62 ( 73.62)
[TRAIN] E: [72][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 42.96)	Acc@5  73.25 ( 72.89)
[EVAL] E: [72][0/4]	Loss 2.5798e+00 (2.5798e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.31 ( 83.31)
[EVAL] E: [72][3/4]	Loss 2.6235e+00 (2.6037e+00)	Acc@1  53.00 ( 53.34)	Acc@5  83.50 ( 83.22)
		 Test evaluation at end of epoch: latest_acc:53.34 LR=0.02320866025105016 -- best acc so far 53.62
Training epoch
[TRAIN] E: [73][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.56 ( 42.56)	Acc@5  73.19 ( 73.19)
[TRAIN] E: [73][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.50 ( 43.00)	Acc@5  72.00 ( 73.11)
[EVAL] E: [73][0/4]	Loss 2.5812e+00 (2.5812e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.44 ( 83.44)
[EVAL] E: [73][3/4]	Loss 2.6257e+00 (2.6050e+00)	Acc@1  53.00 ( 53.36)	Acc@5  83.50 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.36 LR=0.006184665997806821 -- best acc so far 53.62
Training epoch
[TRAIN] E: [74][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.56 ( 41.56)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [74][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.50 ( 42.90)	Acc@5  73.75 ( 73.00)
[EVAL] E: [74][0/4]	Loss 2.5815e+00 (2.5815e+00)	Acc@1  52.62 ( 52.62)	Acc@5  83.12 ( 83.12)
[EVAL] E: [74][3/4]	Loss 2.6260e+00 (2.6052e+00)	Acc@1  53.50 ( 53.48)	Acc@5  83.00 ( 83.16)
		 Test evaluation at end of epoch: latest_acc:53.48 LR=0.1 -- best acc so far 53.62
Training epoch
[TRAIN] E: [75][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.81 ( 42.81)	Acc@5  73.94 ( 73.94)
[TRAIN] E: [75][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 42.95)	Acc@5  72.75 ( 72.77)
[EVAL] E: [75][0/4]	Loss 2.6478e+00 (2.6478e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.25 ( 83.25)
[EVAL] E: [75][3/4]	Loss 2.6857e+00 (2.6719e+00)	Acc@1  52.50 ( 53.26)	Acc@5  84.00 ( 83.26)
		 Test evaluation at end of epoch: latest_acc:53.26 LR=0.09381533400219318 -- best acc so far 53.62
Training epoch
[TRAIN] E: [76][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.75 ( 42.75)	Acc@5  73.25 ( 73.25)
[TRAIN] E: [76][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.75 ( 43.23)	Acc@5  71.25 ( 72.98)
[EVAL] E: [76][0/4]	Loss 2.6819e+00 (2.6819e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.38 ( 83.38)
[EVAL] E: [76][3/4]	Loss 2.7206e+00 (2.7055e+00)	Acc@1  52.50 ( 53.12)	Acc@5  83.00 ( 83.30)
		 Test evaluation at end of epoch: latest_acc:53.12 LR=0.07679133974894983 -- best acc so far 53.62
Training epoch
[TRAIN] E: [77][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.56 ( 43.56)	Acc@5  74.31 ( 74.31)
[TRAIN] E: [77][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.00 ( 43.02)	Acc@5  74.75 ( 72.92)
[EVAL] E: [77][0/4]	Loss 2.7028e+00 (2.7028e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.25 ( 83.25)
[EVAL] E: [77][3/4]	Loss 2.7427e+00 (2.7263e+00)	Acc@1  53.50 ( 53.12)	Acc@5  84.00 ( 83.20)
		 Test evaluation at end of epoch: latest_acc:53.12 LR=0.05313952597646568 -- best acc so far 53.62
Training epoch
[TRAIN] E: [78][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.62 ( 42.62)	Acc@5  72.00 ( 72.00)
[TRAIN] E: [78][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.50 ( 43.17)	Acc@5  71.25 ( 72.68)
[EVAL] E: [78][0/4]	Loss 2.7107e+00 (2.7107e+00)	Acc@1  52.25 ( 52.25)	Acc@5  83.25 ( 83.25)
[EVAL] E: [78][3/4]	Loss 2.7508e+00 (2.7344e+00)	Acc@1  53.50 ( 53.38)	Acc@5  83.50 ( 83.34)
		 Test evaluation at end of epoch: latest_acc:53.38 LR=0.02871103542174637 -- best acc so far 53.62
Training epoch
[TRAIN] E: [79][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.12 ( 41.12)	Acc@5  73.06 ( 73.06)
[TRAIN] E: [79][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.50 ( 42.92)	Acc@5  72.25 ( 73.05)
[EVAL] E: [79][0/4]	Loss 2.7124e+00 (2.7124e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.06 ( 83.06)
[EVAL] E: [79][3/4]	Loss 2.7540e+00 (2.7359e+00)	Acc@1  53.00 ( 53.38)	Acc@5  83.50 ( 83.18)
		 Test evaluation at end of epoch: latest_acc:53.38 LR=0.009549150281252633 -- best acc so far 53.62
Training epoch
[TRAIN] E: [80][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.75)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [80][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.00 ( 43.07)	Acc@5  73.50 ( 72.93)
[EVAL] E: [80][0/4]	Loss 2.7137e+00 (2.7137e+00)	Acc@1  52.44 ( 52.44)	Acc@5  83.19 ( 83.19)
[EVAL] E: [80][3/4]	Loss 2.7562e+00 (2.7373e+00)	Acc@1  53.50 ( 53.38)	Acc@5  83.00 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.38 LR=0.0003942649342761118 -- best acc so far 53.62
Training epoch
[TRAIN] E: [81][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.62 ( 43.62)	Acc@5  73.31 ( 73.31)
[TRAIN] E: [81][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.50 ( 42.75)	Acc@5  77.00 ( 73.00)
[EVAL] E: [81][0/4]	Loss 2.7765e+00 (2.7765e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.25 ( 83.25)
[EVAL] E: [81][3/4]	Loss 2.8142e+00 (2.8001e+00)	Acc@1  53.00 ( 53.22)	Acc@5  83.50 ( 83.28)
		 Test evaluation at end of epoch: latest_acc:53.22 LR=0.09648882429441258 -- best acc so far 53.62
Training epoch
[TRAIN] E: [82][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.12 ( 46.12)	Acc@5  74.69 ( 74.69)
[TRAIN] E: [82][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 42.68)	Acc@5  73.00 ( 72.75)
[EVAL] E: [82][0/4]	Loss 2.8087e+00 (2.8087e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.25 ( 83.25)
[EVAL] E: [82][3/4]	Loss 2.8451e+00 (2.8320e+00)	Acc@1  53.00 ( 53.14)	Acc@5  83.50 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.14 LR=0.08187119948743449 -- best acc so far 53.62
Training epoch
[TRAIN] E: [83][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.19 ( 42.19)	Acc@5  71.38 ( 71.38)
[TRAIN] E: [83][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.25 ( 43.02)	Acc@5  72.00 ( 72.91)
[EVAL] E: [83][0/4]	Loss 2.8342e+00 (2.8342e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.19 ( 83.19)
[EVAL] E: [83][3/4]	Loss 2.8714e+00 (2.8574e+00)	Acc@1  53.00 ( 53.28)	Acc@5  83.50 ( 83.10)
		 Test evaluation at end of epoch: latest_acc:53.28 LR=0.05936906572928624 -- best acc so far 53.62
Training epoch
[TRAIN] E: [84][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.06 ( 42.06)	Acc@5  71.69 ( 71.69)
[TRAIN] E: [84][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.00 ( 43.23)	Acc@5  75.00 ( 72.96)
[EVAL] E: [84][0/4]	Loss 2.8447e+00 (2.8447e+00)	Acc@1  52.25 ( 52.25)	Acc@5  83.00 ( 83.00)
[EVAL] E: [84][3/4]	Loss 2.8821e+00 (2.8675e+00)	Acc@1  53.00 ( 53.30)	Acc@5  84.00 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.3 LR=0.03454915028125265 -- best acc so far 53.62
Training epoch
[TRAIN] E: [85][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.69 ( 43.69)	Acc@5  73.44 ( 73.44)
[TRAIN] E: [85][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.50 ( 43.17)	Acc@5  72.25 ( 72.81)
[EVAL] E: [85][0/4]	Loss 2.8499e+00 (2.8499e+00)	Acc@1  52.25 ( 52.25)	Acc@5  83.00 ( 83.00)
[EVAL] E: [85][3/4]	Loss 2.8888e+00 (2.8730e+00)	Acc@1  53.00 ( 53.40)	Acc@5  83.50 ( 83.18)
		 Test evaluation at end of epoch: latest_acc:53.4 LR=0.013551568628929435 -- best acc so far 53.62
Training epoch
[TRAIN] E: [86][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.12 ( 45.12)	Acc@5  73.25 ( 73.25)
[TRAIN] E: [86][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 42.63)	Acc@5  70.75 ( 72.85)
[EVAL] E: [86][0/4]	Loss 2.8509e+00 (2.8509e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.12 ( 83.12)
[EVAL] E: [86][3/4]	Loss 2.8906e+00 (2.8735e+00)	Acc@1  53.00 ( 53.42)	Acc@5  82.00 ( 83.10)
		 Test evaluation at end of epoch: latest_acc:53.42 LR=0.0015708419435684518 -- best acc so far 53.62
Training epoch
[TRAIN] E: [87][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.31 ( 43.31)	Acc@5  74.12 ( 74.12)
[TRAIN] E: [87][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.25 ( 43.07)	Acc@5  72.75 ( 72.97)
[EVAL] E: [87][0/4]	Loss 2.8911e+00 (2.8911e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.19 ( 83.19)
[EVAL] E: [87][3/4]	Loss 2.9254e+00 (2.9136e+00)	Acc@1  53.50 ( 53.20)	Acc@5  83.00 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.2 LR=0.09842915805643156 -- best acc so far 53.62
Training epoch
[TRAIN] E: [88][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.62 ( 44.62)	Acc@5  71.19 ( 71.19)
[TRAIN] E: [88][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.50 ( 42.84)	Acc@5  72.50 ( 72.91)
[EVAL] E: [88][0/4]	Loss 2.9352e+00 (2.9352e+00)	Acc@1  52.25 ( 52.25)	Acc@5  83.25 ( 83.25)
[EVAL] E: [88][3/4]	Loss 2.9686e+00 (2.9573e+00)	Acc@1  53.00 ( 53.16)	Acc@5  83.50 ( 83.10)
		 Test evaluation at end of epoch: latest_acc:53.16 LR=0.08644843137107058 -- best acc so far 53.62
Training epoch
[TRAIN] E: [89][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.56 ( 41.56)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [89][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.25 ( 42.91)	Acc@5  70.75 ( 72.89)
[EVAL] E: [89][0/4]	Loss 2.9601e+00 (2.9601e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.44 ( 83.44)
[EVAL] E: [89][3/4]	Loss 2.9935e+00 (2.9823e+00)	Acc@1  52.50 ( 53.26)	Acc@5  83.50 ( 83.32)
		 Test evaluation at end of epoch: latest_acc:53.26 LR=0.06545084971874737 -- best acc so far 53.62
Training epoch
[TRAIN] E: [90][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.56 ( 42.56)	Acc@5  73.50 ( 73.50)
[TRAIN] E: [90][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 43.42)	Acc@5  72.00 ( 73.20)
[EVAL] E: [90][0/4]	Loss 2.9752e+00 (2.9752e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.06 ( 83.06)
[EVAL] E: [90][3/4]	Loss 3.0103e+00 (2.9974e+00)	Acc@1  53.50 ( 53.24)	Acc@5  84.00 ( 83.12)
		 Test evaluation at end of epoch: latest_acc:53.24 LR=0.04063093427071377 -- best acc so far 53.62
Training epoch
[TRAIN] E: [91][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.56 ( 42.56)	Acc@5  72.19 ( 72.19)
[TRAIN] E: [91][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.50 ( 43.07)	Acc@5  74.00 ( 72.83)
[EVAL] E: [91][0/4]	Loss 2.9771e+00 (2.9771e+00)	Acc@1  52.25 ( 52.25)	Acc@5  83.06 ( 83.06)
[EVAL] E: [91][3/4]	Loss 3.0126e+00 (2.9996e+00)	Acc@1  53.00 ( 53.34)	Acc@5  83.50 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.34 LR=0.018128800512565515 -- best acc so far 53.62
Training epoch
[TRAIN] E: [92][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.06 ( 46.06)	Acc@5  73.81 ( 73.81)
[TRAIN] E: [92][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.00 ( 43.31)	Acc@5  72.25 ( 72.98)
[EVAL] E: [92][0/4]	Loss 2.9826e+00 (2.9826e+00)	Acc@1  52.44 ( 52.44)	Acc@5  83.31 ( 83.31)
[EVAL] E: [92][3/4]	Loss 3.0195e+00 (3.0049e+00)	Acc@1  53.00 ( 53.44)	Acc@5  83.50 ( 83.28)
		 Test evaluation at end of epoch: latest_acc:53.44 LR=0.0035111757055874327 -- best acc so far 53.62
Training epoch
[TRAIN] E: [93][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.00 ( 41.00)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [93][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.50 ( 43.08)	Acc@5  76.50 ( 72.90)
[EVAL] E: [93][0/4]	Loss 3.0074e+00 (3.0074e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.06 ( 83.06)
[EVAL] E: [93][3/4]	Loss 3.0417e+00 (3.0294e+00)	Acc@1  54.00 ( 53.22)	Acc@5  84.00 ( 83.20)
		 Test evaluation at end of epoch: latest_acc:53.22 LR=0.0996057350657239 -- best acc so far 53.62
Training epoch
[TRAIN] E: [94][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.69 ( 43.69)	Acc@5  72.44 ( 72.44)
[TRAIN] E: [94][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 42.99)	Acc@5  71.75 ( 72.83)
[EVAL] E: [94][0/4]	Loss 3.0542e+00 (3.0542e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.25 ( 83.25)
[EVAL] E: [94][3/4]	Loss 3.0849e+00 (3.0756e+00)	Acc@1  52.50 ( 53.02)	Acc@5  83.50 ( 83.28)
		 Test evaluation at end of epoch: latest_acc:53.02 LR=0.09045084971874738 -- best acc so far 53.62
Training epoch
[TRAIN] E: [95][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.44 ( 44.44)	Acc@5  73.88 ( 73.88)
[TRAIN] E: [95][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 42.99)	Acc@5  71.00 ( 72.90)
[EVAL] E: [95][0/4]	Loss 3.0813e+00 (3.0813e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.31 ( 83.31)
[EVAL] E: [95][3/4]	Loss 3.1113e+00 (3.1024e+00)	Acc@1  53.50 ( 53.14)	Acc@5  83.50 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.14 LR=0.07128896457825364 -- best acc so far 53.62
Training epoch
[TRAIN] E: [96][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.69 ( 43.69)	Acc@5  72.19 ( 72.19)
[TRAIN] E: [96][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.25 ( 42.97)	Acc@5  75.00 ( 72.84)
[EVAL] E: [96][0/4]	Loss 3.0986e+00 (3.0986e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.12 ( 83.12)
[EVAL] E: [96][3/4]	Loss 3.1303e+00 (3.1199e+00)	Acc@1  53.50 ( 53.20)	Acc@5  83.50 ( 83.10)
		 Test evaluation at end of epoch: latest_acc:53.2 LR=0.04686047402353433 -- best acc so far 53.62
Training epoch
[TRAIN] E: [97][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.19 ( 42.19)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [97][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.25 ( 43.11)	Acc@5  70.75 ( 72.86)
[EVAL] E: [97][0/4]	Loss 3.1083e+00 (3.1083e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.12 ( 83.12)
[EVAL] E: [97][3/4]	Loss 3.1413e+00 (3.1294e+00)	Acc@1  53.00 ( 53.30)	Acc@5  83.50 ( 83.18)
		 Test evaluation at end of epoch: latest_acc:53.3 LR=0.02320866025105016 -- best acc so far 53.62
Training epoch
[TRAIN] E: [98][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.31 ( 43.31)	Acc@5  73.75 ( 73.75)
[TRAIN] E: [98][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.75 ( 43.18)	Acc@5  73.00 ( 72.89)
[EVAL] E: [98][0/4]	Loss 3.1068e+00 (3.1068e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.12 ( 83.12)
[EVAL] E: [98][3/4]	Loss 3.1405e+00 (3.1282e+00)	Acc@1  53.50 ( 53.36)	Acc@5  83.50 ( 83.20)
		 Test evaluation at end of epoch: latest_acc:53.36 LR=0.006184665997806821 -- best acc so far 53.62
Training epoch
[TRAIN] E: [99][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.88 ( 41.88)	Acc@5  70.62 ( 70.62)
[TRAIN] E: [99][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.00 ( 42.42)	Acc@5  76.50 ( 72.70)
[EVAL] E: [99][0/4]	Loss 3.1064e+00 (3.1064e+00)	Acc@1  52.44 ( 52.44)	Acc@5  83.06 ( 83.06)
[EVAL] E: [99][3/4]	Loss 3.1405e+00 (3.1279e+00)	Acc@1  53.00 ( 53.44)	Acc@5  83.50 ( 83.20)
		 Test evaluation at end of epoch: latest_acc:53.44 LR=0.1 -- best acc so far 53.62
Training epoch
[TRAIN] E: [100][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.12 ( 43.12)	Acc@5  73.50 ( 73.50)
[TRAIN] E: [100][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.00 ( 43.36)	Acc@5  69.75 ( 73.05)
[EVAL] E: [100][0/4]	Loss 3.1713e+00 (3.1713e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.19 ( 83.19)
[EVAL] E: [100][3/4]	Loss 3.2000e+00 (3.1916e+00)	Acc@1  53.00 ( 53.10)	Acc@5  83.50 ( 83.16)
		 Test evaluation at end of epoch: latest_acc:53.1 LR=0.09381533400219318 -- best acc so far 53.62
Training epoch
[TRAIN] E: [101][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.56 ( 44.56)	Acc@5  72.69 ( 72.69)
[TRAIN] E: [101][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.00 ( 43.03)	Acc@5  74.50 ( 72.99)
[EVAL] E: [101][0/4]	Loss 3.1996e+00 (3.1996e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.12 ( 83.12)
[EVAL] E: [101][3/4]	Loss 3.2279e+00 (3.2197e+00)	Acc@1  53.50 ( 53.18)	Acc@5  83.50 ( 83.26)
		 Test evaluation at end of epoch: latest_acc:53.18 LR=0.07679133974894983 -- best acc so far 53.62
Training epoch
[TRAIN] E: [102][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.12 ( 42.12)	Acc@5  73.25 ( 73.25)
[TRAIN] E: [102][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.50 ( 42.76)	Acc@5  75.75 ( 72.63)
[EVAL] E: [102][0/4]	Loss 3.2162e+00 (3.2162e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.12 ( 83.12)
[EVAL] E: [102][3/4]	Loss 3.2452e+00 (3.2361e+00)	Acc@1  53.50 ( 53.34)	Acc@5  83.50 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.34 LR=0.05313952597646568 -- best acc so far 53.62
Training epoch
[TRAIN] E: [103][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.44 ( 42.44)	Acc@5  72.88 ( 72.88)
[TRAIN] E: [103][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.25 ( 43.01)	Acc@5  72.25 ( 72.90)
[EVAL] E: [103][0/4]	Loss 3.2258e+00 (3.2258e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.38 ( 83.38)
[EVAL] E: [103][3/4]	Loss 3.2553e+00 (3.2455e+00)	Acc@1  53.00 ( 53.32)	Acc@5  83.00 ( 83.30)
		 Test evaluation at end of epoch: latest_acc:53.32 LR=0.02871103542174637 -- best acc so far 53.62
Training epoch
[TRAIN] E: [104][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.25 ( 41.25)	Acc@5  72.81 ( 72.81)
[TRAIN] E: [104][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.00 ( 42.93)	Acc@5  74.25 ( 72.84)
[EVAL] E: [104][0/4]	Loss 3.2291e+00 (3.2291e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.06 ( 83.06)
[EVAL] E: [104][3/4]	Loss 3.2599e+00 (3.2490e+00)	Acc@1  53.00 ( 53.32)	Acc@5  83.00 ( 83.14)
		 Test evaluation at end of epoch: latest_acc:53.32 LR=0.009549150281252633 -- best acc so far 53.62
Training epoch
[TRAIN] E: [105][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.12 ( 45.12)	Acc@5  73.31 ( 73.31)
[TRAIN] E: [105][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.75 ( 42.86)	Acc@5  71.00 ( 72.62)
[EVAL] E: [105][0/4]	Loss 3.2231e+00 (3.2231e+00)	Acc@1  52.50 ( 52.50)	Acc@5  83.25 ( 83.25)
[EVAL] E: [105][3/4]	Loss 3.2536e+00 (3.2429e+00)	Acc@1  52.50 ( 53.48)	Acc@5  83.00 ( 83.18)
		 Test evaluation at end of epoch: latest_acc:53.48 LR=0.0003942649342761118 -- best acc so far 53.62
Training epoch
[TRAIN] E: [106][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.00 ( 42.00)	Acc@5  73.25 ( 73.25)
[TRAIN] E: [106][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.75 ( 42.97)	Acc@5  69.25 ( 72.96)
[EVAL] E: [106][0/4]	Loss 3.2770e+00 (3.2770e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.25 ( 83.25)
[EVAL] E: [106][3/4]	Loss 3.3031e+00 (3.2961e+00)	Acc@1  53.50 ( 53.10)	Acc@5  83.00 ( 83.22)
		 Test evaluation at end of epoch: latest_acc:53.1 LR=0.09648882429441258 -- best acc so far 53.62
Training epoch
[TRAIN] E: [107][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.81 ( 41.81)	Acc@5  71.81 ( 71.81)
[TRAIN] E: [107][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.50 ( 43.20)	Acc@5  73.75 ( 72.80)
[EVAL] E: [107][0/4]	Loss 3.3081e+00 (3.3081e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.25 ( 83.25)
[EVAL] E: [107][3/4]	Loss 3.3338e+00 (3.3268e+00)	Acc@1  53.50 ( 53.02)	Acc@5  83.00 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:53.02 LR=0.08187119948743449 -- best acc so far 53.62
Training epoch
[TRAIN] E: [108][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.31 ( 41.31)	Acc@5  70.62 ( 70.62)
[TRAIN] E: [108][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.00 ( 42.76)	Acc@5  74.00 ( 72.97)
[EVAL] E: [108][0/4]	Loss 3.3288e+00 (3.3288e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.19 ( 83.19)
[EVAL] E: [108][3/4]	Loss 3.3551e+00 (3.3475e+00)	Acc@1  53.50 ( 53.08)	Acc@5  83.00 ( 83.16)
		 Test evaluation at end of epoch: latest_acc:53.08 LR=0.05936906572928624 -- best acc so far 53.62
Training epoch
[TRAIN] E: [109][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.06 ( 43.06)	Acc@5  70.62 ( 70.62)
[TRAIN] E: [109][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 43.19)	Acc@5  72.75 ( 72.54)
[EVAL] E: [109][0/4]	Loss 3.3404e+00 (3.3404e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.19 ( 83.19)
[EVAL] E: [109][3/4]	Loss 3.3674e+00 (3.3592e+00)	Acc@1  53.00 ( 53.18)	Acc@5  82.50 ( 83.14)
		 Test evaluation at end of epoch: latest_acc:53.18 LR=0.03454915028125265 -- best acc so far 53.62
Training epoch
[TRAIN] E: [110][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.81 ( 40.81)	Acc@5  71.56 ( 71.56)
[TRAIN] E: [110][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.05)	Acc@5  75.75 ( 73.03)
[EVAL] E: [110][0/4]	Loss 3.3421e+00 (3.3421e+00)	Acc@1  51.88 ( 51.88)	Acc@5  83.38 ( 83.38)
[EVAL] E: [110][3/4]	Loss 3.3698e+00 (3.3610e+00)	Acc@1  53.00 ( 53.12)	Acc@5  83.00 ( 83.32)
		 Test evaluation at end of epoch: latest_acc:53.12 LR=0.013551568628929435 -- best acc so far 53.62
Training epoch
[TRAIN] E: [111][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.88 ( 41.88)	Acc@5  72.75 ( 72.75)
[TRAIN] E: [111][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 42.72)	Acc@5  72.75 ( 72.65)
[EVAL] E: [111][0/4]	Loss 3.3428e+00 (3.3428e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.19 ( 83.19)
[EVAL] E: [111][3/4]	Loss 3.3708e+00 (3.3615e+00)	Acc@1  52.50 ( 53.26)	Acc@5  83.00 ( 83.18)
		 Test evaluation at end of epoch: latest_acc:53.26 LR=0.0015708419435684518 -- best acc so far 53.62
Training epoch
[TRAIN] E: [112][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 43.25)	Acc@5  74.25 ( 74.25)
[TRAIN] E: [112][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.00 ( 43.05)	Acc@5  71.25 ( 72.97)
[EVAL] E: [112][0/4]	Loss 3.3794e+00 (3.3794e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.25 ( 83.25)
[EVAL] E: [112][3/4]	Loss 3.4045e+00 (3.3976e+00)	Acc@1  53.50 ( 53.24)	Acc@5  83.50 ( 83.10)
		 Test evaluation at end of epoch: latest_acc:53.24 LR=0.09842915805643156 -- best acc so far 53.62
Training epoch
[TRAIN] E: [113][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.12 ( 42.12)	Acc@5  71.38 ( 71.38)
[TRAIN] E: [113][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.75 ( 43.11)	Acc@5  72.50 ( 72.87)
[EVAL] E: [113][0/4]	Loss 3.4138e+00 (3.4138e+00)	Acc@1  51.75 ( 51.75)	Acc@5  83.19 ( 83.19)
[EVAL] E: [113][3/4]	Loss 3.4375e+00 (3.4316e+00)	Acc@1  53.50 ( 53.02)	Acc@5  83.00 ( 83.22)
		 Test evaluation at end of epoch: latest_acc:53.02 LR=0.08644843137107058 -- best acc so far 53.62
Training epoch
[TRAIN] E: [114][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.06 ( 44.06)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [114][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  38.25 ( 42.86)	Acc@5  69.75 ( 72.83)
[EVAL] E: [114][0/4]	Loss 3.4322e+00 (3.4322e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.12 ( 83.12)
[EVAL] E: [114][3/4]	Loss 3.4555e+00 (3.4499e+00)	Acc@1  53.00 ( 53.10)	Acc@5  83.00 ( 83.18)
		 Test evaluation at end of epoch: latest_acc:53.1 LR=0.06545084971874737 -- best acc so far 53.62
Training epoch
[TRAIN] E: [115][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.38 ( 42.38)	Acc@5  71.62 ( 71.62)
[TRAIN] E: [115][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.25 ( 42.94)	Acc@5  72.75 ( 72.82)
[EVAL] E: [115][0/4]	Loss 3.4448e+00 (3.4448e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.19 ( 83.19)
[EVAL] E: [115][3/4]	Loss 3.4690e+00 (3.4621e+00)	Acc@1  53.00 ( 53.26)	Acc@5  82.50 ( 83.22)
		 Test evaluation at end of epoch: latest_acc:53.26 LR=0.04063093427071377 -- best acc so far 53.62
Training epoch
[TRAIN] E: [116][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.56 ( 44.56)	Acc@5  72.00 ( 72.00)
[TRAIN] E: [116][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 42.92)	Acc@5  70.75 ( 72.82)
[EVAL] E: [116][0/4]	Loss 3.4513e+00 (3.4513e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.12 ( 83.12)
[EVAL] E: [116][3/4]	Loss 3.4766e+00 (3.4689e+00)	Acc@1  52.50 ( 53.08)	Acc@5  82.50 ( 83.14)
		 Test evaluation at end of epoch: latest_acc:53.08 LR=0.018128800512565515 -- best acc so far 53.62
Training epoch
[TRAIN] E: [117][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 43.25)	Acc@5  71.12 ( 71.12)
[TRAIN] E: [117][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  47.00 ( 42.90)	Acc@5  72.00 ( 72.82)
[EVAL] E: [117][0/4]	Loss 3.4528e+00 (3.4528e+00)	Acc@1  52.25 ( 52.25)	Acc@5  83.19 ( 83.19)
[EVAL] E: [117][3/4]	Loss 3.4785e+00 (3.4701e+00)	Acc@1  52.50 ( 53.34)	Acc@5  83.00 ( 83.14)
		 Test evaluation at end of epoch: latest_acc:53.34 LR=0.0035111757055874327 -- best acc so far 53.62
Training epoch
[TRAIN] E: [118][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.50 ( 43.50)	Acc@5  73.88 ( 73.88)
[TRAIN] E: [118][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 43.00)	Acc@5  70.00 ( 72.87)
[EVAL] E: [118][0/4]	Loss 3.4712e+00 (3.4712e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.19 ( 83.19)
[EVAL] E: [118][3/4]	Loss 3.4940e+00 (3.4881e+00)	Acc@1  53.00 ( 53.08)	Acc@5  82.50 ( 83.18)
		 Test evaluation at end of epoch: latest_acc:53.08 LR=0.0996057350657239 -- best acc so far 53.62
Training epoch
[TRAIN] E: [119][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.69 ( 42.69)	Acc@5  72.94 ( 72.94)
[TRAIN] E: [119][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.50 ( 43.15)	Acc@5  68.25 ( 72.67)
[EVAL] E: [119][0/4]	Loss 3.5096e+00 (3.5096e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.25 ( 83.25)
[EVAL] E: [119][3/4]	Loss 3.5304e+00 (3.5260e+00)	Acc@1  53.00 ( 53.04)	Acc@5  82.50 ( 83.20)
		 Test evaluation at end of epoch: latest_acc:53.04 LR=0.09045084971874738 -- best acc so far 53.62
Training epoch
[TRAIN] E: [120][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.31 ( 42.31)	Acc@5  72.94 ( 72.94)
[TRAIN] E: [120][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.06)	Acc@5  74.75 ( 72.73)
[EVAL] E: [120][0/4]	Loss 3.5319e+00 (3.5319e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.19 ( 83.19)
[EVAL] E: [120][3/4]	Loss 3.5535e+00 (3.5481e+00)	Acc@1  53.50 ( 53.04)	Acc@5  83.00 ( 83.08)
		 Test evaluation at end of epoch: latest_acc:53.04 LR=0.07128896457825364 -- best acc so far 53.62
Training epoch
[TRAIN] E: [121][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.31 ( 41.31)	Acc@5  71.94 ( 71.94)
[TRAIN] E: [121][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.00 ( 42.98)	Acc@5  74.75 ( 73.03)
[EVAL] E: [121][0/4]	Loss 3.5445e+00 (3.5445e+00)	Acc@1  51.88 ( 51.88)	Acc@5  83.19 ( 83.19)
[EVAL] E: [121][3/4]	Loss 3.5664e+00 (3.5605e+00)	Acc@1  52.50 ( 53.02)	Acc@5  82.50 ( 83.14)
		 Test evaluation at end of epoch: latest_acc:53.02 LR=0.04686047402353433 -- best acc so far 53.62
Training epoch
[TRAIN] E: [122][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.69 ( 41.69)	Acc@5  72.25 ( 72.25)
[TRAIN] E: [122][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.75 ( 42.87)	Acc@5  78.00 ( 72.79)
[EVAL] E: [122][0/4]	Loss 3.5490e+00 (3.5490e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.31 ( 83.31)
[EVAL] E: [122][3/4]	Loss 3.5711e+00 (3.5650e+00)	Acc@1  53.00 ( 53.18)	Acc@5  82.50 ( 83.14)
		 Test evaluation at end of epoch: latest_acc:53.18 LR=0.02320866025105016 -- best acc so far 53.62
Training epoch
[TRAIN] E: [123][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 43.00)	Acc@5  73.44 ( 73.44)
[TRAIN] E: [123][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.34)	Acc@5  74.50 ( 72.72)
[EVAL] E: [123][0/4]	Loss 3.5503e+00 (3.5503e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.19 ( 83.19)
[EVAL] E: [123][3/4]	Loss 3.5727e+00 (3.5663e+00)	Acc@1  52.50 ( 53.22)	Acc@5  83.00 ( 83.06)
		 Test evaluation at end of epoch: latest_acc:53.22 LR=0.006184665997806821 -- best acc so far 53.62
Training epoch
[TRAIN] E: [124][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.38 ( 42.38)	Acc@5  72.94 ( 72.94)
[TRAIN] E: [124][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.50 ( 43.02)	Acc@5  71.25 ( 72.90)
[EVAL] E: [124][0/4]	Loss 3.5485e+00 (3.5485e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.12 ( 83.12)
[EVAL] E: [124][3/4]	Loss 3.5717e+00 (3.5646e+00)	Acc@1  52.50 ( 53.30)	Acc@5  83.00 ( 83.20)
		 Test evaluation at end of epoch: latest_acc:53.3 LR=0.1 -- best acc so far 53.62
Training epoch
[TRAIN] E: [125][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.56 ( 44.56)	Acc@5  73.50 ( 73.50)
[TRAIN] E: [125][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  35.00 ( 42.96)	Acc@5  68.25 ( 72.89)
[EVAL] E: [125][0/4]	Loss 3.5982e+00 (3.5982e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.12 ( 83.12)
[EVAL] E: [125][3/4]	Loss 3.6177e+00 (3.6133e+00)	Acc@1  52.00 ( 52.92)	Acc@5  82.50 ( 83.14)
		 Test evaluation at end of epoch: latest_acc:52.92 LR=0.09381533400219318 -- best acc so far 53.62
Training epoch
[TRAIN] E: [126][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.38 ( 41.38)	Acc@5  72.19 ( 72.19)
[TRAIN] E: [126][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  47.75 ( 42.63)	Acc@5  74.25 ( 72.61)
[EVAL] E: [126][0/4]	Loss 3.6179e+00 (3.6179e+00)	Acc@1  51.88 ( 51.88)	Acc@5  83.31 ( 83.31)
[EVAL] E: [126][3/4]	Loss 3.6371e+00 (3.6330e+00)	Acc@1  53.50 ( 53.06)	Acc@5  82.50 ( 83.14)
		 Test evaluation at end of epoch: latest_acc:53.06 LR=0.07679133974894983 -- best acc so far 53.62
Training epoch
[TRAIN] E: [127][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.88 ( 43.88)	Acc@5  73.50 ( 73.50)
[TRAIN] E: [127][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.75 ( 43.22)	Acc@5  70.25 ( 72.70)
[EVAL] E: [127][0/4]	Loss 3.6320e+00 (3.6320e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.25 ( 83.25)
[EVAL] E: [127][3/4]	Loss 3.6519e+00 (3.6470e+00)	Acc@1  53.50 ( 53.08)	Acc@5  82.50 ( 83.06)
		 Test evaluation at end of epoch: latest_acc:53.08 LR=0.05313952597646568 -- best acc so far 53.62
Training epoch
[TRAIN] E: [128][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.12 ( 43.12)	Acc@5  73.88 ( 73.88)
[TRAIN] E: [128][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  37.50 ( 42.99)	Acc@5  70.75 ( 72.72)
[EVAL] E: [128][0/4]	Loss 3.6372e+00 (3.6372e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.12 ( 83.12)
[EVAL] E: [128][3/4]	Loss 3.6575e+00 (3.6519e+00)	Acc@1  53.00 ( 53.06)	Acc@5  82.50 ( 83.06)
		 Test evaluation at end of epoch: latest_acc:53.06 LR=0.02871103542174637 -- best acc so far 53.62
Training epoch
[TRAIN] E: [129][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.94 ( 42.94)	Acc@5  72.31 ( 72.31)
[TRAIN] E: [129][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.50 ( 42.75)	Acc@5  72.25 ( 72.31)
[EVAL] E: [129][0/4]	Loss 3.6394e+00 (3.6394e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.25 ( 83.25)
[EVAL] E: [129][3/4]	Loss 3.6606e+00 (3.6543e+00)	Acc@1  52.50 ( 53.12)	Acc@5  82.50 ( 83.08)
		 Test evaluation at end of epoch: latest_acc:53.12 LR=0.009549150281252633 -- best acc so far 53.62
Training epoch
[TRAIN] E: [130][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.88 ( 44.88)	Acc@5  73.81 ( 73.81)
[TRAIN] E: [130][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.75 ( 43.04)	Acc@5  73.50 ( 72.66)
[EVAL] E: [130][0/4]	Loss 3.6380e+00 (3.6380e+00)	Acc@1  52.44 ( 52.44)	Acc@5  83.19 ( 83.19)
[EVAL] E: [130][3/4]	Loss 3.6596e+00 (3.6530e+00)	Acc@1  52.50 ( 53.40)	Acc@5  83.00 ( 83.18)
		 Test evaluation at end of epoch: latest_acc:53.4 LR=0.0003942649342761118 -- best acc so far 53.62
Training epoch
[TRAIN] E: [131][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.56 ( 39.56)	Acc@5  70.44 ( 70.44)
[TRAIN] E: [131][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.75 ( 42.99)	Acc@5  74.50 ( 72.66)
[EVAL] E: [131][0/4]	Loss 3.6763e+00 (3.6763e+00)	Acc@1  51.88 ( 51.88)	Acc@5  83.38 ( 83.38)
[EVAL] E: [131][3/4]	Loss 3.6942e+00 (3.6905e+00)	Acc@1  53.50 ( 52.90)	Acc@5  83.00 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:52.9 LR=0.09648882429441258 -- best acc so far 53.62
Training epoch
[TRAIN] E: [132][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.88 ( 42.88)	Acc@5  72.38 ( 72.38)
[TRAIN] E: [132][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.50 ( 42.59)	Acc@5  72.75 ( 72.50)
[EVAL] E: [132][0/4]	Loss 3.6985e+00 (3.6985e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.31 ( 83.31)
[EVAL] E: [132][3/4]	Loss 3.7161e+00 (3.7122e+00)	Acc@1  53.00 ( 52.98)	Acc@5  82.50 ( 83.24)
		 Test evaluation at end of epoch: latest_acc:52.98 LR=0.08187119948743449 -- best acc so far 53.62
Training epoch
[TRAIN] E: [133][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.31 ( 42.31)	Acc@5  72.69 ( 72.69)
[TRAIN] E: [133][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 43.09)	Acc@5  72.00 ( 72.94)
[EVAL] E: [133][0/4]	Loss 3.7131e+00 (3.7131e+00)	Acc@1  51.75 ( 51.75)	Acc@5  83.19 ( 83.19)
[EVAL] E: [133][3/4]	Loss 3.7310e+00 (3.7268e+00)	Acc@1  53.50 ( 53.00)	Acc@5  82.50 ( 83.08)
		 Test evaluation at end of epoch: latest_acc:53.0 LR=0.05936906572928624 -- best acc so far 53.62
Training epoch
[TRAIN] E: [134][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.38 ( 44.38)	Acc@5  74.06 ( 74.06)
[TRAIN] E: [134][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.11)	Acc@5  76.50 ( 72.89)
[EVAL] E: [134][0/4]	Loss 3.7213e+00 (3.7213e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.25 ( 83.25)
[EVAL] E: [134][3/4]	Loss 3.7397e+00 (3.7350e+00)	Acc@1  52.00 ( 53.00)	Acc@5  82.50 ( 83.12)
		 Test evaluation at end of epoch: latest_acc:53.0 LR=0.03454915028125265 -- best acc so far 53.62
Training epoch
[TRAIN] E: [135][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.81 ( 44.81)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [135][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.25 ( 42.79)	Acc@5  68.75 ( 72.76)
[EVAL] E: [135][0/4]	Loss 3.7234e+00 (3.7234e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.19 ( 83.19)
[EVAL] E: [135][3/4]	Loss 3.7421e+00 (3.7370e+00)	Acc@1  52.50 ( 53.18)	Acc@5  82.50 ( 83.12)
		 Test evaluation at end of epoch: latest_acc:53.18 LR=0.013551568628929435 -- best acc so far 53.62
Training epoch
[TRAIN] E: [136][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.38 ( 42.38)	Acc@5  73.44 ( 73.44)
[TRAIN] E: [136][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 42.66)	Acc@5  71.50 ( 72.86)
[EVAL] E: [136][0/4]	Loss 3.7245e+00 (3.7245e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.12 ( 83.12)
[EVAL] E: [136][3/4]	Loss 3.7440e+00 (3.7383e+00)	Acc@1  52.50 ( 53.16)	Acc@5  82.50 ( 83.08)
		 Test evaluation at end of epoch: latest_acc:53.16 LR=0.0015708419435684518 -- best acc so far 53.62
Training epoch
[TRAIN] E: [137][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.69 ( 42.69)	Acc@5  73.25 ( 73.25)
[TRAIN] E: [137][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.19)	Acc@5  73.75 ( 72.84)
[EVAL] E: [137][0/4]	Loss 3.7497e+00 (3.7497e+00)	Acc@1  51.75 ( 51.75)	Acc@5  83.19 ( 83.19)
[EVAL] E: [137][3/4]	Loss 3.7666e+00 (3.7628e+00)	Acc@1  52.50 ( 52.92)	Acc@5  82.50 ( 83.16)
		 Test evaluation at end of epoch: latest_acc:52.92 LR=0.09842915805643156 -- best acc so far 53.62
Training epoch
[TRAIN] E: [138][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.19 ( 43.19)	Acc@5  74.06 ( 74.06)
[TRAIN] E: [138][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  48.00 ( 42.76)	Acc@5  76.00 ( 72.85)
[EVAL] E: [138][0/4]	Loss 3.7738e+00 (3.7738e+00)	Acc@1  51.62 ( 51.62)	Acc@5  83.06 ( 83.06)
[EVAL] E: [138][3/4]	Loss 3.7900e+00 (3.7867e+00)	Acc@1  53.00 ( 52.86)	Acc@5  82.50 ( 83.04)
		 Test evaluation at end of epoch: latest_acc:52.86 LR=0.08644843137107058 -- best acc so far 53.62
Training epoch
[TRAIN] E: [139][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.81 ( 42.81)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [139][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.75 ( 42.49)	Acc@5  73.50 ( 72.51)
[EVAL] E: [139][0/4]	Loss 3.7898e+00 (3.7898e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.31 ( 83.31)
[EVAL] E: [139][3/4]	Loss 3.8059e+00 (3.8024e+00)	Acc@1  53.00 ( 53.02)	Acc@5  82.50 ( 83.16)
		 Test evaluation at end of epoch: latest_acc:53.02 LR=0.06545084971874737 -- best acc so far 53.62
Training epoch
[TRAIN] E: [140][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.56 ( 41.56)	Acc@5  72.88 ( 72.88)
[TRAIN] E: [140][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.75 ( 42.99)	Acc@5  70.50 ( 72.92)
[EVAL] E: [140][0/4]	Loss 3.7984e+00 (3.7984e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.12 ( 83.12)
[EVAL] E: [140][3/4]	Loss 3.8153e+00 (3.8109e+00)	Acc@1  52.50 ( 53.08)	Acc@5  82.50 ( 83.12)
		 Test evaluation at end of epoch: latest_acc:53.08 LR=0.04063093427071377 -- best acc so far 53.62
Training epoch
[TRAIN] E: [141][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.44 ( 44.44)	Acc@5  74.25 ( 74.25)
[TRAIN] E: [141][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  38.00 ( 42.86)	Acc@5  74.25 ( 72.93)
[EVAL] E: [141][0/4]	Loss 3.7995e+00 (3.7995e+00)	Acc@1  52.25 ( 52.25)	Acc@5  83.19 ( 83.19)
[EVAL] E: [141][3/4]	Loss 3.8164e+00 (3.8121e+00)	Acc@1  53.00 ( 53.28)	Acc@5  82.50 ( 83.06)
		 Test evaluation at end of epoch: latest_acc:53.28 LR=0.018128800512565515 -- best acc so far 53.62
Training epoch
[TRAIN] E: [142][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.25 ( 44.25)	Acc@5  74.12 ( 74.12)
[TRAIN] E: [142][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.25 ( 43.10)	Acc@5  69.00 ( 72.99)
[EVAL] E: [142][0/4]	Loss 3.8009e+00 (3.8009e+00)	Acc@1  52.44 ( 52.44)	Acc@5  83.19 ( 83.19)
[EVAL] E: [142][3/4]	Loss 3.8179e+00 (3.8133e+00)	Acc@1  52.00 ( 53.16)	Acc@5  82.50 ( 83.08)
		 Test evaluation at end of epoch: latest_acc:53.16 LR=0.0035111757055874327 -- best acc so far 53.62
Training epoch
[TRAIN] E: [143][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.44 ( 42.44)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [143][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.50 ( 42.65)	Acc@5  73.50 ( 72.72)
[EVAL] E: [143][0/4]	Loss 3.8156e+00 (3.8156e+00)	Acc@1  51.75 ( 51.75)	Acc@5  83.31 ( 83.31)
[EVAL] E: [143][3/4]	Loss 3.8313e+00 (3.8279e+00)	Acc@1  53.00 ( 53.00)	Acc@5  82.50 ( 83.10)
		 Test evaluation at end of epoch: latest_acc:53.0 LR=0.0996057350657239 -- best acc so far 53.62
Training epoch
[TRAIN] E: [144][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.50 ( 39.50)	Acc@5  71.88 ( 71.88)
[TRAIN] E: [144][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.50 ( 42.61)	Acc@5  68.75 ( 72.58)
[EVAL] E: [144][0/4]	Loss 3.8425e+00 (3.8425e+00)	Acc@1  51.62 ( 51.62)	Acc@5  83.19 ( 83.19)
[EVAL] E: [144][3/4]	Loss 3.8570e+00 (3.8541e+00)	Acc@1  52.50 ( 52.96)	Acc@5  82.50 ( 83.04)
		 Test evaluation at end of epoch: latest_acc:52.96 LR=0.09045084971874738 -- best acc so far 53.62
Training epoch
[TRAIN] E: [145][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.19 ( 44.19)	Acc@5  73.62 ( 73.62)
[TRAIN] E: [145][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.00 ( 42.51)	Acc@5  74.50 ( 72.58)
[EVAL] E: [145][0/4]	Loss 3.8593e+00 (3.8593e+00)	Acc@1  51.69 ( 51.69)	Acc@5  83.31 ( 83.31)
[EVAL] E: [145][3/4]	Loss 3.8736e+00 (3.8708e+00)	Acc@1  52.50 ( 52.86)	Acc@5  82.50 ( 83.10)
		 Test evaluation at end of epoch: latest_acc:52.86 LR=0.07128896457825364 -- best acc so far 53.62
Training epoch
[TRAIN] E: [146][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.56 ( 41.56)	Acc@5  71.44 ( 71.44)
[TRAIN] E: [146][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 42.79)	Acc@5  70.75 ( 72.57)
[EVAL] E: [146][0/4]	Loss 3.8680e+00 (3.8680e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.25 ( 83.25)
[EVAL] E: [146][3/4]	Loss 3.8827e+00 (3.8794e+00)	Acc@1  51.50 ( 52.94)	Acc@5  82.50 ( 83.10)
		 Test evaluation at end of epoch: latest_acc:52.94 LR=0.04686047402353433 -- best acc so far 53.62
Training epoch
[TRAIN] E: [147][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.62 ( 41.62)	Acc@5  71.31 ( 71.31)
[TRAIN] E: [147][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.75 ( 42.33)	Acc@5  74.75 ( 72.55)
[EVAL] E: [147][0/4]	Loss 3.8742e+00 (3.8742e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.06 ( 83.06)
[EVAL] E: [147][3/4]	Loss 3.8896e+00 (3.8855e+00)	Acc@1  52.50 ( 53.08)	Acc@5  82.50 ( 83.04)
		 Test evaluation at end of epoch: latest_acc:53.08 LR=0.02320866025105016 -- best acc so far 53.62
Training epoch
[TRAIN] E: [148][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.88 ( 41.88)	Acc@5  71.25 ( 71.25)
[TRAIN] E: [148][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.75 ( 43.07)	Acc@5  75.25 ( 72.71)
[EVAL] E: [148][0/4]	Loss 3.8725e+00 (3.8725e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.25 ( 83.25)
[EVAL] E: [148][3/4]	Loss 3.8883e+00 (3.8840e+00)	Acc@1  52.00 ( 53.04)	Acc@5  82.50 ( 83.02)
		 Test evaluation at end of epoch: latest_acc:53.04 LR=0.006184665997806821 -- best acc so far 53.62
Training epoch
[TRAIN] E: [149][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.12 ( 44.12)	Acc@5  75.12 ( 75.12)
[TRAIN] E: [149][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 42.78)	Acc@5  73.00 ( 72.82)
[EVAL] E: [149][0/4]	Loss 3.8709e+00 (3.8709e+00)	Acc@1  52.44 ( 52.44)	Acc@5  83.19 ( 83.19)
[EVAL] E: [149][3/4]	Loss 3.8865e+00 (3.8824e+00)	Acc@1  51.50 ( 53.08)	Acc@5  82.50 ( 83.00)
		 Test evaluation at end of epoch: latest_acc:53.08 LR=0.1 -- best acc so far 53.62
Training epoch
[TRAIN] E: [150][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.62 ( 45.62)	Acc@5  74.69 ( 74.69)
[TRAIN] E: [150][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.25 ( 42.49)	Acc@5  72.00 ( 72.69)
[EVAL] E: [150][0/4]	Loss 3.9077e+00 (3.9077e+00)	Acc@1  51.75 ( 51.75)	Acc@5  83.38 ( 83.38)
[EVAL] E: [150][3/4]	Loss 3.9208e+00 (3.9183e+00)	Acc@1  53.00 ( 52.76)	Acc@5  82.00 ( 83.08)
		 Test evaluation at end of epoch: latest_acc:52.76 LR=0.09381533400219318 -- best acc so far 53.62
Training epoch
[TRAIN] E: [151][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.94 ( 42.94)	Acc@5  73.38 ( 73.38)
[TRAIN] E: [151][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.50 ( 42.70)	Acc@5  72.50 ( 72.72)
[EVAL] E: [151][0/4]	Loss 3.9237e+00 (3.9237e+00)	Acc@1  51.69 ( 51.69)	Acc@5  83.19 ( 83.19)
[EVAL] E: [151][3/4]	Loss 3.9370e+00 (3.9341e+00)	Acc@1  52.50 ( 52.90)	Acc@5  82.50 ( 83.04)
		 Test evaluation at end of epoch: latest_acc:52.9 LR=0.07679133974894983 -- best acc so far 53.62
Training epoch
[TRAIN] E: [152][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.56 ( 43.56)	Acc@5  72.19 ( 72.19)
[TRAIN] E: [152][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  49.00 ( 42.69)	Acc@5  74.25 ( 72.32)
[EVAL] E: [152][0/4]	Loss 3.9347e+00 (3.9347e+00)	Acc@1  51.75 ( 51.75)	Acc@5  83.06 ( 83.06)
[EVAL] E: [152][3/4]	Loss 3.9483e+00 (3.9451e+00)	Acc@1  52.50 ( 52.92)	Acc@5  82.50 ( 82.94)
		 Test evaluation at end of epoch: latest_acc:52.92 LR=0.05313952597646568 -- best acc so far 53.62
Training epoch
[TRAIN] E: [153][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.44 ( 43.44)	Acc@5  71.25 ( 71.25)
[TRAIN] E: [153][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 42.80)	Acc@5  74.75 ( 72.76)
[EVAL] E: [153][0/4]	Loss 3.9391e+00 (3.9391e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.25 ( 83.25)
[EVAL] E: [153][3/4]	Loss 3.9529e+00 (3.9495e+00)	Acc@1  52.00 ( 53.12)	Acc@5  82.50 ( 82.94)
		 Test evaluation at end of epoch: latest_acc:53.12 LR=0.02871103542174637 -- best acc so far 53.62
Training epoch
[TRAIN] E: [154][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.56 ( 42.56)	Acc@5  72.62 ( 72.62)
[TRAIN] E: [154][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.75 ( 42.71)	Acc@5  71.00 ( 72.43)
[EVAL] E: [154][0/4]	Loss 3.9390e+00 (3.9390e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.19 ( 83.19)
[EVAL] E: [154][3/4]	Loss 3.9533e+00 (3.9494e+00)	Acc@1  52.00 ( 53.16)	Acc@5  82.50 ( 82.96)
		 Test evaluation at end of epoch: latest_acc:53.16 LR=0.009549150281252633 -- best acc so far 53.62
Training epoch
[TRAIN] E: [155][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.38 ( 42.38)	Acc@5  72.38 ( 72.38)
[TRAIN] E: [155][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.25 ( 42.42)	Acc@5  71.00 ( 72.54)
[EVAL] E: [155][0/4]	Loss 3.9382e+00 (3.9382e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.31 ( 83.31)
[EVAL] E: [155][3/4]	Loss 3.9525e+00 (3.9487e+00)	Acc@1  52.00 ( 53.20)	Acc@5  82.50 ( 83.08)
		 Test evaluation at end of epoch: latest_acc:53.2 LR=0.0003942649342761118 -- best acc so far 53.62
Training epoch
[TRAIN] E: [156][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.62 ( 41.62)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [156][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.25 ( 42.44)	Acc@5  72.75 ( 72.70)
[EVAL] E: [156][0/4]	Loss 3.9669e+00 (3.9669e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.06 ( 83.06)
[EVAL] E: [156][3/4]	Loss 3.9790e+00 (3.9766e+00)	Acc@1  52.50 ( 52.84)	Acc@5  82.50 ( 82.94)
		 Test evaluation at end of epoch: latest_acc:52.84 LR=0.09648882429441258 -- best acc so far 53.62
Training epoch
[TRAIN] E: [157][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 43.00)	Acc@5  74.25 ( 74.25)
[TRAIN] E: [157][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 42.58)	Acc@5  74.25 ( 72.72)
[EVAL] E: [157][0/4]	Loss 3.9845e+00 (3.9845e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.12 ( 83.12)
[EVAL] E: [157][3/4]	Loss 3.9964e+00 (3.9940e+00)	Acc@1  52.50 ( 52.76)	Acc@5  82.50 ( 83.00)
		 Test evaluation at end of epoch: latest_acc:52.76 LR=0.08187119948743449 -- best acc so far 53.62
Training epoch
[TRAIN] E: [158][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.62 ( 41.62)	Acc@5  71.75 ( 71.75)
[TRAIN] E: [158][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 42.59)	Acc@5  74.25 ( 72.40)
[EVAL] E: [158][0/4]	Loss 3.9938e+00 (3.9938e+00)	Acc@1  51.69 ( 51.69)	Acc@5  83.31 ( 83.31)
[EVAL] E: [158][3/4]	Loss 4.0057e+00 (4.0033e+00)	Acc@1  52.00 ( 52.80)	Acc@5  82.50 ( 82.96)
		 Test evaluation at end of epoch: latest_acc:52.8 LR=0.05936906572928624 -- best acc so far 53.62
Training epoch
[TRAIN] E: [159][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.94 ( 41.94)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [159][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 42.73)	Acc@5  73.25 ( 72.58)
[EVAL] E: [159][0/4]	Loss 4.0006e+00 (4.0006e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.25 ( 83.25)
[EVAL] E: [159][3/4]	Loss 4.0128e+00 (4.0099e+00)	Acc@1  51.50 ( 52.96)	Acc@5  82.50 ( 82.98)
		 Test evaluation at end of epoch: latest_acc:52.96 LR=0.03454915028125265 -- best acc so far 53.62
Training epoch
[TRAIN] E: [160][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.94 ( 40.94)	Acc@5  73.38 ( 73.38)
[TRAIN] E: [160][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.00 ( 42.75)	Acc@5  72.50 ( 72.36)
[EVAL] E: [160][0/4]	Loss 4.0004e+00 (4.0004e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.38 ( 83.38)
[EVAL] E: [160][3/4]	Loss 4.0132e+00 (4.0099e+00)	Acc@1  51.50 ( 53.06)	Acc@5  82.50 ( 83.02)
		 Test evaluation at end of epoch: latest_acc:53.06 LR=0.013551568628929435 -- best acc so far 53.62
Training epoch
[TRAIN] E: [161][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.19 ( 42.19)	Acc@5  73.81 ( 73.81)
[TRAIN] E: [161][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.50 ( 42.59)	Acc@5  74.50 ( 72.65)
[EVAL] E: [161][0/4]	Loss 4.0004e+00 (4.0004e+00)	Acc@1  52.62 ( 52.62)	Acc@5  83.50 ( 83.50)
[EVAL] E: [161][3/4]	Loss 4.0136e+00 (4.0100e+00)	Acc@1  52.00 ( 53.26)	Acc@5  82.50 ( 83.06)
		 Test evaluation at end of epoch: latest_acc:53.26 LR=0.0015708419435684518 -- best acc so far 53.62
Training epoch
[TRAIN] E: [162][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.12 ( 43.12)	Acc@5  72.06 ( 72.06)
[TRAIN] E: [162][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.50 ( 42.52)	Acc@5  70.25 ( 72.47)
[EVAL] E: [162][0/4]	Loss 4.0205e+00 (4.0205e+00)	Acc@1  51.62 ( 51.62)	Acc@5  83.19 ( 83.19)
[EVAL] E: [162][3/4]	Loss 4.0318e+00 (4.0294e+00)	Acc@1  53.00 ( 52.70)	Acc@5  82.00 ( 82.92)
		 Test evaluation at end of epoch: latest_acc:52.7 LR=0.09842915805643156 -- best acc so far 53.62
Training epoch
[TRAIN] E: [163][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.06 ( 43.06)	Acc@5  71.06 ( 71.06)
[TRAIN] E: [163][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 42.47)	Acc@5  74.50 ( 72.49)
[EVAL] E: [163][0/4]	Loss 4.0385e+00 (4.0385e+00)	Acc@1  51.75 ( 51.75)	Acc@5  83.25 ( 83.25)
[EVAL] E: [163][3/4]	Loss 4.0493e+00 (4.0473e+00)	Acc@1  52.50 ( 52.86)	Acc@5  82.00 ( 82.86)
		 Test evaluation at end of epoch: latest_acc:52.86 LR=0.08644843137107058 -- best acc so far 53.62
Training epoch
[TRAIN] E: [164][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.25 ( 41.25)	Acc@5  71.31 ( 71.31)
[TRAIN] E: [164][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.75 ( 42.72)	Acc@5  70.00 ( 72.37)
[EVAL] E: [164][0/4]	Loss 4.0483e+00 (4.0483e+00)	Acc@1  51.62 ( 51.62)	Acc@5  83.31 ( 83.31)
[EVAL] E: [164][3/4]	Loss 4.0591e+00 (4.0568e+00)	Acc@1  53.00 ( 52.74)	Acc@5  82.00 ( 82.88)
		 Test evaluation at end of epoch: latest_acc:52.74 LR=0.06545084971874737 -- best acc so far 53.62
Training epoch
[TRAIN] E: [165][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.75)	Acc@5  72.94 ( 72.94)
[TRAIN] E: [165][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  47.25 ( 42.53)	Acc@5  79.00 ( 72.54)
[EVAL] E: [165][0/4]	Loss 4.0564e+00 (4.0564e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.12 ( 83.12)
[EVAL] E: [165][3/4]	Loss 4.0675e+00 (4.0649e+00)	Acc@1  52.00 ( 52.94)	Acc@5  82.50 ( 82.88)
		 Test evaluation at end of epoch: latest_acc:52.94 LR=0.04063093427071377 -- best acc so far 53.62
Training epoch
[TRAIN] E: [166][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.81 ( 42.81)	Acc@5  71.56 ( 71.56)
[TRAIN] E: [166][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.75 ( 42.82)	Acc@5  76.00 ( 72.32)
[EVAL] E: [166][0/4]	Loss 4.0585e+00 (4.0585e+00)	Acc@1  52.38 ( 52.38)	Acc@5  83.12 ( 83.12)
[EVAL] E: [166][3/4]	Loss 4.0695e+00 (4.0671e+00)	Acc@1  51.50 ( 53.12)	Acc@5  82.50 ( 82.86)
		 Test evaluation at end of epoch: latest_acc:53.12 LR=0.018128800512565515 -- best acc so far 53.62
Training epoch
[TRAIN] E: [167][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.88 ( 42.88)	Acc@5  73.19 ( 73.19)
[TRAIN] E: [167][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  47.75 ( 42.74)	Acc@5  75.50 ( 72.34)
[EVAL] E: [167][0/4]	Loss 4.0578e+00 (4.0578e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.38 ( 83.38)
[EVAL] E: [167][3/4]	Loss 4.0695e+00 (4.0664e+00)	Acc@1  51.50 ( 53.22)	Acc@5  82.00 ( 82.90)
		 Test evaluation at end of epoch: latest_acc:53.22 LR=0.0035111757055874327 -- best acc so far 53.62
Training epoch
[TRAIN] E: [168][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.06 ( 43.06)	Acc@5  73.56 ( 73.56)
[TRAIN] E: [168][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.50 ( 42.42)	Acc@5  72.25 ( 72.50)
[EVAL] E: [168][0/4]	Loss 4.0678e+00 (4.0678e+00)	Acc@1  51.88 ( 51.88)	Acc@5  83.50 ( 83.50)
[EVAL] E: [168][3/4]	Loss 4.0783e+00 (4.0761e+00)	Acc@1  51.50 ( 52.82)	Acc@5  82.00 ( 82.98)
		 Test evaluation at end of epoch: latest_acc:52.82 LR=0.0996057350657239 -- best acc so far 53.62
Training epoch
[TRAIN] E: [169][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.06 ( 43.06)	Acc@5  72.88 ( 72.88)
[TRAIN] E: [169][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 42.50)	Acc@5  74.25 ( 72.55)
[EVAL] E: [169][0/4]	Loss 4.0882e+00 (4.0882e+00)	Acc@1  51.69 ( 51.69)	Acc@5  83.38 ( 83.38)
[EVAL] E: [169][3/4]	Loss 4.0976e+00 (4.0961e+00)	Acc@1  52.50 ( 52.62)	Acc@5  82.00 ( 82.80)
		 Test evaluation at end of epoch: latest_acc:52.62 LR=0.09045084971874738 -- best acc so far 53.62
Training epoch
[TRAIN] E: [170][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 42.50)	Acc@5  71.69 ( 71.69)
[TRAIN] E: [170][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.25 ( 42.68)	Acc@5  72.50 ( 72.42)
[EVAL] E: [170][0/4]	Loss 4.0999e+00 (4.0999e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.12 ( 83.12)
[EVAL] E: [170][3/4]	Loss 4.1096e+00 (4.1077e+00)	Acc@1  52.50 ( 52.86)	Acc@5  82.00 ( 82.78)
		 Test evaluation at end of epoch: latest_acc:52.86 LR=0.07128896457825364 -- best acc so far 53.62
Training epoch
[TRAIN] E: [171][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.06 ( 41.06)	Acc@5  71.50 ( 71.50)
[TRAIN] E: [171][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.75 ( 42.72)	Acc@5  69.25 ( 72.46)
[EVAL] E: [171][0/4]	Loss 4.1061e+00 (4.1061e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.31 ( 83.31)
[EVAL] E: [171][3/4]	Loss 4.1160e+00 (4.1138e+00)	Acc@1  52.50 ( 52.84)	Acc@5  82.00 ( 82.84)
		 Test evaluation at end of epoch: latest_acc:52.84 LR=0.04686047402353433 -- best acc so far 53.62
Training epoch
[TRAIN] E: [172][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.00 ( 42.00)	Acc@5  72.31 ( 72.31)
[TRAIN] E: [172][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  38.50 ( 42.13)	Acc@5  71.50 ( 72.36)
[EVAL] E: [172][0/4]	Loss 4.1105e+00 (4.1105e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.38 ( 83.38)
[EVAL] E: [172][3/4]	Loss 4.1208e+00 (4.1182e+00)	Acc@1  52.00 ( 53.10)	Acc@5  82.00 ( 82.92)
		 Test evaluation at end of epoch: latest_acc:53.1 LR=0.02320866025105016 -- best acc so far 53.62
Training epoch
[TRAIN] E: [173][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.00 ( 40.00)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [173][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  47.00 ( 42.43)	Acc@5  75.75 ( 72.40)
[EVAL] E: [173][0/4]	Loss 4.1110e+00 (4.1110e+00)	Acc@1  52.44 ( 52.44)	Acc@5  83.25 ( 83.25)
[EVAL] E: [173][3/4]	Loss 4.1212e+00 (4.1187e+00)	Acc@1  51.00 ( 53.14)	Acc@5  82.00 ( 82.90)
		 Test evaluation at end of epoch: latest_acc:53.14 LR=0.006184665997806821 -- best acc so far 53.62
Training epoch
[TRAIN] E: [174][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.88 ( 41.88)	Acc@5  71.75 ( 71.75)
[TRAIN] E: [174][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.00 ( 42.36)	Acc@5  76.00 ( 72.21)
[EVAL] E: [174][0/4]	Loss 4.1094e+00 (4.1094e+00)	Acc@1  52.50 ( 52.50)	Acc@5  83.25 ( 83.25)
[EVAL] E: [174][3/4]	Loss 4.1201e+00 (4.1171e+00)	Acc@1  51.00 ( 53.16)	Acc@5  82.50 ( 82.98)
		 Test evaluation at end of epoch: latest_acc:53.16 LR=0.1 -- best acc so far 53.62
Training epoch
[TRAIN] E: [175][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.69 ( 44.69)	Acc@5  75.12 ( 75.12)
[TRAIN] E: [175][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.00 ( 42.64)	Acc@5  74.75 ( 72.47)
[EVAL] E: [175][0/4]	Loss 4.1345e+00 (4.1345e+00)	Acc@1  51.62 ( 51.62)	Acc@5  83.31 ( 83.31)
[EVAL] E: [175][3/4]	Loss 4.1431e+00 (4.1417e+00)	Acc@1  52.50 ( 52.80)	Acc@5  82.00 ( 82.74)
		 Test evaluation at end of epoch: latest_acc:52.8 LR=0.09381533400219318 -- best acc so far 53.62
Training epoch
[TRAIN] E: [176][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.75 ( 40.75)	Acc@5  71.81 ( 71.81)
[TRAIN] E: [176][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.50 ( 42.45)	Acc@5  74.00 ( 72.55)
[EVAL] E: [176][0/4]	Loss 4.1474e+00 (4.1474e+00)	Acc@1  51.69 ( 51.69)	Acc@5  83.00 ( 83.00)
[EVAL] E: [176][3/4]	Loss 4.1562e+00 (4.1544e+00)	Acc@1  52.50 ( 52.80)	Acc@5  82.00 ( 82.70)
		 Test evaluation at end of epoch: latest_acc:52.8 LR=0.07679133974894983 -- best acc so far 53.62
Training epoch
[TRAIN] E: [177][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.62 ( 41.62)	Acc@5  71.44 ( 71.44)
[TRAIN] E: [177][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 42.28)	Acc@5  70.50 ( 72.11)
[EVAL] E: [177][0/4]	Loss 4.1542e+00 (4.1542e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.31 ( 83.31)
[EVAL] E: [177][3/4]	Loss 4.1629e+00 (4.1612e+00)	Acc@1  52.00 ( 52.98)	Acc@5  82.00 ( 82.86)
		 Test evaluation at end of epoch: latest_acc:52.98 LR=0.05313952597646568 -- best acc so far 53.62
Training epoch
[TRAIN] E: [178][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.94 ( 41.94)	Acc@5  73.19 ( 73.19)
[TRAIN] E: [178][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.25 ( 42.47)	Acc@5  75.25 ( 72.54)
[EVAL] E: [178][0/4]	Loss 4.1585e+00 (4.1585e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.31 ( 83.31)
[EVAL] E: [178][3/4]	Loss 4.1675e+00 (4.1654e+00)	Acc@1  51.50 ( 53.12)	Acc@5  82.00 ( 82.82)
		 Test evaluation at end of epoch: latest_acc:53.12 LR=0.02871103542174637 -- best acc so far 53.62
Training epoch
[TRAIN] E: [179][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.12 ( 44.12)	Acc@5  74.94 ( 74.94)
[TRAIN] E: [179][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.50 ( 42.49)	Acc@5  70.00 ( 72.23)
[EVAL] E: [179][0/4]	Loss 4.1586e+00 (4.1586e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.31 ( 83.31)
[EVAL] E: [179][3/4]	Loss 4.1679e+00 (4.1656e+00)	Acc@1  51.50 ( 53.26)	Acc@5  82.00 ( 83.00)
		 Test evaluation at end of epoch: latest_acc:53.26 LR=0.009549150281252633 -- best acc so far 53.62
Training epoch
[TRAIN] E: [180][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.19 ( 41.19)	Acc@5  72.88 ( 72.88)
[TRAIN] E: [180][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.75 ( 42.37)	Acc@5  71.75 ( 72.45)
[EVAL] E: [180][0/4]	Loss 4.1582e+00 (4.1582e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.31 ( 83.31)
[EVAL] E: [180][3/4]	Loss 4.1678e+00 (4.1653e+00)	Acc@1  52.00 ( 53.32)	Acc@5  82.00 ( 82.90)
		 Test evaluation at end of epoch: latest_acc:53.32 LR=0.0003942649342761118 -- best acc so far 53.62
Training epoch
[TRAIN] E: [181][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.06 ( 41.06)	Acc@5  72.62 ( 72.62)
[TRAIN] E: [181][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.75 ( 42.31)	Acc@5  72.00 ( 72.35)
[EVAL] E: [181][0/4]	Loss 4.1780e+00 (4.1780e+00)	Acc@1  51.69 ( 51.69)	Acc@5  83.31 ( 83.31)
[EVAL] E: [181][3/4]	Loss 4.1862e+00 (4.1846e+00)	Acc@1  53.00 ( 52.80)	Acc@5  82.00 ( 82.70)
		 Test evaluation at end of epoch: latest_acc:52.8 LR=0.09648882429441258 -- best acc so far 53.62
Training epoch
[TRAIN] E: [182][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.81 ( 39.81)	Acc@5  68.50 ( 68.50)
[TRAIN] E: [182][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.00 ( 42.33)	Acc@5  72.50 ( 72.29)
[EVAL] E: [182][0/4]	Loss 4.1894e+00 (4.1894e+00)	Acc@1  51.75 ( 51.75)	Acc@5  83.06 ( 83.06)
[EVAL] E: [182][3/4]	Loss 4.1971e+00 (4.1957e+00)	Acc@1  52.50 ( 52.86)	Acc@5  82.00 ( 82.68)
		 Test evaluation at end of epoch: latest_acc:52.86 LR=0.08187119948743449 -- best acc so far 53.62
Training epoch
[TRAIN] E: [183][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.75 ( 39.75)	Acc@5  70.81 ( 70.81)
[TRAIN] E: [183][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 42.32)	Acc@5  75.25 ( 72.11)
[EVAL] E: [183][0/4]	Loss 4.1977e+00 (4.1977e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.06 ( 83.06)
[EVAL] E: [183][3/4]	Loss 4.2055e+00 (4.2040e+00)	Acc@1  52.50 ( 53.04)	Acc@5  82.00 ( 82.78)
		 Test evaluation at end of epoch: latest_acc:53.04 LR=0.05936906572928624 -- best acc so far 53.62
Training epoch
[TRAIN] E: [184][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.38 ( 43.38)	Acc@5  71.94 ( 71.94)
[TRAIN] E: [184][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.25 ( 41.94)	Acc@5  67.75 ( 72.16)
[EVAL] E: [184][0/4]	Loss 4.2018e+00 (4.2018e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.44 ( 83.44)
[EVAL] E: [184][3/4]	Loss 4.2099e+00 (4.2080e+00)	Acc@1  52.50 ( 52.98)	Acc@5  82.00 ( 82.76)
		 Test evaluation at end of epoch: latest_acc:52.98 LR=0.03454915028125265 -- best acc so far 53.62
Training epoch
[TRAIN] E: [185][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.44 ( 43.44)	Acc@5  71.50 ( 71.50)
[TRAIN] E: [185][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.25 ( 42.00)	Acc@5  74.25 ( 72.21)
[EVAL] E: [185][0/4]	Loss 4.2022e+00 (4.2022e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.31 ( 83.31)
[EVAL] E: [185][3/4]	Loss 4.2104e+00 (4.2085e+00)	Acc@1  51.50 ( 53.06)	Acc@5  82.00 ( 82.84)
		 Test evaluation at end of epoch: latest_acc:53.06 LR=0.013551568628929435 -- best acc so far 53.62
Training epoch
[TRAIN] E: [186][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.06 ( 41.06)	Acc@5  70.25 ( 70.25)
[TRAIN] E: [186][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.00 ( 42.29)	Acc@5  72.00 ( 72.01)
[EVAL] E: [186][0/4]	Loss 4.2027e+00 (4.2027e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.19 ( 83.19)
[EVAL] E: [186][3/4]	Loss 4.2111e+00 (4.2090e+00)	Acc@1  51.50 ( 53.30)	Acc@5  82.00 ( 82.78)
		 Test evaluation at end of epoch: latest_acc:53.3 LR=0.0015708419435684518 -- best acc so far 53.62
Training epoch
[TRAIN] E: [187][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.38 ( 42.38)	Acc@5  73.44 ( 73.44)
[TRAIN] E: [187][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.50 ( 42.03)	Acc@5  71.75 ( 71.92)
[EVAL] E: [187][0/4]	Loss 4.2161e+00 (4.2161e+00)	Acc@1  52.06 ( 52.06)	Acc@5  83.25 ( 83.25)
[EVAL] E: [187][3/4]	Loss 4.2233e+00 (4.2221e+00)	Acc@1  52.50 ( 52.88)	Acc@5  82.00 ( 82.64)
		 Test evaluation at end of epoch: latest_acc:52.88 LR=0.09842915805643156 -- best acc so far 53.62
Training epoch
[TRAIN] E: [188][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.19 ( 42.19)	Acc@5  72.19 ( 72.19)
[TRAIN] E: [188][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.25 ( 42.02)	Acc@5  72.50 ( 72.14)
[EVAL] E: [188][0/4]	Loss 4.2293e+00 (4.2293e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.38 ( 83.38)
[EVAL] E: [188][3/4]	Loss 4.2362e+00 (4.2351e+00)	Acc@1  51.50 ( 52.78)	Acc@5  82.00 ( 82.72)
		 Test evaluation at end of epoch: latest_acc:52.78 LR=0.08644843137107058 -- best acc so far 53.62
Training epoch
[TRAIN] E: [189][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.19 ( 42.19)	Acc@5  72.88 ( 72.88)
[TRAIN] E: [189][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  38.50 ( 42.08)	Acc@5  71.50 ( 72.08)
[EVAL] E: [189][0/4]	Loss 4.2368e+00 (4.2368e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.31 ( 83.31)
[EVAL] E: [189][3/4]	Loss 4.2437e+00 (4.2424e+00)	Acc@1  52.00 ( 52.90)	Acc@5  82.00 ( 82.62)
		 Test evaluation at end of epoch: latest_acc:52.9 LR=0.06545084971874737 -- best acc so far 53.62
Training epoch
[TRAIN] E: [190][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.12 ( 40.12)	Acc@5  72.31 ( 72.31)
[TRAIN] E: [190][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.50 ( 41.95)	Acc@5  69.75 ( 72.08)
[EVAL] E: [190][0/4]	Loss 4.2415e+00 (4.2415e+00)	Acc@1  52.00 ( 52.00)	Acc@5  83.38 ( 83.38)
[EVAL] E: [190][3/4]	Loss 4.2486e+00 (4.2471e+00)	Acc@1  51.00 ( 52.82)	Acc@5  82.00 ( 82.74)
		 Test evaluation at end of epoch: latest_acc:52.82 LR=0.04063093427071377 -- best acc so far 53.62
Training epoch
[TRAIN] E: [191][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.56 ( 41.56)	Acc@5  72.44 ( 72.44)
[TRAIN] E: [191][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.00 ( 41.71)	Acc@5  68.50 ( 72.08)
[EVAL] E: [191][0/4]	Loss 4.2437e+00 (4.2437e+00)	Acc@1  52.25 ( 52.25)	Acc@5  83.38 ( 83.38)
[EVAL] E: [191][3/4]	Loss 4.2511e+00 (4.2493e+00)	Acc@1  51.50 ( 53.12)	Acc@5  82.00 ( 82.76)
		 Test evaluation at end of epoch: latest_acc:53.12 LR=0.018128800512565515 -- best acc so far 53.62
Training epoch
[TRAIN] E: [192][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.31 ( 44.31)	Acc@5  74.19 ( 74.19)
[TRAIN] E: [192][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  38.25 ( 41.88)	Acc@5  64.00 ( 71.93)
[EVAL] E: [192][0/4]	Loss 4.2431e+00 (4.2431e+00)	Acc@1  52.19 ( 52.19)	Acc@5  83.19 ( 83.19)
[EVAL] E: [192][3/4]	Loss 4.2504e+00 (4.2488e+00)	Acc@1  51.00 ( 53.14)	Acc@5  82.00 ( 82.72)
		 Test evaluation at end of epoch: latest_acc:53.14 LR=0.0035111757055874327 -- best acc so far 53.62
Training epoch
[TRAIN] E: [193][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.62 ( 42.62)	Acc@5  72.00 ( 72.00)
[TRAIN] E: [193][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.50 ( 41.84)	Acc@5  70.50 ( 72.09)
[EVAL] E: [193][0/4]	Loss 4.2501e+00 (4.2501e+00)	Acc@1  52.12 ( 52.12)	Acc@5  83.19 ( 83.19)
[EVAL] E: [193][3/4]	Loss 4.2570e+00 (4.2556e+00)	Acc@1  52.00 ( 53.04)	Acc@5  82.00 ( 82.60)
		 Test evaluation at end of epoch: latest_acc:53.04 LR=0.0996057350657239 -- best acc so far 53.62
Training epoch
[TRAIN] E: [194][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.06 ( 42.06)	Acc@5  71.38 ( 71.38)
[TRAIN] E: [194][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.50 ( 42.04)	Acc@5  70.50 ( 71.80)
[EVAL] E: [194][0/4]	Loss 4.2653e+00 (4.2653e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.25 ( 83.25)
[EVAL] E: [194][3/4]	Loss 4.2713e+00 (4.2704e+00)	Acc@1  52.00 ( 52.74)	Acc@5  82.00 ( 82.58)
		 Test evaluation at end of epoch: latest_acc:52.74 LR=0.09045084971874738 -- best acc so far 53.62
Training epoch
[TRAIN] E: [195][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.25 ( 40.25)	Acc@5  71.31 ( 71.31)
[TRAIN] E: [195][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 42.15)	Acc@5  73.75 ( 72.13)
[EVAL] E: [195][0/4]	Loss 4.2736e+00 (4.2736e+00)	Acc@1  51.81 ( 51.81)	Acc@5  83.38 ( 83.38)
[EVAL] E: [195][3/4]	Loss 4.2799e+00 (4.2787e+00)	Acc@1  51.50 ( 52.68)	Acc@5  82.00 ( 82.66)
		 Test evaluation at end of epoch: latest_acc:52.68 LR=0.07128896457825364 -- best acc so far 53.62
Training epoch
[TRAIN] E: [196][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.75)	Acc@5  71.69 ( 71.69)
[TRAIN] E: [196][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.25 ( 42.06)	Acc@5  67.75 ( 71.84)
[EVAL] E: [196][0/4]	Loss 4.2786e+00 (4.2786e+00)	Acc@1  51.88 ( 51.88)	Acc@5  83.25 ( 83.25)
[EVAL] E: [196][3/4]	Loss 4.2849e+00 (4.2836e+00)	Acc@1  50.50 ( 52.92)	Acc@5  82.00 ( 82.62)
		 Test evaluation at end of epoch: latest_acc:52.92 LR=0.04686047402353433 -- best acc so far 53.62
Training epoch
[TRAIN] E: [197][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.19 ( 41.19)	Acc@5  71.69 ( 71.69)
[TRAIN] E: [197][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  44.00 ( 42.07)	Acc@5  70.75 ( 72.07)
[EVAL] E: [197][0/4]	Loss 4.2814e+00 (4.2814e+00)	Acc@1  51.94 ( 51.94)	Acc@5  83.38 ( 83.38)
[EVAL] E: [197][3/4]	Loss 4.2879e+00 (4.2864e+00)	Acc@1  51.00 ( 53.04)	Acc@5  82.50 ( 82.62)
		 Test evaluation at end of epoch: latest_acc:53.04 LR=0.02320866025105016 -- best acc so far 53.62
Training epoch
[TRAIN] E: [198][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.06 ( 45.06)	Acc@5  74.12 ( 74.12)
[TRAIN] E: [198][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.00 ( 42.11)	Acc@5  69.75 ( 71.81)
[EVAL] E: [198][0/4]	Loss 4.2816e+00 (4.2816e+00)	Acc@1  52.31 ( 52.31)	Acc@5  83.31 ( 83.31)
[EVAL] E: [198][3/4]	Loss 4.2882e+00 (4.2867e+00)	Acc@1  51.00 ( 53.04)	Acc@5  83.00 ( 82.64)
		 Test evaluation at end of epoch: latest_acc:53.04 LR=0.006184665997806821 -- best acc so far 53.62
Training epoch
[TRAIN] E: [199][ 0/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.69 ( 42.69)	Acc@5  72.06 ( 72.06)
[TRAIN] E: [199][31/32]	Loss 0.0000e+00 (0.0000e+00)	Acc@1  41.00 ( 42.05)	Acc@5  71.75 ( 71.98)
[EVAL] E: [199][0/4]	Loss 4.2805e+00 (4.2805e+00)	Acc@1  52.25 ( 52.25)	Acc@5  83.12 ( 83.12)
[EVAL] E: [199][3/4]	Loss 4.2872e+00 (4.2856e+00)	Acc@1  50.50 ( 53.08)	Acc@5  82.00 ( 82.60)
		 Test evaluation at end of epoch: latest_acc:53.08 LR=0.1 -- best acc so far 53.62
