Main Function with logger : Logger(dir=meta_results, use-tf=False, writer=None)
Arguments : -------------------------------
batch_size       : 200
checkpoint_dir   : ./checkpoint
class_num        : 100
cutout_length    : 16
data_path        : /home/prathamesh/code/data/cifar/
dataset          : cifar100
epochs           : 200
eval_batch_size  : 200
eval_frequency   : 1
global_rand_seed : -1
input_size       : 32
inst_based       : True
log_dir          : ./log
lr               : 0.1
mcd_weight       : 0.01
meta_interval    : 1
meta_lr          : 0.01
meta_weight_decay : 0.0
model_name       : ResNet10_s
momentum         : 0.9
print_freq       : 100
print_freq_eval  : 100
rand_seed        : 53634
save_dir         : ./meta_results/
unsup_adapt      : False
wd               : 0.0005
workers          : 8
Python  Version  : 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0]
Pillow  Version  : 9.2.0
PyTorch Version  : 1.13.1
cuDNN   Version  : 8500
CUDA available   : True
CUDA GPU numbers : 1
CUDA_VISIBLE_DEVICES : 0
model information : EfficientNetV2_s (CIFAR)
--------------------------------------------------
[Student]Params=0.08 MB, FLOPs=4.16 M ... = 0.00 G
--------------------------------------------------
train_data : Dataset CIFAR100
    Number of datapoints: 50000
    Root location: /home/prathamesh/code/data/cifar/
    Split: Train
    StandardTransform
Transform: Compose(
               RandomCrop(size=(32, 32), padding=4)
               RandomHorizontalFlip(p=0.5)
               AutoAugment CIFAR10 Policy
               ToTensor()
               CUTOUT(length=16)
               Normalize(mean=[0.5070588235294118, 0.48666666666666664, 0.4407843137254902], std=[0.26745098039215687, 0.2564705882352941, 0.27607843137254906])
           )
valid_data : Dataset CIFAR100
    Number of datapoints: 10000
    Root location: /home/prathamesh/code/data/cifar/
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.5070588235294118, 0.48666666666666664, 0.4407843137254902], std=[0.26745098039215687, 0.2564705882352941, 0.27607843137254906])
           )
[TRAIN] E: [0][  0/250]	Loss 6.6108e-04 (6.6108e-04)	Acc@1  36.50 ( 36.50)	Acc@5  69.50 ( 69.50)
[TRAIN] E: [0][100/250]	Loss 5.6103e-08 (6.5966e-06)	Acc@1  47.00 ( 43.53)	Acc@5  75.50 ( 73.08)
[TRAIN] E: [0][200/250]	Loss 2.2650e-08 (3.3451e-06)	Acc@1  44.50 ( 43.02)	Acc@5  72.50 ( 72.68)
[TRAIN] E: [0][249/250]	Loss 1.3702e-07 (2.7009e-06)	Acc@1  39.00 ( 42.99)	Acc@5  69.00 ( 72.67)
[EVAL] E: [0][ 0/50]	Loss 1.6614e+00 (1.6614e+00)	Acc@1  59.00 ( 59.00)	Acc@5  80.00 ( 80.00)
[EVAL] E: [0][49/50]	Loss 1.6619e+00 (1.6960e+00)	Acc@1  55.00 ( 53.61)	Acc@5  84.00 ( 82.73)
		 LR=0.09990212389432412 -- best acc so far 53.61
***[2023-04-24 19:48:18]*** [Post-train] [Student] EVALUATION loss = 1.696024, accuracy@1 = 53.61, accuracy@5 = 82.73, error@1 = 46.39, error@5 = 17.27
[TRAIN] E: [1][  0/250]	Loss 2.6781e-07 (2.6781e-07)	Acc@1  45.50 ( 45.50)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [1][100/250]	Loss -4.4331e-09 (8.3364e-08)	Acc@1  41.00 ( 42.92)	Acc@5  69.00 ( 72.63)
[TRAIN] E: [1][200/250]	Loss 1.7576e-07 (7.8778e-08)	Acc@1  42.50 ( 42.51)	Acc@5  71.00 ( 72.17)
[TRAIN] E: [1][249/250]	Loss -3.8967e-08 (8.2988e-08)	Acc@1  39.50 ( 42.51)	Acc@5  71.50 ( 72.26)
[EVAL] E: [1][ 0/50]	Loss 1.7744e+00 (1.7744e+00)	Acc@1  60.00 ( 60.00)	Acc@5  80.50 ( 80.50)
[EVAL] E: [1][49/50]	Loss 1.7961e+00 (1.8255e+00)	Acc@1  56.00 ( 53.56)	Acc@5  85.00 ( 82.82)
		 LR=0.09960730848288585 -- best acc so far 53.61
***[2023-04-24 19:50:09]*** [Post-train] [Student] EVALUATION loss = 1.825505, accuracy@1 = 53.56, accuracy@5 = 82.82, error@1 = 46.44, error@5 = 17.18
[TRAIN] E: [2][  0/250]	Loss 2.6897e-08 (2.6897e-08)	Acc@1  41.00 ( 41.00)	Acc@5  74.00 ( 74.00)
[TRAIN] E: [2][100/250]	Loss -1.8843e-07 (1.0837e-07)	Acc@1  41.00 ( 42.73)	Acc@5  71.50 ( 72.65)
[TRAIN] E: [2][200/250]	Loss 3.3900e-07 (1.1320e-07)	Acc@1  40.00 ( 42.86)	Acc@5  73.50 ( 72.43)
[TRAIN] E: [2][249/250]	Loss 2.0698e-07 (1.1439e-07)	Acc@1  43.50 ( 42.81)	Acc@5  75.50 ( 72.43)
[EVAL] E: [2][ 0/50]	Loss 1.9828e+00 (1.9828e+00)	Acc@1  59.00 ( 59.00)	Acc@5  80.00 ( 80.00)
[EVAL] E: [2][49/50]	Loss 2.0300e+00 (2.0468e+00)	Acc@1  56.50 ( 53.61)	Acc@5  84.00 ( 82.73)
		 LR=0.0991167156882891 -- best acc so far 53.61
***[2023-04-24 19:51:57]*** [Post-train] [Student] EVALUATION loss = 2.046793, accuracy@1 = 53.61, accuracy@5 = 82.73, error@1 = 46.39, error@5 = 17.27
[TRAIN] E: [3][  0/250]	Loss 8.2105e-08 (8.2105e-08)	Acc@1  38.00 ( 38.00)	Acc@5  69.50 ( 69.50)
[TRAIN] E: [3][100/250]	Loss 1.3128e-07 (1.2001e-07)	Acc@1  40.50 ( 42.74)	Acc@5  70.00 ( 72.86)
[TRAIN] E: [3][200/250]	Loss 2.3961e-07 (1.2017e-07)	Acc@1  44.00 ( 42.88)	Acc@5  71.00 ( 72.84)
[TRAIN] E: [3][249/250]	Loss 5.9605e-09 (1.2158e-07)	Acc@1  51.50 ( 42.88)	Acc@5  74.00 ( 72.87)
[EVAL] E: [3][ 0/50]	Loss 2.2580e+00 (2.2580e+00)	Acc@1  60.00 ( 60.00)	Acc@5  79.50 ( 79.50)
[EVAL] E: [3][49/50]	Loss 2.3157e+00 (2.3250e+00)	Acc@1  56.50 ( 53.64)	Acc@5  84.00 ( 82.82)
		 LR=0.0984322816561636 -- best acc so far 53.64
***[2023-04-24 19:53:50]*** [Post-train] [Student] EVALUATION loss = 2.325027, accuracy@1 = 53.64, accuracy@5 = 82.82, error@1 = 46.36, error@5 = 17.18
[TRAIN] E: [4][  0/250]	Loss 2.1026e-07 (2.1026e-07)	Acc@1  44.50 ( 44.50)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [4][100/250]	Loss 6.4671e-08 (1.1308e-07)	Acc@1  43.50 ( 42.19)	Acc@5  69.50 ( 72.34)
[TRAIN] E: [4][200/250]	Loss 4.6298e-07 (1.2094e-07)	Acc@1  39.50 ( 42.55)	Acc@5  79.00 ( 72.58)
[TRAIN] E: [4][249/250]	Loss 9.2536e-08 (1.2264e-07)	Acc@1  40.50 ( 42.50)	Acc@5  73.50 ( 72.55)
[EVAL] E: [4][ 0/50]	Loss 2.5617e+00 (2.5617e+00)	Acc@1  59.50 ( 59.50)	Acc@5  79.50 ( 79.50)
[EVAL] E: [4][49/50]	Loss 2.6214e+00 (2.6316e+00)	Acc@1  56.00 ( 53.60)	Acc@5  83.00 ( 82.84)
		 LR=0.09755670753494601 -- best acc so far 53.64
***[2023-04-24 19:55:39]*** [Post-train] [Student] EVALUATION loss = 2.631602, accuracy@1 = 53.60, accuracy@5 = 82.84, error@1 = 46.40, error@5 = 17.16
[TRAIN] E: [5][  0/250]	Loss 1.9491e-07 (1.9491e-07)	Acc@1  44.00 ( 44.00)	Acc@5  72.00 ( 72.00)
[TRAIN] E: [5][100/250]	Loss 2.8163e-07 (1.2951e-07)	Acc@1  44.00 ( 42.27)	Acc@5  75.50 ( 72.42)
[TRAIN] E: [5][200/250]	Loss 1.4424e-07 (1.3151e-07)	Acc@1  38.50 ( 42.56)	Acc@5  67.50 ( 72.75)
[TRAIN] E: [5][249/250]	Loss -1.1474e-07 (1.3735e-07)	Acc@1  45.00 ( 42.78)	Acc@5  67.50 ( 72.68)
[EVAL] E: [5][ 0/50]	Loss 2.8847e+00 (2.8847e+00)	Acc@1  59.00 ( 59.00)	Acc@5  80.00 ( 80.00)
[EVAL] E: [5][49/50]	Loss 2.9391e+00 (2.9463e+00)	Acc@1  55.50 ( 53.69)	Acc@5  83.50 ( 82.73)
		 LR=0.09649344881568099 -- best acc so far 53.69
***[2023-04-24 19:57:28]*** [Post-train] [Student] EVALUATION loss = 2.946319, accuracy@1 = 53.69, accuracy@5 = 82.73, error@1 = 46.31, error@5 = 17.27
[TRAIN] E: [6][  0/250]	Loss -9.8348e-08 (-9.8348e-08)	Acc@1  41.00 ( 41.00)	Acc@5  73.50 ( 73.50)
[TRAIN] E: [6][100/250]	Loss 8.2552e-08 (1.3381e-07)	Acc@1  44.00 ( 42.73)	Acc@5  71.00 ( 72.51)
[TRAIN] E: [6][200/250]	Loss 2.4945e-07 (1.2894e-07)	Acc@1  44.50 ( 42.73)	Acc@5  79.50 ( 72.85)
[TRAIN] E: [6][249/250]	Loss -1.0729e-08 (1.3521e-07)	Acc@1  48.50 ( 42.63)	Acc@5  71.00 ( 72.77)
[EVAL] E: [6][ 0/50]	Loss 3.1788e+00 (3.1788e+00)	Acc@1  58.50 ( 58.50)	Acc@5  80.00 ( 80.00)
[EVAL] E: [6][49/50]	Loss 3.2259e+00 (3.2316e+00)	Acc@1  55.50 ( 53.61)	Acc@5  83.50 ( 82.70)
		 LR=0.09524670169477678 -- best acc so far 53.69
***[2023-04-24 19:59:15]*** [Post-train] [Student] EVALUATION loss = 3.231564, accuracy@1 = 53.61, accuracy@5 = 82.70, error@1 = 46.39, error@5 = 17.30
[TRAIN] E: [7][  0/250]	Loss 5.8442e-07 (5.8442e-07)	Acc@1  46.00 ( 46.00)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [7][100/250]	Loss 1.0341e-07 (1.5828e-07)	Acc@1  44.00 ( 42.40)	Acc@5  75.00 ( 72.18)
[TRAIN] E: [7][200/250]	Loss -3.9637e-08 (1.4396e-07)	Acc@1  40.00 ( 42.51)	Acc@5  72.00 ( 72.36)
[TRAIN] E: [7][249/250]	Loss 2.3127e-07 (1.3852e-07)	Acc@1  40.00 ( 42.38)	Acc@5  71.00 ( 72.30)
[EVAL] E: [7][ 0/50]	Loss 3.4408e+00 (3.4408e+00)	Acc@1  59.00 ( 59.00)	Acc@5  80.00 ( 80.00)
[EVAL] E: [7][49/50]	Loss 3.4791e+00 (3.4847e+00)	Acc@1  55.50 ( 53.56)	Acc@5  83.00 ( 82.65)
		 LR=0.093821386513535 -- best acc so far 53.69
***[2023-04-24 20:01:06]*** [Post-train] [Student] EVALUATION loss = 3.484740, accuracy@1 = 53.56, accuracy@5 = 82.65, error@1 = 46.44, error@5 = 17.35
[TRAIN] E: [8][  0/250]	Loss 1.3530e-07 (1.3530e-07)	Acc@1  36.50 ( 36.50)	Acc@5  71.50 ( 71.50)
[TRAIN] E: [8][100/250]	Loss 4.6551e-07 (1.5032e-07)	Acc@1  43.50 ( 42.67)	Acc@5  66.50 ( 72.12)
[TRAIN] E: [8][200/250]	Loss -1.0252e-07 (1.4051e-07)	Acc@1  44.50 ( 42.74)	Acc@5  74.00 ( 72.32)
[TRAIN] E: [8][249/250]	Loss 3.2783e-09 (1.4800e-07)	Acc@1  39.50 ( 42.82)	Acc@5  69.00 ( 72.52)
[EVAL] E: [8][ 0/50]	Loss 3.6645e+00 (3.6645e+00)	Acc@1  59.00 ( 59.00)	Acc@5  80.00 ( 80.00)
[EVAL] E: [8][49/50]	Loss 3.6946e+00 (3.6999e+00)	Acc@1  55.50 ( 53.45)	Acc@5  83.00 ( 82.72)
		 LR=0.09222312833981147 -- best acc so far 53.69
***[2023-04-24 20:02:53]*** [Post-train] [Student] EVALUATION loss = 3.699947, accuracy@1 = 53.45, accuracy@5 = 82.72, error@1 = 46.55, error@5 = 17.28
[TRAIN] E: [9][  0/250]	Loss 2.0921e-07 (2.0921e-07)	Acc@1  46.00 ( 46.00)	Acc@5  78.00 ( 78.00)
[TRAIN] E: [9][100/250]	Loss 1.2070e-07 (1.4396e-07)	Acc@1  43.50 ( 43.36)	Acc@5  74.00 ( 72.89)
[TRAIN] E: [9][200/250]	Loss -6.6757e-08 (1.3764e-07)	Acc@1  40.50 ( 42.69)	Acc@5  73.50 ( 72.70)
[TRAIN] E: [9][249/250]	Loss -1.5199e-08 (1.3409e-07)	Acc@1  46.00 ( 42.47)	Acc@5  72.50 ( 72.51)
[EVAL] E: [9][ 0/50]	Loss 3.8454e+00 (3.8454e+00)	Acc@1  58.00 ( 58.00)	Acc@5  79.50 ( 79.50)
[EVAL] E: [9][49/50]	Loss 3.8699e+00 (3.8740e+00)	Acc@1  54.00 ( 53.23)	Acc@5  84.00 ( 82.61)
		 LR=0.09045823476844315 -- best acc so far 53.69
***[2023-04-24 20:04:43]*** [Post-train] [Student] EVALUATION loss = 3.873993, accuracy@1 = 53.23, accuracy@5 = 82.61, error@1 = 46.77, error@5 = 17.39
[TRAIN] E: [10][  0/250]	Loss 3.4392e-07 (3.4392e-07)	Acc@1  44.00 ( 44.00)	Acc@5  74.50 ( 74.50)
[TRAIN] E: [10][100/250]	Loss 2.5362e-07 (9.8743e-08)	Acc@1  40.50 ( 42.32)	Acc@5  73.50 ( 72.54)
[TRAIN] E: [10][200/250]	Loss 1.1951e-07 (1.0616e-07)	Acc@1  41.50 ( 42.49)	Acc@5  66.50 ( 72.58)
[TRAIN] E: [10][249/250]	Loss 5.1260e-08 (1.1012e-07)	Acc@1  47.00 ( 42.47)	Acc@5  77.00 ( 72.47)
[EVAL] E: [10][ 0/50]	Loss 3.9980e+00 (3.9980e+00)	Acc@1  58.50 ( 58.50)	Acc@5  79.00 ( 79.00)
[EVAL] E: [10][49/50]	Loss 4.0162e+00 (4.0199e+00)	Acc@1  53.00 ( 53.30)	Acc@5  83.00 ( 82.56)
		 LR=0.08853367102805307 -- best acc so far 53.69
***[2023-04-24 20:06:36]*** [Post-train] [Student] EVALUATION loss = 4.019855, accuracy@1 = 53.30, accuracy@5 = 82.56, error@1 = 46.70, error@5 = 17.44
[TRAIN] E: [11][  0/250]	Loss 2.4498e-07 (2.4498e-07)	Acc@1  51.00 ( 51.00)	Acc@5  81.00 ( 81.00)
[TRAIN] E: [11][100/250]	Loss 2.9564e-07 (1.0691e-07)	Acc@1  40.00 ( 42.12)	Acc@5  71.50 ( 72.33)
[TRAIN] E: [11][200/250]	Loss 1.8418e-07 (1.0919e-07)	Acc@1  43.00 ( 42.37)	Acc@5  69.00 ( 72.23)
[TRAIN] E: [11][249/250]	Loss 1.3500e-07 (1.1129e-07)	Acc@1  47.00 ( 42.22)	Acc@5  75.00 ( 72.13)
[EVAL] E: [11][ 0/50]	Loss 4.1165e+00 (4.1165e+00)	Acc@1  58.00 ( 58.00)	Acc@5  79.00 ( 79.00)
[EVAL] E: [11][49/50]	Loss 4.1319e+00 (4.1344e+00)	Acc@1  54.00 ( 53.26)	Acc@5  82.50 ( 82.42)
		 LR=0.086457032492475 -- best acc so far 53.69
***[2023-04-24 20:08:31]*** [Post-train] [Student] EVALUATION loss = 4.134380, accuracy@1 = 53.26, accuracy@5 = 82.42, error@1 = 46.74, error@5 = 17.58
[TRAIN] E: [12][  0/250]	Loss -1.8448e-07 (-1.8448e-07)	Acc@1  42.50 ( 42.50)	Acc@5  77.50 ( 77.50)
[TRAIN] E: [12][100/250]	Loss 8.3148e-08 (1.0278e-07)	Acc@1  46.00 ( 42.13)	Acc@5  74.00 ( 71.97)
[TRAIN] E: [12][200/250]	Loss 4.3124e-07 (8.2879e-08)	Acc@1  46.00 ( 42.23)	Acc@5  71.50 ( 72.11)
[TRAIN] E: [12][249/250]	Loss 4.7088e-08 (8.4064e-08)	Acc@1  47.00 ( 41.99)	Acc@5  68.50 ( 72.06)
[EVAL] E: [12][ 0/50]	Loss 4.2173e+00 (4.2173e+00)	Acc@1  58.50 ( 58.50)	Acc@5  79.00 ( 79.00)
[EVAL] E: [12][49/50]	Loss 4.2294e+00 (4.2312e+00)	Acc@1  53.00 ( 53.05)	Acc@5  82.00 ( 82.24)
		 LR=0.08423651470528296 -- best acc so far 53.69
***[2023-04-24 20:10:24]*** [Post-train] [Student] EVALUATION loss = 4.231240, accuracy@1 = 53.05, accuracy@5 = 82.24, error@1 = 46.95, error@5 = 17.76
[TRAIN] E: [13][  0/250]	Loss -1.3292e-07 (-1.3292e-07)	Acc@1  40.00 ( 40.00)	Acc@5  68.50 ( 68.50)
[TRAIN] E: [13][100/250]	Loss 1.9461e-07 (9.3606e-08)	Acc@1  41.50 ( 41.82)	Acc@5  70.50 ( 71.81)
[TRAIN] E: [13][200/250]	Loss 1.9848e-07 (9.0592e-08)	Acc@1  39.00 ( 41.86)	Acc@5  76.00 ( 72.01)
[TRAIN] E: [13][249/250]	Loss -1.4395e-07 (9.0333e-08)	Acc@1  42.50 ( 41.80)	Acc@5  74.00 ( 71.90)
[EVAL] E: [13][ 0/50]	Loss 4.2982e+00 (4.2982e+00)	Acc@1  58.50 ( 58.50)	Acc@5  79.00 ( 79.00)
[EVAL] E: [13][49/50]	Loss 4.3079e+00 (4.3093e+00)	Acc@1  54.00 ( 53.05)	Acc@5  82.00 ( 82.06)
		 LR=0.08188088103572494 -- best acc so far 53.69
***[2023-04-24 20:12:13]*** [Post-train] [Student] EVALUATION loss = 4.309323, accuracy@1 = 53.05, accuracy@5 = 82.06, error@1 = 46.95, error@5 = 17.94
[TRAIN] E: [14][  0/250]	Loss 5.6922e-08 (5.6922e-08)	Acc@1  46.00 ( 46.00)	Acc@5  78.00 ( 78.00)
[TRAIN] E: [14][100/250]	Loss 1.6928e-07 (6.0469e-08)	Acc@1  42.00 ( 41.16)	Acc@5  70.00 ( 71.56)
[TRAIN] E: [14][200/250]	Loss -4.7982e-08 (6.5313e-08)	Acc@1  44.00 ( 41.11)	Acc@5  72.00 ( 71.44)
[TRAIN] E: [14][249/250]	Loss -1.4156e-07 (7.0275e-08)	Acc@1  41.50 ( 40.97)	Acc@5  73.50 ( 71.32)
[EVAL] E: [14][ 0/50]	Loss 4.3632e+00 (4.3632e+00)	Acc@1  58.50 ( 58.50)	Acc@5  78.50 ( 78.50)
[EVAL] E: [14][49/50]	Loss 4.3712e+00 (4.3720e+00)	Acc@1  53.50 ( 52.30)	Acc@5  82.50 ( 81.77)
		 LR=0.079399428093708 -- best acc so far 53.69
***[2023-04-24 20:14:02]*** [Post-train] [Student] EVALUATION loss = 4.372030, accuracy@1 = 52.30, accuracy@5 = 81.77, error@1 = 47.70, error@5 = 18.23
[TRAIN] E: [15][  0/250]	Loss 8.3447e-09 (8.3447e-09)	Acc@1  37.50 ( 37.50)	Acc@5  70.00 ( 70.00)
[TRAIN] E: [15][100/250]	Loss 9.5367e-08 (5.8227e-08)	Acc@1  38.50 ( 40.62)	Acc@5  71.00 ( 70.66)
[TRAIN] E: [15][200/250]	Loss -9.4473e-08 (5.3188e-08)	Acc@1  40.00 ( 40.50)	Acc@5  74.50 ( 70.66)
[TRAIN] E: [15][249/250]	Loss 1.9938e-07 (5.3183e-08)	Acc@1  39.50 ( 40.30)	Acc@5  70.00 ( 70.52)
[EVAL] E: [15][ 0/50]	Loss 4.4166e+00 (4.4166e+00)	Acc@1  57.50 ( 57.50)	Acc@5  79.00 ( 79.00)
[EVAL] E: [15][49/50]	Loss 4.4230e+00 (4.4235e+00)	Acc@1  52.50 ( 51.77)	Acc@5  82.00 ( 81.49)
		 LR=0.07680194904032629 -- best acc so far 53.69
***[2023-04-24 20:15:58]*** [Post-train] [Student] EVALUATION loss = 4.423476, accuracy@1 = 51.77, accuracy@5 = 81.49, error@1 = 48.23, error@5 = 18.51
[TRAIN] E: [16][  0/250]	Loss -7.3016e-08 (-7.3016e-08)	Acc@1  37.50 ( 37.50)	Acc@5  70.50 ( 70.50)
[TRAIN] E: [16][100/250]	Loss -1.3679e-07 (3.0643e-08)	Acc@1  37.00 ( 39.46)	Acc@5  69.00 ( 69.63)
[TRAIN] E: [16][200/250]	Loss 8.0764e-08 (9.2091e-09)	Acc@1  36.50 ( 39.36)	Acc@5  68.50 ( 69.69)
[TRAIN] E: [16][249/250]	Loss 4.2915e-08 (1.7610e-08)	Acc@1  45.50 ( 39.32)	Acc@5  75.50 ( 69.71)
[EVAL] E: [16][ 0/50]	Loss 4.4608e+00 (4.4608e+00)	Acc@1  57.50 ( 57.50)	Acc@5  79.50 ( 79.50)
[EVAL] E: [16][49/50]	Loss 4.4658e+00 (4.4660e+00)	Acc@1  51.00 ( 50.88)	Acc@5  81.50 ( 80.75)
		 LR=0.07409869493872821 -- best acc so far 53.69
***[2023-04-24 20:17:47]*** [Post-train] [Student] EVALUATION loss = 4.466021, accuracy@1 = 50.88, accuracy@5 = 80.75, error@1 = 49.12, error@5 = 19.25
[TRAIN] E: [17][  0/250]	Loss -2.7150e-07 (-2.7150e-07)	Acc@1  41.00 ( 41.00)	Acc@5  71.00 ( 71.00)
[TRAIN] E: [17][100/250]	Loss 5.9605e-08 (-1.2665e-08)	Acc@1  39.50 ( 38.67)	Acc@5  67.00 ( 68.70)
[TRAIN] E: [17][200/250]	Loss -5.4240e-08 (-2.1185e-08)	Acc@1  39.50 ( 37.96)	Acc@5  66.00 ( 68.44)
[TRAIN] E: [17][249/250]	Loss -6.7949e-08 (-2.1884e-08)	Acc@1  36.50 ( 37.68)	Acc@5  61.00 ( 68.22)
[EVAL] E: [17][ 0/50]	Loss 4.4960e+00 (4.4960e+00)	Acc@1  56.50 ( 56.50)	Acc@5  79.50 ( 79.50)
[EVAL] E: [17][49/50]	Loss 4.4998e+00 (4.4998e+00)	Acc@1  51.00 ( 49.41)	Acc@5  80.50 ( 79.74)
		 LR=0.07130033429785342 -- best acc so far 53.69
***[2023-04-24 20:19:36]*** [Post-train] [Student] EVALUATION loss = 4.499814, accuracy@1 = 49.41, accuracy@5 = 79.74, error@1 = 50.59, error@5 = 20.26
[TRAIN] E: [18][  0/250]	Loss 3.5256e-07 (3.5256e-07)	Acc@1  36.50 ( 36.50)	Acc@5  71.00 ( 71.00)
[TRAIN] E: [18][100/250]	Loss -2.2352e-07 (-6.5114e-08)	Acc@1  34.50 ( 36.63)	Acc@5  61.00 ( 66.45)
[TRAIN] E: [18][200/250]	Loss -2.0981e-07 (-7.1321e-08)	Acc@1  32.50 ( 35.99)	Acc@5  63.00 ( 65.96)
[TRAIN] E: [18][249/250]	Loss -1.8746e-07 (-6.7129e-08)	Acc@1  35.00 ( 35.59)	Acc@5  62.00 ( 65.66)
[EVAL] E: [18][ 0/50]	Loss 4.5243e+00 (4.5243e+00)	Acc@1  53.00 ( 53.00)	Acc@5  80.00 ( 80.00)
[EVAL] E: [18][49/50]	Loss 4.5273e+00 (4.5271e+00)	Acc@1  45.50 ( 47.11)	Acc@5  79.50 ( 78.02)
		 LR=0.06841791096870209 -- best acc so far 53.69
***[2023-04-24 20:21:25]*** [Post-train] [Student] EVALUATION loss = 4.527053, accuracy@1 = 47.11, accuracy@5 = 78.02, error@1 = 52.89, error@5 = 21.98
[TRAIN] E: [19][  0/250]	Loss -1.2130e-07 (-1.2130e-07)	Acc@1  36.00 ( 36.00)	Acc@5  66.50 ( 66.50)
[TRAIN] E: [19][100/250]	Loss -1.7345e-07 (-7.0894e-08)	Acc@1  35.50 ( 33.52)	Acc@5  66.50 ( 63.57)
[TRAIN] E: [19][200/250]	Loss -3.3736e-07 (-7.5541e-08)	Acc@1  27.50 ( 32.57)	Acc@5  54.50 ( 62.22)
[TRAIN] E: [19][249/250]	Loss 8.1658e-08 (-6.8539e-08)	Acc@1  28.50 ( 32.24)	Acc@5  61.00 ( 61.76)
[EVAL] E: [19][ 0/50]	Loss 4.5466e+00 (4.5466e+00)	Acc@1  50.00 ( 50.00)	Acc@5  78.00 ( 78.00)
[EVAL] E: [19][49/50]	Loss 4.5488e+00 (4.5484e+00)	Acc@1  40.00 ( 43.31)	Acc@5  76.00 ( 74.62)
		 LR=0.06546280055930045 -- best acc so far 53.69
***[2023-04-24 20:23:15]*** [Post-train] [Student] EVALUATION loss = 4.548436, accuracy@1 = 43.31, accuracy@5 = 74.62, error@1 = 56.69, error@5 = 25.38
[TRAIN] E: [20][  0/250]	Loss -3.5763e-09 (-3.5763e-09)	Acc@1  28.50 ( 28.50)	Acc@5  57.00 ( 57.00)
[TRAIN] E: [20][100/250]	Loss -3.2395e-07 (-8.8404e-08)	Acc@1  28.00 ( 29.25)	Acc@5  52.00 ( 57.59)
[TRAIN] E: [20][200/250]	Loss 1.0163e-07 (-7.3351e-08)	Acc@1  35.00 ( 28.11)	Acc@5  55.50 ( 56.14)
[TRAIN] E: [20][249/250]	Loss -1.3828e-07 (-7.1305e-08)	Acc@1  23.50 ( 27.60)	Acc@5  50.00 ( 55.52)
[EVAL] E: [20][ 0/50]	Loss 4.5643e+00 (4.5643e+00)	Acc@1  39.00 ( 39.00)	Acc@5  75.00 ( 75.00)
[EVAL] E: [20][49/50]	Loss 4.5657e+00 (4.5653e+00)	Acc@1  35.50 ( 37.05)	Acc@5  67.50 ( 68.50)
		 LR=0.06244666554037285 -- best acc so far 53.69
***[2023-04-24 20:25:09]*** [Post-train] [Student] EVALUATION loss = 4.565290, accuracy@1 = 37.05, accuracy@5 = 68.50, error@1 = 62.95, error@5 = 31.50
[TRAIN] E: [21][  0/250]	Loss 1.8477e-07 (1.8477e-07)	Acc@1  21.00 ( 21.00)	Acc@5  48.00 ( 48.00)
[TRAIN] E: [21][100/250]	Loss -1.9073e-08 (-7.3656e-08)	Acc@1  19.50 ( 23.06)	Acc@5  47.50 ( 49.94)
[TRAIN] E: [21][200/250]	Loss 1.6153e-07 (-5.5738e-08)	Acc@1  25.50 ( 21.77)	Acc@5  45.00 ( 47.53)
[TRAIN] E: [21][249/250]	Loss 1.3113e-08 (-4.8975e-08)	Acc@1  15.50 ( 21.19)	Acc@5  38.50 ( 46.56)
[EVAL] E: [21][ 0/50]	Loss 4.5783e+00 (4.5783e+00)	Acc@1  28.50 ( 28.50)	Acc@5  60.50 ( 60.50)
[EVAL] E: [21][49/50]	Loss 4.5791e+00 (4.5787e+00)	Acc@1  26.50 ( 28.65)	Acc@5  54.00 ( 58.27)
		 LR=0.059381409218897986 -- best acc so far 53.69
***[2023-04-24 20:26:58]*** [Post-train] [Student] EVALUATION loss = 4.578739, accuracy@1 = 28.65, accuracy@5 = 58.27, error@1 = 71.35, error@5 = 41.73
[TRAIN] E: [22][  0/250]	Loss -1.2606e-07 (-1.2606e-07)	Acc@1  15.50 ( 15.50)	Acc@5  42.00 ( 42.00)
[TRAIN] E: [22][100/250]	Loss 8.5831e-08 (-3.3665e-08)	Acc@1  15.00 ( 16.34)	Acc@5  35.00 ( 38.61)
[TRAIN] E: [22][200/250]	Loss -1.9044e-07 (-4.5049e-08)	Acc@1  14.00 ( 15.29)	Acc@5  29.50 ( 36.38)
[TRAIN] E: [22][249/250]	Loss -2.5332e-07 (-4.8624e-08)	Acc@1  14.00 ( 14.75)	Acc@5  33.50 ( 35.49)
[EVAL] E: [22][ 0/50]	Loss 4.5881e+00 (4.5881e+00)	Acc@1  18.00 ( 18.00)	Acc@5  48.00 ( 48.00)
[EVAL] E: [22][49/50]	Loss 4.5884e+00 (4.5881e+00)	Acc@1  18.50 ( 19.08)	Acc@5  41.00 ( 45.31)
		 LR=0.05627912876119434 -- best acc so far 53.69
***[2023-04-24 20:28:49]*** [Post-train] [Student] EVALUATION loss = 4.588088, accuracy@1 = 19.08, accuracy@5 = 45.31, error@1 = 80.92, error@5 = 54.69
[TRAIN] E: [23][  0/250]	Loss 1.4782e-07 (1.4782e-07)	Acc@1  10.50 ( 10.50)	Acc@5  26.00 ( 26.00)
[TRAIN] E: [23][100/250]	Loss -1.0312e-07 (-1.3868e-08)	Acc@1  10.00 ( 10.69)	Acc@5  24.00 ( 28.18)
[TRAIN] E: [23][200/250]	Loss 3.0875e-07 (-1.4539e-08)	Acc@1   7.00 (  9.86)	Acc@5  16.00 ( 26.20)
[TRAIN] E: [23][249/250]	Loss -2.4140e-08 (-1.8251e-08)	Acc@1   6.50 (  9.34)	Acc@5  19.00 ( 25.16)
[EVAL] E: [23][ 0/50]	Loss 4.5948e+00 (4.5948e+00)	Acc@1  10.00 ( 10.00)	Acc@5  30.00 ( 30.00)
[EVAL] E: [23][49/50]	Loss 4.5947e+00 (4.5946e+00)	Acc@1  11.50 ( 10.65)	Acc@5  30.00 ( 31.95)
		 LR=0.05315206745093131 -- best acc so far 53.69
***[2023-04-24 20:30:38]*** [Post-train] [Student] EVALUATION loss = 4.594564, accuracy@1 = 10.65, accuracy@5 = 31.95, error@1 = 89.35, error@5 = 68.05
[TRAIN] E: [24][  0/250]	Loss 1.4395e-07 (1.4395e-07)	Acc@1   8.00 (  8.00)	Acc@5  20.50 ( 20.50)
[TRAIN] E: [24][100/250]	Loss 8.9407e-10 (1.9501e-08)	Acc@1   3.50 (  6.40)	Acc@5  14.00 ( 18.20)
[TRAIN] E: [24][200/250]	Loss 2.0295e-07 (2.7987e-08)	Acc@1   6.50 (  6.01)	Acc@5  12.00 ( 16.90)
[TRAIN] E: [24][249/250]	Loss -1.3232e-07 (3.8238e-08)	Acc@1   4.50 (  5.75)	Acc@5  12.50 ( 16.17)
[EVAL] E: [24][ 0/50]	Loss 4.5993e+00 (4.5993e+00)	Acc@1   6.00 (  6.00)	Acc@5  17.50 ( 17.50)
[EVAL] E: [24][49/50]	Loss 4.5990e+00 (4.5989e+00)	Acc@1   6.00 (  5.57)	Acc@5  15.00 ( 18.89)
		 LR=0.05001256637048207 -- best acc so far 53.69
***[2023-04-24 20:32:27]*** [Post-train] [Student] EVALUATION loss = 4.598896, accuracy@1 = 5.57, accuracy@5 = 18.89, error@1 = 94.43, error@5 = 81.11
[TRAIN] E: [25][  0/250]	Loss 1.5497e-08 (1.5497e-08)	Acc@1   2.50 (  2.50)	Acc@5  12.00 ( 12.00)
[TRAIN] E: [25][100/250]	Loss 8.9407e-09 (3.1127e-08)	Acc@1   2.50 (  3.71)	Acc@5  11.00 ( 11.35)
[TRAIN] E: [25][200/250]	Loss 4.0233e-08 (6.0749e-08)	Acc@1   3.50 (  3.45)	Acc@5  10.50 ( 10.60)
[TRAIN] E: [25][249/250]	Loss 2.1011e-07 (5.6214e-08)	Acc@1   3.00 (  3.30)	Acc@5  10.00 ( 10.18)
[EVAL] E: [25][ 0/50]	Loss 4.6023e+00 (4.6023e+00)	Acc@1   3.50 (  3.50)	Acc@5   9.50 (  9.50)
[EVAL] E: [25][49/50]	Loss 4.6018e+00 (4.6018e+00)	Acc@1   1.50 (  2.57)	Acc@5  10.00 ( 10.17)
		 LR=0.04687301569630958 -- best acc so far 53.69
***[2023-04-24 20:34:18]*** [Post-train] [Student] EVALUATION loss = 4.601760, accuracy@1 = 2.57, accuracy@5 = 10.17, error@1 = 97.43, error@5 = 89.83
[TRAIN] E: [26][  0/250]	Loss 2.0206e-07 (2.0206e-07)	Acc@1   3.00 (  3.00)	Acc@5   8.50 (  8.50)
[TRAIN] E: [26][100/250]	Loss -9.9838e-08 (8.1641e-08)	Acc@1   2.50 (  2.31)	Acc@5   9.00 (  7.76)
[TRAIN] E: [26][200/250]	Loss 3.1412e-07 (9.0964e-08)	Acc@1   1.00 (  2.03)	Acc@5   5.50 (  7.24)
[TRAIN] E: [26][249/250]	Loss 8.3447e-09 (8.0851e-08)	Acc@1   2.00 (  1.90)	Acc@5   6.00 (  7.03)
[EVAL] E: [26][ 0/50]	Loss 4.6040e+00 (4.6040e+00)	Acc@1   2.00 (  2.00)	Acc@5   8.50 (  8.50)
[EVAL] E: [26][49/50]	Loss 4.6035e+00 (4.6035e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.50 (  6.60)
		 LR=0.04374580580060053 -- best acc so far 53.69
***[2023-04-24 20:36:09]*** [Post-train] [Student] EVALUATION loss = 4.603462, accuracy@1 = 1.50, accuracy@5 = 6.60, error@1 = 98.50, error@5 = 93.40
[TRAIN] E: [27][  0/250]	Loss 2.9504e-07 (2.9504e-07)	Acc@1   2.00 (  2.00)	Acc@5   7.00 (  7.00)
[TRAIN] E: [27][100/250]	Loss 6.3181e-08 (8.4895e-08)	Acc@1   1.50 (  1.36)	Acc@5   5.50 (  6.39)
[TRAIN] E: [27][200/250]	Loss -2.8610e-08 (1.0288e-07)	Acc@1   0.50 (  1.24)	Acc@5   5.00 (  6.00)
[TRAIN] E: [27][249/250]	Loss 3.0905e-07 (1.0551e-07)	Acc@1   1.50 (  1.15)	Acc@5   7.50 (  5.85)
[EVAL] E: [27][ 0/50]	Loss 4.6049e+00 (4.6049e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [27][49/50]	Loss 4.6044e+00 (4.6044e+00)	Acc@1   1.50 (  1.06)	Acc@5   5.50 (  5.28)
		 LR=0.04064327835212695 -- best acc so far 53.69
***[2023-04-24 20:37:59]*** [Post-train] [Student] EVALUATION loss = 4.604398, accuracy@1 = 1.06, accuracy@5 = 5.28, error@1 = 98.94, error@5 = 94.72
[TRAIN] E: [28][  0/250]	Loss 3.4451e-07 (3.4451e-07)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [28][100/250]	Loss 1.3411e-08 (1.1447e-07)	Acc@1   0.50 (  1.04)	Acc@5   8.00 (  5.53)
[TRAIN] E: [28][200/250]	Loss -4.6194e-08 (1.0510e-07)	Acc@1   2.50 (  1.00)	Acc@5   7.00 (  5.36)
[TRAIN] E: [28][249/250]	Loss 4.5300e-08 (1.0902e-07)	Acc@1   2.00 (  1.00)	Acc@5   4.50 (  5.31)
[EVAL] E: [28][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [28][49/50]	Loss 4.6048e+00 (4.6048e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.04)
		 LR=0.03757767760931802 -- best acc so far 53.69
***[2023-04-24 20:39:54]*** [Post-train] [Student] EVALUATION loss = 4.604841, accuracy@1 = 1.00, accuracy@5 = 5.04, error@1 = 99.00, error@5 = 94.96
[TRAIN] E: [29][  0/250]	Loss -1.5587e-07 (-1.5587e-07)	Acc@1   0.50 (  0.50)	Acc@5   2.50 (  2.50)
[TRAIN] E: [29][100/250]	Loss 1.6659e-07 (1.0928e-07)	Acc@1   1.00 (  1.10)	Acc@5   5.50 (  5.15)
[TRAIN] E: [29][200/250]	Loss 7.2420e-08 (1.1646e-07)	Acc@1   0.50 (  1.01)	Acc@5   6.00 (  5.09)
[TRAIN] E: [29][249/250]	Loss 3.2783e-08 (1.2127e-07)	Acc@1   2.00 (  1.00)	Acc@5   6.00 (  5.13)
[EVAL] E: [29][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [29][49/50]	Loss 4.6050e+00 (4.6050e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.03)
		 LR=0.034561102097765854 -- best acc so far 53.69
***[2023-04-24 20:41:44]*** [Post-train] [Student] EVALUATION loss = 4.605023, accuracy@1 = 1.00, accuracy@5 = 5.03, error@1 = 99.00, error@5 = 94.97
[TRAIN] E: [30][  0/250]	Loss 7.0333e-08 (7.0333e-08)	Acc@1   0.00 (  0.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [30][100/250]	Loss 3.4839e-07 (9.8799e-08)	Acc@1   1.50 (  0.97)	Acc@5   6.50 (  5.28)
[TRAIN] E: [30][200/250]	Loss 1.0669e-07 (1.1373e-07)	Acc@1   0.50 (  1.02)	Acc@5   4.00 (  5.16)
[TRAIN] E: [30][249/250]	Loss 6.7353e-08 (1.1700e-07)	Acc@1   2.50 (  1.00)	Acc@5   4.00 (  5.11)
[EVAL] E: [30][ 0/50]	Loss 4.6056e+00 (4.6056e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [30][49/50]	Loss 4.6051e+00 (4.6051e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.04)
		 LR=0.0316054568628723 -- best acc so far 53.69
***[2023-04-24 20:43:40]*** [Post-train] [Student] EVALUATION loss = 4.605098, accuracy@1 = 1.00, accuracy@5 = 5.04, error@1 = 99.00, error@5 = 94.96
[TRAIN] E: [31][  0/250]	Loss 3.8803e-07 (3.8803e-07)	Acc@1   2.00 (  2.00)	Acc@5   6.50 (  6.50)
[TRAIN] E: [31][100/250]	Loss 2.7418e-07 (1.4108e-07)	Acc@1   1.00 (  0.93)	Acc@5   6.50 (  5.01)
[TRAIN] E: [31][200/250]	Loss 4.7714e-07 (1.5318e-07)	Acc@1   2.50 (  0.95)	Acc@5   8.00 (  5.03)
[TRAIN] E: [31][249/250]	Loss 1.1384e-07 (1.5302e-07)	Acc@1   0.00 (  1.00)	Acc@5   2.50 (  5.07)
[EVAL] E: [31][ 0/50]	Loss 4.6056e+00 (4.6056e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [31][49/50]	Loss 4.6051e+00 (4.6051e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.04)
		 LR=0.028722406486073566 -- best acc so far 53.69
***[2023-04-24 20:45:28]*** [Post-train] [Student] EVALUATION loss = 4.605132, accuracy@1 = 1.00, accuracy@5 = 5.04, error@1 = 99.00, error@5 = 94.96
[TRAIN] E: [32][  0/250]	Loss -9.3579e-08 (-9.3579e-08)	Acc@1   0.50 (  0.50)	Acc@5   2.50 (  2.50)
[TRAIN] E: [32][100/250]	Loss 2.5034e-08 (1.0660e-07)	Acc@1   0.00 (  1.00)	Acc@5   2.00 (  5.01)
[TRAIN] E: [32][200/250]	Loss 1.7256e-07 (1.3015e-07)	Acc@1   2.50 (  0.99)	Acc@5   8.50 (  5.09)
[TRAIN] E: [32][249/250]	Loss 3.6448e-07 (1.3324e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.10)
[EVAL] E: [32][ 0/50]	Loss 4.6056e+00 (4.6056e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [32][49/50]	Loss 4.6052e+00 (4.6051e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.08)
		 LR=0.02592332905006647 -- best acc so far 53.69
***[2023-04-24 20:47:17]*** [Post-train] [Student] EVALUATION loss = 4.605149, accuracy@1 = 1.00, accuracy@5 = 5.08, error@1 = 99.00, error@5 = 94.92
[TRAIN] E: [33][  0/250]	Loss 3.4958e-07 (3.4958e-07)	Acc@1   1.50 (  1.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [33][100/250]	Loss 2.6911e-07 (1.5051e-07)	Acc@1   1.00 (  1.11)	Acc@5   6.50 (  4.98)
[TRAIN] E: [33][200/250]	Loss 8.3148e-08 (1.5997e-07)	Acc@1   3.00 (  1.03)	Acc@5   6.50 (  5.13)
[TRAIN] E: [33][249/250]	Loss 3.5882e-07 (1.5972e-07)	Acc@1   1.50 (  1.00)	Acc@5   3.00 (  5.12)
[EVAL] E: [33][ 0/50]	Loss 4.6056e+00 (4.6056e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [33][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.10)
		 LR=0.02321927123471414 -- best acc so far 53.69
***[2023-04-24 20:49:07]*** [Post-train] [Student] EVALUATION loss = 4.605159, accuracy@1 = 1.00, accuracy@5 = 5.10, error@1 = 99.00, error@5 = 94.90
[TRAIN] E: [34][  0/250]	Loss 1.0788e-07 (1.0788e-07)	Acc@1   0.00 (  0.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [34][100/250]	Loss 2.8014e-07 (2.0174e-07)	Acc@1   1.00 (  0.98)	Acc@5   4.00 (  5.09)
[TRAIN] E: [34][200/250]	Loss -3.2187e-08 (1.7367e-07)	Acc@1   0.50 (  0.96)	Acc@5   8.00 (  5.19)
[TRAIN] E: [34][249/250]	Loss 9.6858e-08 (1.8076e-07)	Acc@1   2.00 (  1.00)	Acc@5   5.50 (  5.18)
[EVAL] E: [34][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   7.00 (  7.00)
[EVAL] E: [34][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   4.50 (  5.27)
		 LR=0.020620904720847207 -- best acc so far 53.69
***[2023-04-24 20:50:56]*** [Post-train] [Student] EVALUATION loss = 4.605165, accuracy@1 = 1.00, accuracy@5 = 5.27, error@1 = 99.00, error@5 = 94.73
[TRAIN] E: [35][  0/250]	Loss -2.5928e-08 (-2.5928e-08)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [35][100/250]	Loss 2.1100e-07 (1.7032e-07)	Acc@1   2.50 (  1.02)	Acc@5   7.50 (  5.00)
[TRAIN] E: [35][200/250]	Loss 2.2471e-07 (1.7563e-07)	Acc@1   0.00 (  1.05)	Acc@5   6.00 (  5.12)
[TRAIN] E: [35][249/250]	Loss 1.8686e-07 (1.8528e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.02)
[EVAL] E: [35][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   7.00 (  7.00)
[EVAL] E: [35][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.01)
		 LR=0.018138484074015183 -- best acc so far 53.69
***[2023-04-24 20:52:46]*** [Post-train] [Student] EVALUATION loss = 4.605168, accuracy@1 = 1.00, accuracy@5 = 5.01, error@1 = 99.00, error@5 = 94.99
[TRAIN] E: [36][  0/250]	Loss 2.8074e-07 (2.8074e-07)	Acc@1   1.50 (  1.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [36][100/250]	Loss -6.5565e-08 (1.3318e-07)	Acc@1   0.00 (  1.05)	Acc@5   2.50 (  4.96)
[TRAIN] E: [36][200/250]	Loss 2.7776e-07 (1.5617e-07)	Acc@1   0.50 (  1.01)	Acc@5   5.00 (  4.98)
[TRAIN] E: [36][249/250]	Loss 1.1772e-07 (1.6261e-07)	Acc@1   1.50 (  1.00)	Acc@5   3.50 (  4.99)
[EVAL] E: [36][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [36][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.015781806274400994 -- best acc so far 53.69
***[2023-04-24 20:54:37]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [37][  0/250]	Loss -3.1888e-08 (-3.1888e-08)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [37][100/250]	Loss 2.0325e-07 (1.7691e-07)	Acc@1   1.00 (  1.07)	Acc@5   5.50 (  4.95)
[TRAIN] E: [37][200/250]	Loss -1.6540e-07 (1.5573e-07)	Acc@1   0.50 (  0.98)	Acc@5   5.00 (  4.99)
[TRAIN] E: [37][249/250]	Loss 2.5183e-07 (1.7488e-07)	Acc@1   0.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [37][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [37][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.013560172052616067 -- best acc so far 53.69
***[2023-04-24 20:56:27]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [38][  0/250]	Loss 3.6359e-07 (3.6359e-07)	Acc@1   0.00 (  0.00)	Acc@5   6.50 (  6.50)
[TRAIN] E: [38][100/250]	Loss -2.3246e-08 (1.9339e-07)	Acc@1   2.00 (  1.05)	Acc@5   7.50 (  4.83)
[TRAIN] E: [38][200/250]	Loss 6.6817e-07 (1.8107e-07)	Acc@1   0.50 (  1.01)	Acc@5   4.50 (  4.98)
[TRAIN] E: [38][249/250]	Loss 3.6359e-07 (2.1404e-07)	Acc@1   0.00 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [38][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [38][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.011482349183965618 -- best acc so far 53.69
***[2023-04-24 20:58:17]*** [Post-train] [Student] EVALUATION loss = 4.605172, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [39][  0/250]	Loss 3.2991e-07 (3.2991e-07)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[TRAIN] E: [39][100/250]	Loss 4.8995e-07 (1.2778e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  4.96)
[TRAIN] E: [39][200/250]	Loss -4.0233e-08 (1.4714e-07)	Acc@1   1.00 (  1.02)	Acc@5   5.50 (  5.02)
[TRAIN] E: [39][249/250]	Loss 4.3184e-07 (1.1013e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [39][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [39][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.009556537886045253 -- best acc so far 53.69
***[2023-04-24 21:00:09]*** [Post-train] [Student] EVALUATION loss = 4.605173, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [40][  0/250]	Loss 4.0382e-07 (4.0382e-07)	Acc@1   1.00 (  1.00)	Acc@5   7.50 (  7.50)
[TRAIN] E: [40][100/250]	Loss 3.0816e-07 (1.8450e-07)	Acc@1   1.00 (  0.95)	Acc@5   4.50 (  4.94)
[TRAIN] E: [40][200/250]	Loss 1.0818e-07 (1.7945e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.03)
[TRAIN] E: [40][249/250]	Loss 8.7917e-08 (1.8315e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [40][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [40][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.00779033845622838 -- best acc so far 53.69
***[2023-04-24 21:02:02]*** [Post-train] [Student] EVALUATION loss = 4.605173, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [41][  0/250]	Loss -1.1206e-07 (-1.1206e-07)	Acc@1   0.50 (  0.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [41][100/250]	Loss 2.8729e-07 (8.8005e-08)	Acc@1   1.00 (  1.05)	Acc@5   6.00 (  5.20)
[TRAIN] E: [41][200/250]	Loss 2.4587e-07 (2.2962e-07)	Acc@1   1.00 (  1.01)	Acc@5   3.00 (  5.00)
[TRAIN] E: [41][249/250]	Loss -1.2666e-07 (2.1346e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [41][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [41][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.006190721276764722 -- best acc so far 53.69
***[2023-04-24 21:03:52]*** [Post-train] [Student] EVALUATION loss = 4.605173, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [42][  0/250]	Loss 2.6524e-08 (2.6524e-08)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [42][100/250]	Loss 1.3113e-08 (4.3081e-09)	Acc@1   1.00 (  1.01)	Acc@5   6.00 (  4.98)
[TRAIN] E: [42][200/250]	Loss 4.9978e-07 (2.0470e-07)	Acc@1   0.50 (  0.99)	Acc@5   3.50 (  5.01)
[TRAIN] E: [42][249/250]	Loss 5.6744e-07 (1.9421e-07)	Acc@1   1.50 (  1.00)	Acc@5   7.50 (  5.00)
[EVAL] E: [42][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [42][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.004763999305866018 -- best acc so far 53.69
***[2023-04-24 21:05:43]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [43][  0/250]	Loss 5.9962e-07 (5.9962e-07)	Acc@1   1.50 (  1.50)	Acc@5   6.50 (  6.50)
[TRAIN] E: [43][100/250]	Loss -2.5332e-07 (1.1360e-08)	Acc@1   4.00 (  1.10)	Acc@5  10.00 (  5.11)
[TRAIN] E: [43][200/250]	Loss -6.5267e-08 (-2.4881e-08)	Acc@1   0.50 (  1.00)	Acc@5   3.00 (  5.03)
[TRAIN] E: [43][249/250]	Loss 8.6427e-07 (5.7483e-08)	Acc@1   1.50 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [43][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [43][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.003515803163344178 -- best acc so far 53.69
***[2023-04-24 21:07:37]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [44][  0/250]	Loss 8.2731e-07 (8.2731e-07)	Acc@1   1.50 (  1.50)	Acc@5   8.50 (  8.50)
[TRAIN] E: [44][100/250]	Loss -4.6790e-08 (3.4448e-07)	Acc@1   0.00 (  1.01)	Acc@5   6.00 (  5.00)
[TRAIN] E: [44][200/250]	Loss 4.4435e-07 (2.6694e-07)	Acc@1   1.00 (  1.01)	Acc@5   5.00 (  5.01)
[TRAIN] E: [44][249/250]	Loss 1.6272e-07 (2.0720e-07)	Acc@1   0.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [44][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [44][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0024510589091271354 -- best acc so far 53.69
***[2023-04-24 21:09:30]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [45][  0/250]	Loss -1.3947e-07 (-1.3947e-07)	Acc@1   2.00 (  2.00)	Acc@5   6.50 (  6.50)
[TRAIN] E: [45][100/250]	Loss -1.3858e-07 (8.2488e-08)	Acc@1   0.50 (  0.96)	Acc@5   2.00 (  5.10)
[TRAIN] E: [45][200/250]	Loss 2.0057e-07 (4.3992e-08)	Acc@1   0.50 (  0.97)	Acc@5   3.50 (  4.98)
[TRAIN] E: [45][249/250]	Loss 2.3276e-07 (6.2381e-08)	Acc@1   0.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [45][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [45][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0015739686023509116 -- best acc so far 53.69
***[2023-04-24 21:11:21]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [46][  0/250]	Loss -4.6462e-07 (-4.6462e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [46][100/250]	Loss 4.0084e-07 (7.8185e-08)	Acc@1   2.00 (  0.88)	Acc@5   7.00 (  4.79)
[TRAIN] E: [46][200/250]	Loss 1.0183e-06 (3.2944e-07)	Acc@1   0.50 (  0.98)	Acc@5   2.50 (  4.99)
[TRAIN] E: [46][249/250]	Loss 3.8177e-07 (4.0637e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [46][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [46][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.000887993717751906 -- best acc so far 53.69
***[2023-04-24 21:13:12]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [47][  0/250]	Loss 3.7700e-07 (3.7700e-07)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [47][100/250]	Loss 5.9098e-07 (3.3908e-07)	Acc@1   0.00 (  1.06)	Acc@5   4.50 (  5.03)
[TRAIN] E: [47][200/250]	Loss 4.3124e-07 (3.2300e-07)	Acc@1   1.00 (  1.02)	Acc@5   4.50 (  4.97)
[TRAIN] E: [47][249/250]	Loss 4.4405e-07 (3.5160e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [47][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [47][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0003958414848075243 -- best acc so far 53.69
***[2023-04-24 21:15:05]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [48][  0/250]	Loss 7.1436e-07 (7.1436e-07)	Acc@1   1.50 (  1.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [48][100/250]	Loss 1.0490e-07 (-5.8466e-08)	Acc@1   1.00 (  0.95)	Acc@5   4.00 (  5.05)
[TRAIN] E: [48][200/250]	Loss -1.7852e-07 (-1.4274e-07)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  4.96)
[TRAIN] E: [48][249/250]	Loss -2.9832e-07 (-1.4810e-07)	Acc@1   0.00 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [48][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [48][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=9.945420353821844e-05 -- best acc so far 53.69
***[2023-04-24 21:16:55]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [49][  0/250]	Loss 5.0664e-08 (5.0664e-08)	Acc@1   1.50 (  1.50)	Acc@5   7.00 (  7.00)
[TRAIN] E: [49][100/250]	Loss -7.3314e-08 (1.9982e-07)	Acc@1   0.00 (  1.04)	Acc@5   5.00 (  5.18)
[TRAIN] E: [49][200/250]	Loss -3.9935e-08 (1.9133e-07)	Acc@1   1.50 (  0.99)	Acc@5   3.50 (  4.98)
[TRAIN] E: [49][249/250]	Loss 2.5779e-07 (1.9191e-07)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [49][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [49][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=1.57913669363019e-09 -- best acc so far 53.69
***[2023-04-24 21:18:46]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [50][  0/250]	Loss -5.9009e-08 (-5.9009e-08)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [50][100/250]	Loss -4.3213e-08 (1.5281e-07)	Acc@1   0.50 (  1.02)	Acc@5   5.50 (  5.04)
[TRAIN] E: [50][200/250]	Loss 4.4018e-07 (1.8724e-07)	Acc@1   0.50 (  1.01)	Acc@5   6.50 (  5.03)
[TRAIN] E: [50][249/250]	Loss 1.6746e-06 (1.7993e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [50][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [50][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09990212389432412 -- best acc so far 53.69
***[2023-04-24 21:20:39]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [51][  0/250]	Loss -1.3182e-06 (-1.3182e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [51][100/250]	Loss 2.2864e-06 (7.9838e-08)	Acc@1   2.00 (  1.00)	Acc@5   8.00 (  5.02)
[TRAIN] E: [51][200/250]	Loss 1.0702e-06 (2.4264e-07)	Acc@1   0.00 (  1.03)	Acc@5   2.00 (  5.05)
[TRAIN] E: [51][249/250]	Loss 3.2884e-06 (2.3220e-07)	Acc@1   0.00 (  1.00)	Acc@5   1.50 (  5.00)
[EVAL] E: [51][ 0/50]	Loss 4.6054e+00 (4.6054e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [51][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09960730848288585 -- best acc so far 53.69
***[2023-04-24 21:22:27]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [52][  0/250]	Loss -1.6609e-06 (-1.6609e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [52][100/250]	Loss 7.0333e-08 (1.8355e-07)	Acc@1   1.00 (  0.96)	Acc@5   6.00 (  5.00)
[TRAIN] E: [52][200/250]	Loss 2.6959e-06 (3.5029e-07)	Acc@1   0.50 (  0.98)	Acc@5   5.00 (  4.97)
[TRAIN] E: [52][249/250]	Loss 1.0431e-06 (3.3995e-07)	Acc@1   2.00 (  1.00)	Acc@5   8.00 (  5.00)
[EVAL] E: [52][ 0/50]	Loss 4.6054e+00 (4.6054e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [52][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0991167156882891 -- best acc so far 53.69
***[2023-04-24 21:24:16]*** [Post-train] [Student] EVALUATION loss = 4.605173, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [53][  0/250]	Loss -3.1355e-06 (-3.1355e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [53][100/250]	Loss -9.5636e-07 (3.2878e-07)	Acc@1   1.00 (  1.08)	Acc@5   7.00 (  5.10)
[TRAIN] E: [53][200/250]	Loss -2.2429e-06 (1.9148e-07)	Acc@1   1.50 (  1.03)	Acc@5   6.50 (  5.02)
[TRAIN] E: [53][249/250]	Loss -2.5806e-06 (1.7166e-07)	Acc@1   2.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [53][ 0/50]	Loss 4.6054e+00 (4.6054e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [53][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0984322816561636 -- best acc so far 53.69
***[2023-04-24 21:26:08]*** [Post-train] [Student] EVALUATION loss = 4.605172, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [54][  0/250]	Loss 2.7564e-06 (2.7564e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [54][100/250]	Loss -1.7852e-07 (1.1706e-07)	Acc@1   1.00 (  1.02)	Acc@5   2.00 (  5.04)
[TRAIN] E: [54][200/250]	Loss -2.5329e-06 (1.0115e-07)	Acc@1   2.00 (  1.01)	Acc@5   7.00 (  5.04)
[TRAIN] E: [54][249/250]	Loss -4.8548e-07 (1.8049e-07)	Acc@1   1.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [54][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [54][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09755670753494601 -- best acc so far 53.69
***[2023-04-24 21:27:57]*** [Post-train] [Student] EVALUATION loss = 4.605172, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [55][  0/250]	Loss 3.4598e-06 (3.4598e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [55][100/250]	Loss 2.0862e-06 (8.3143e-07)	Acc@1   2.00 (  0.87)	Acc@5   5.50 (  4.85)
[TRAIN] E: [55][200/250]	Loss 1.8629e-06 (6.4254e-07)	Acc@1   0.00 (  0.98)	Acc@5   2.50 (  4.96)
[TRAIN] E: [55][249/250]	Loss -2.2250e-06 (5.1512e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [55][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [55][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09649344881568099 -- best acc so far 53.69
***[2023-04-24 21:29:47]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [56][  0/250]	Loss -7.5996e-07 (-7.5996e-07)	Acc@1   2.00 (  2.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [56][100/250]	Loss 0.0000e+00 (-1.5518e-07)	Acc@1   1.50 (  1.05)	Acc@5   6.00 (  4.93)
[TRAIN] E: [56][200/250]	Loss 8.9407e-07 (4.6409e-09)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
[TRAIN] E: [56][249/250]	Loss 3.1590e-06 (4.5813e-08)	Acc@1   0.50 (  1.01)	Acc@5   3.50 (  5.00)
[EVAL] E: [56][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [56][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09524670169477678 -- best acc so far 53.69
***[2023-04-24 21:31:37]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [57][  0/250]	Loss -1.1048e-06 (-1.1048e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [57][100/250]	Loss 1.0216e-06 (5.0776e-07)	Acc@1   2.00 (  0.96)	Acc@5   5.50 (  4.92)
[TRAIN] E: [57][200/250]	Loss -2.5630e-06 (3.3465e-07)	Acc@1   0.50 (  0.97)	Acc@5   6.00 (  4.99)
[TRAIN] E: [57][249/250]	Loss 2.3842e-07 (2.6011e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [57][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [57][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.093821386513535 -- best acc so far 53.69
***[2023-04-24 21:33:28]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [58][  0/250]	Loss 2.3842e-06 (2.3842e-06)	Acc@1   1.00 (  1.00)	Acc@5   8.00 (  8.00)
[TRAIN] E: [58][100/250]	Loss 2.6226e-06 (1.2377e-07)	Acc@1   0.00 (  1.02)	Acc@5   4.50 (  4.91)
[TRAIN] E: [58][200/250]	Loss 1.7881e-07 (8.3869e-08)	Acc@1   1.50 (  0.98)	Acc@5   6.00 (  4.90)
[TRAIN] E: [58][249/250]	Loss -2.2054e-06 (4.8970e-08)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [58][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [58][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09222312833981147 -- best acc so far 53.69
***[2023-04-24 21:35:19]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [59][  0/250]	Loss 3.5763e-07 (3.5763e-07)	Acc@1   2.00 (  2.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [59][100/250]	Loss 2.3246e-06 (4.1544e-07)	Acc@1   2.00 (  1.09)	Acc@5   5.50 (  5.20)
[TRAIN] E: [59][200/250]	Loss -1.7881e-06 (4.5616e-07)	Acc@1   1.00 (  1.02)	Acc@5   4.00 (  5.11)
[TRAIN] E: [59][249/250]	Loss 1.0729e-06 (3.0167e-07)	Acc@1   0.00 (  1.00)	Acc@5   2.00 (  5.00)
[EVAL] E: [59][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [59][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09045823476844315 -- best acc so far 53.69
***[2023-04-24 21:37:10]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [60][  0/250]	Loss -2.8020e-06 (-2.8020e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [60][100/250]	Loss 1.9670e-06 (-2.9009e-08)	Acc@1   1.50 (  1.02)	Acc@5   4.50 (  4.91)
[TRAIN] E: [60][200/250]	Loss 2.9802e-06 (1.7402e-07)	Acc@1   4.00 (  1.02)	Acc@5   9.00 (  5.01)
[TRAIN] E: [60][249/250]	Loss -5.3644e-07 (2.4172e-07)	Acc@1   1.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [60][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [60][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08853367102805307 -- best acc so far 53.69
***[2023-04-24 21:39:01]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [61][  0/250]	Loss -3.5763e-06 (-3.5763e-06)	Acc@1   0.00 (  0.00)	Acc@5   2.50 (  2.50)
[TRAIN] E: [61][100/250]	Loss 2.4438e-06 (-1.0831e-07)	Acc@1   1.00 (  1.01)	Acc@5   6.00 (  5.14)
[TRAIN] E: [61][200/250]	Loss -2.1458e-06 (1.5561e-08)	Acc@1   0.00 (  1.00)	Acc@5   3.50 (  5.11)
[TRAIN] E: [61][249/250]	Loss -8.3447e-07 (3.3015e-08)	Acc@1   1.00 (  1.00)	Acc@5   2.50 (  5.00)
[EVAL] E: [61][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [61][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.086457032492475 -- best acc so far 53.69
***[2023-04-24 21:40:50]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [62][  0/250]	Loss 2.6226e-06 (2.6226e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [62][100/250]	Loss -1.1325e-06 (4.7861e-07)	Acc@1   1.00 (  0.88)	Acc@5   7.50 (  4.94)
[TRAIN] E: [62][200/250]	Loss 2.3842e-07 (4.9107e-07)	Acc@1   1.50 (  0.99)	Acc@5   5.00 (  4.94)
[TRAIN] E: [62][249/250]	Loss -8.9407e-07 (4.8518e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [62][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [62][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08423651470528296 -- best acc so far 53.69
***[2023-04-24 21:42:38]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [63][  0/250]	Loss -3.6359e-06 (-3.6359e-06)	Acc@1   1.50 (  1.50)	Acc@5   6.50 (  6.50)
[TRAIN] E: [63][100/250]	Loss 2.5630e-06 (1.1095e-07)	Acc@1   1.00 (  0.97)	Acc@5   5.50 (  4.98)
[TRAIN] E: [63][200/250]	Loss 2.1458e-06 (9.9934e-08)	Acc@1   0.00 (  1.00)	Acc@5   3.00 (  5.09)
[TRAIN] E: [63][249/250]	Loss -7.7486e-07 (1.0613e-07)	Acc@1   0.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [63][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [63][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08188088103572494 -- best acc so far 53.69
***[2023-04-24 21:44:29]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [64][  0/250]	Loss -2.8014e-06 (-2.8014e-06)	Acc@1   0.00 (  0.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [64][100/250]	Loss -4.2319e-06 (-1.0328e-07)	Acc@1   0.00 (  0.81)	Acc@5   4.00 (  4.90)
[TRAIN] E: [64][200/250]	Loss 1.2517e-06 (3.8550e-09)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.04)
[TRAIN] E: [64][249/250]	Loss -2.0266e-06 (-3.4809e-08)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [64][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [64][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07939942809370802 -- best acc so far 53.69
***[2023-04-24 21:46:20]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [65][  0/250]	Loss 2.7418e-06 (2.7418e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [65][100/250]	Loss -8.9407e-07 (3.4169e-07)	Acc@1   1.00 (  1.06)	Acc@5   7.00 (  5.14)
[TRAIN] E: [65][200/250]	Loss -2.4438e-06 (3.6919e-07)	Acc@1   0.50 (  0.98)	Acc@5   2.50 (  5.04)
[TRAIN] E: [65][249/250]	Loss -9.5367e-07 (3.9554e-07)	Acc@1   2.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [65][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [65][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0768019490403263 -- best acc so far 53.69
***[2023-04-24 21:48:09]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [66][  0/250]	Loss -3.1590e-06 (-3.1590e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [66][100/250]	Loss 1.1921e-06 (5.1107e-07)	Acc@1   1.00 (  1.07)	Acc@5   6.00 (  5.18)
[TRAIN] E: [66][200/250]	Loss -1.1921e-06 (3.4221e-07)	Acc@1   1.50 (  1.04)	Acc@5   4.50 (  5.05)
[TRAIN] E: [66][249/250]	Loss 2.6226e-06 (3.2020e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [66][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [66][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07409869493872821 -- best acc so far 53.69
***[2023-04-24 21:49:58]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [67][  0/250]	Loss 1.7285e-06 (1.7285e-06)	Acc@1   1.00 (  1.00)	Acc@5   8.50 (  8.50)
[TRAIN] E: [67][100/250]	Loss 2.8610e-06 (2.2721e-07)	Acc@1   1.50 (  0.94)	Acc@5   9.00 (  4.94)
[TRAIN] E: [67][200/250]	Loss -2.1458e-06 (2.6481e-07)	Acc@1   1.00 (  0.98)	Acc@5   5.00 (  5.00)
[TRAIN] E: [67][249/250]	Loss 3.2783e-06 (2.5726e-07)	Acc@1   2.50 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [67][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [67][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07130033429785343 -- best acc so far 53.69
***[2023-04-24 21:51:52]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [68][  0/250]	Loss 8.9407e-07 (8.9407e-07)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [68][100/250]	Loss -1.7285e-06 (1.2629e-07)	Acc@1   1.00 (  1.06)	Acc@5   3.00 (  5.06)
[TRAIN] E: [68][200/250]	Loss 5.3644e-07 (1.5331e-07)	Acc@1   0.50 (  1.02)	Acc@5   3.00 (  5.02)
[TRAIN] E: [68][249/250]	Loss -2.5034e-06 (1.7333e-07)	Acc@1   0.00 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [68][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [68][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06841791096870212 -- best acc so far 53.69
***[2023-04-24 21:53:44]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [69][  0/250]	Loss -2.0862e-06 (-2.0862e-06)	Acc@1   2.00 (  2.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [69][100/250]	Loss 2.0862e-06 (2.5199e-07)	Acc@1   1.50 (  1.06)	Acc@5   3.00 (  4.97)
[TRAIN] E: [69][200/250]	Loss -3.6359e-06 (7.4135e-08)	Acc@1   2.00 (  1.01)	Acc@5   6.50 (  5.00)
[TRAIN] E: [69][249/250]	Loss 5.9605e-08 (8.1539e-08)	Acc@1   0.00 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [69][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [69][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06546280055930047 -- best acc so far 53.69
***[2023-04-24 21:55:32]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [70][  0/250]	Loss 1.1921e-07 (1.1921e-07)	Acc@1   0.50 (  0.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [70][100/250]	Loss 1.4305e-06 (-1.1862e-07)	Acc@1   2.50 (  0.94)	Acc@5   5.00 (  4.64)
[TRAIN] E: [70][200/250]	Loss 1.6689e-06 (8.8962e-09)	Acc@1   2.00 (  0.99)	Acc@5   5.00 (  4.97)
[TRAIN] E: [70][249/250]	Loss -2.7418e-06 (-1.0252e-08)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [70][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [70][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06244666554037286 -- best acc so far 53.69
***[2023-04-24 21:57:22]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [71][  0/250]	Loss -3.1590e-06 (-3.1590e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [71][100/250]	Loss 2.1458e-06 (-1.1508e-07)	Acc@1   1.00 (  0.96)	Acc@5   6.50 (  5.00)
[TRAIN] E: [71][200/250]	Loss -7.1526e-07 (-4.5371e-08)	Acc@1   0.00 (  0.98)	Acc@5   3.00 (  4.98)
[TRAIN] E: [71][249/250]	Loss -2.5630e-06 (-4.9829e-08)	Acc@1   0.50 (  1.00)	Acc@5   1.00 (  5.00)
[EVAL] E: [71][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [71][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05938140921889801 -- best acc so far 53.69
***[2023-04-24 21:59:16]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [72][  0/250]	Loss -2.2650e-06 (-2.2650e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [72][100/250]	Loss -1.6093e-06 (-1.9481e-08)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  4.88)
[TRAIN] E: [72][200/250]	Loss 2.1458e-06 (-8.3034e-08)	Acc@1   1.00 (  0.99)	Acc@5   5.00 (  4.97)
[TRAIN] E: [72][249/250]	Loss 5.9605e-07 (-3.8626e-08)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [72][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [72][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05627912876119434 -- best acc so far 53.69
***[2023-04-24 22:01:05]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [73][  0/250]	Loss -1.1921e-06 (-1.1921e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [73][100/250]	Loss 1.6689e-06 (-9.7964e-08)	Acc@1   1.00 (  1.04)	Acc@5   3.50 (  4.94)
[TRAIN] E: [73][200/250]	Loss 2.4438e-06 (2.8171e-08)	Acc@1   0.50 (  1.01)	Acc@5   4.50 (  5.01)
[TRAIN] E: [73][249/250]	Loss 1.6093e-06 (-9.2983e-09)	Acc@1   0.50 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [73][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [73][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05315206745093132 -- best acc so far 53.69
***[2023-04-24 22:02:59]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [74][  0/250]	Loss 7.1526e-07 (7.1526e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [74][100/250]	Loss 3.0994e-06 (-1.6819e-07)	Acc@1   1.00 (  1.08)	Acc@5   3.00 (  5.22)
[TRAIN] E: [74][200/250]	Loss 2.3842e-06 (-9.8451e-08)	Acc@1   1.50 (  1.01)	Acc@5   5.50 (  4.96)
[TRAIN] E: [74][249/250]	Loss -1.9073e-06 (2.0742e-08)	Acc@1   0.00 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [74][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [74][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.050012566370482084 -- best acc so far 53.69
***[2023-04-24 22:04:50]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [75][  0/250]	Loss -1.3113e-06 (-1.3113e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[TRAIN] E: [75][100/250]	Loss 1.2517e-06 (-3.0097e-08)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.09)
[TRAIN] E: [75][200/250]	Loss -1.6093e-06 (4.8929e-08)	Acc@1   1.50 (  1.00)	Acc@5   4.50 (  5.04)
[TRAIN] E: [75][249/250]	Loss -3.5167e-06 (1.7738e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [75][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [75][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0468730156963096 -- best acc so far 53.69
***[2023-04-24 22:06:40]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [76][  0/250]	Loss -3.6955e-06 (-3.6955e-06)	Acc@1   1.50 (  1.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [76][100/250]	Loss -1.7285e-06 (-1.0150e-07)	Acc@1   0.50 (  0.94)	Acc@5   5.00 (  5.10)
[TRAIN] E: [76][200/250]	Loss -2.9802e-07 (1.3641e-07)	Acc@1   2.00 (  1.01)	Acc@5   5.00 (  4.97)
[TRAIN] E: [76][249/250]	Loss 3.6359e-06 (1.0633e-07)	Acc@1   1.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [76][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [76][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.04374580580060053 -- best acc so far 53.69
***[2023-04-24 22:08:31]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [77][  0/250]	Loss 3.3975e-06 (3.3975e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [77][100/250]	Loss 0.0000e+00 (-3.4819e-08)	Acc@1   2.00 (  1.03)	Acc@5   6.00 (  4.88)
[TRAIN] E: [77][200/250]	Loss 1.5497e-06 (2.8883e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  4.93)
[TRAIN] E: [77][249/250]	Loss -1.3113e-06 (1.9479e-07)	Acc@1   1.50 (  1.00)	Acc@5   8.00 (  5.00)
[EVAL] E: [77][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [77][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.04064327835212697 -- best acc so far 53.69
***[2023-04-24 22:10:20]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [78][  0/250]	Loss -2.5034e-06 (-2.5034e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [78][100/250]	Loss 1.3113e-06 (5.1225e-07)	Acc@1   0.00 (  0.91)	Acc@5   5.50 (  5.11)
[TRAIN] E: [78][200/250]	Loss -2.3246e-06 (3.2649e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.05)
[TRAIN] E: [78][249/250]	Loss -1.7285e-06 (2.6107e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [78][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [78][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.037577677609318044 -- best acc so far 53.69
***[2023-04-24 22:12:09]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [79][  0/250]	Loss -1.6689e-06 (-1.6689e-06)	Acc@1   0.50 (  0.50)	Acc@5   6.50 (  6.50)
[TRAIN] E: [79][100/250]	Loss -2.0862e-06 (4.7684e-07)	Acc@1   0.00 (  1.00)	Acc@5   2.50 (  4.88)
[TRAIN] E: [79][200/250]	Loss 6.5565e-07 (4.0389e-07)	Acc@1   1.50 (  1.04)	Acc@5   6.00 (  5.05)
[TRAIN] E: [79][249/250]	Loss 9.5367e-07 (5.0426e-07)	Acc@1   0.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [79][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [79][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.034561102097765875 -- best acc so far 53.69
***[2023-04-24 22:13:58]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [80][  0/250]	Loss 1.2517e-06 (1.2517e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [80][100/250]	Loss -2.3246e-06 (-1.6583e-07)	Acc@1   1.50 (  1.03)	Acc@5   3.50 (  5.12)
[TRAIN] E: [80][200/250]	Loss 2.0266e-06 (2.2982e-07)	Acc@1   1.50 (  0.99)	Acc@5   6.50 (  5.01)
[TRAIN] E: [80][249/250]	Loss -2.0862e-06 (2.6679e-07)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [80][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [80][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0316054568628723 -- best acc so far 53.69
***[2023-04-24 22:15:52]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [81][  0/250]	Loss -1.6689e-06 (-1.6689e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [81][100/250]	Loss 3.1590e-06 (-1.2688e-07)	Acc@1   0.00 (  1.07)	Acc@5   5.00 (  4.97)
[TRAIN] E: [81][200/250]	Loss 3.2783e-06 (2.9951e-08)	Acc@1   1.50 (  0.99)	Acc@5   7.50 (  4.96)
[TRAIN] E: [81][249/250]	Loss 7.7486e-07 (2.8610e-07)	Acc@1   0.00 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [81][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [81][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.028722406486073583 -- best acc so far 53.69
***[2023-04-24 22:17:43]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [82][  0/250]	Loss 9.5367e-07 (9.5367e-07)	Acc@1   1.50 (  1.50)	Acc@5   7.00 (  7.00)
[TRAIN] E: [82][100/250]	Loss 3.2187e-06 (1.1685e-07)	Acc@1   0.00 (  1.10)	Acc@5   4.00 (  4.85)
[TRAIN] E: [82][200/250]	Loss 1.1921e-07 (3.4695e-07)	Acc@1   2.00 (  1.04)	Acc@5   4.50 (  4.97)
[TRAIN] E: [82][249/250]	Loss -2.5034e-06 (1.8263e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [82][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [82][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.02592332905006651 -- best acc so far 53.69
***[2023-04-24 22:19:35]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [83][  0/250]	Loss -2.5630e-06 (-2.5630e-06)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [83][100/250]	Loss 3.1590e-06 (6.6391e-07)	Acc@1   0.50 (  1.05)	Acc@5   5.50 (  5.04)
[TRAIN] E: [83][200/250]	Loss 4.7684e-07 (2.4880e-07)	Acc@1   2.00 (  1.03)	Acc@5   5.50 (  5.04)
[TRAIN] E: [83][249/250]	Loss -2.9802e-07 (2.0027e-07)	Acc@1   1.00 (  1.00)	Acc@5   2.00 (  5.00)
[EVAL] E: [83][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [83][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.023219271234714157 -- best acc so far 53.69
***[2023-04-24 22:21:28]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [84][  0/250]	Loss -3.5763e-07 (-3.5763e-07)	Acc@1   0.00 (  0.00)	Acc@5   1.50 (  1.50)
[TRAIN] E: [84][100/250]	Loss 6.5565e-07 (3.6648e-07)	Acc@1   1.00 (  0.94)	Acc@5   5.00 (  5.00)
[TRAIN] E: [84][200/250]	Loss 1.9073e-06 (5.1213e-07)	Acc@1   1.50 (  1.00)	Acc@5   5.00 (  4.99)
[TRAIN] E: [84][249/250]	Loss 1.5497e-06 (5.9247e-07)	Acc@1   1.00 (  1.00)	Acc@5   2.50 (  5.00)
[EVAL] E: [84][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [84][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.020620904720847225 -- best acc so far 53.69
***[2023-04-24 22:23:19]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [85][  0/250]	Loss 1.4305e-06 (1.4305e-06)	Acc@1   2.00 (  2.00)	Acc@5   7.00 (  7.00)
[TRAIN] E: [85][100/250]	Loss 1.7881e-06 (-8.1853e-07)	Acc@1   0.50 (  0.98)	Acc@5   3.50 (  4.93)
[TRAIN] E: [85][200/250]	Loss -2.4438e-06 (-6.2926e-07)	Acc@1   1.00 (  0.98)	Acc@5   4.00 (  5.00)
[TRAIN] E: [85][249/250]	Loss -2.5034e-06 (-3.3855e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [85][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [85][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0181384840740152 -- best acc so far 53.69
***[2023-04-24 22:25:11]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [86][  0/250]	Loss -2.6226e-06 (-2.6226e-06)	Acc@1   0.00 (  0.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [86][100/250]	Loss 2.1458e-06 (8.3624e-07)	Acc@1   0.50 (  1.08)	Acc@5   3.00 (  4.90)
[TRAIN] E: [86][200/250]	Loss -1.7285e-06 (5.8982e-07)	Acc@1   0.50 (  1.02)	Acc@5   4.50 (  5.05)
[TRAIN] E: [86][249/250]	Loss 1.9073e-06 (7.7295e-07)	Acc@1   0.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [86][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [86][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.01578180627440101 -- best acc so far 53.69
***[2023-04-24 22:27:03]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [87][  0/250]	Loss 2.2054e-06 (2.2054e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [87][100/250]	Loss -1.7881e-06 (-4.2786e-07)	Acc@1   2.00 (  1.04)	Acc@5   6.50 (  4.99)
[TRAIN] E: [87][200/250]	Loss -1.9073e-06 (-3.6593e-07)	Acc@1   1.00 (  1.01)	Acc@5   6.00 (  5.01)
[TRAIN] E: [87][249/250]	Loss 2.2650e-06 (-1.5616e-07)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [87][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [87][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.013560172052616067 -- best acc so far 53.69
***[2023-04-24 22:28:52]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [88][  0/250]	Loss 2.1458e-06 (2.1458e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [88][100/250]	Loss 4.1723e-07 (1.4400e-07)	Acc@1   2.50 (  1.03)	Acc@5   4.50 (  4.95)
[TRAIN] E: [88][200/250]	Loss 2.3842e-07 (6.6929e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.01)
[TRAIN] E: [88][249/250]	Loss -3.8743e-06 (1.8358e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [88][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [88][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.01148234918396563 -- best acc so far 53.69
***[2023-04-24 22:30:45]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [89][  0/250]	Loss -3.9339e-06 (-3.9339e-06)	Acc@1   0.50 (  0.50)	Acc@5   2.00 (  2.00)
[TRAIN] E: [89][100/250]	Loss -3.1590e-06 (2.5907e-07)	Acc@1   0.50 (  0.99)	Acc@5   5.00 (  5.07)
[TRAIN] E: [89][200/250]	Loss -3.3975e-06 (5.6017e-07)	Acc@1   1.50 (  0.99)	Acc@5   4.00 (  5.00)
[TRAIN] E: [89][249/250]	Loss 2.5630e-06 (5.1141e-07)	Acc@1   1.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [89][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [89][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.009556537886045269 -- best acc so far 53.69
***[2023-04-24 22:32:33]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [90][  0/250]	Loss 2.5630e-06 (2.5630e-06)	Acc@1   2.00 (  2.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [90][100/250]	Loss -3.7551e-06 (-4.9690e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.10)
[TRAIN] E: [90][200/250]	Loss -6.5565e-07 (8.3031e-08)	Acc@1   2.00 (  1.00)	Acc@5   5.50 (  4.97)
[TRAIN] E: [90][249/250]	Loss -2.3842e-06 (-2.8872e-07)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [90][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [90][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.007790338456228391 -- best acc so far 53.69
***[2023-04-24 22:34:26]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [91][  0/250]	Loss -2.3842e-06 (-2.3842e-06)	Acc@1   1.00 (  1.00)	Acc@5   7.00 (  7.00)
[TRAIN] E: [91][100/250]	Loss -7.1526e-07 (1.3089e-06)	Acc@1   0.00 (  0.99)	Acc@5   2.00 (  4.82)
[TRAIN] E: [91][200/250]	Loss 3.0994e-06 (5.3763e-07)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  5.00)
[TRAIN] E: [91][249/250]	Loss 7.1526e-07 (8.1921e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [91][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [91][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.006190721276764732 -- best acc so far 53.69
***[2023-04-24 22:36:14]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [92][  0/250]	Loss 7.1526e-07 (7.1526e-07)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [92][100/250]	Loss -2.3246e-06 (-1.3444e-06)	Acc@1   2.50 (  1.02)	Acc@5   4.00 (  4.91)
[TRAIN] E: [92][200/250]	Loss 1.1921e-06 (8.5967e-07)	Acc@1   1.50 (  1.02)	Acc@5   6.00 (  5.02)
[TRAIN] E: [92][249/250]	Loss -1.7881e-07 (9.2149e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [92][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [92][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.004763999305866029 -- best acc so far 53.69
***[2023-04-24 22:38:05]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [93][  0/250]	Loss -1.7881e-07 (-1.7881e-07)	Acc@1   2.00 (  2.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [93][100/250]	Loss -2.2054e-06 (-1.4122e-06)	Acc@1   2.00 (  1.08)	Acc@5   6.00 (  4.90)
[TRAIN] E: [93][200/250]	Loss 2.5630e-06 (-1.1316e-06)	Acc@1   0.50 (  0.99)	Acc@5   7.00 (  4.93)
[TRAIN] E: [93][249/250]	Loss 1.4305e-06 (-4.9949e-07)	Acc@1   1.00 (  1.00)	Acc@5   8.50 (  5.00)
[EVAL] E: [93][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [93][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.003515803163344189 -- best acc so far 53.69
***[2023-04-24 22:39:54]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [94][  0/250]	Loss 1.4305e-06 (1.4305e-06)	Acc@1   2.00 (  2.00)	Acc@5   8.00 (  8.00)
[TRAIN] E: [94][100/250]	Loss -7.7486e-07 (7.6719e-08)	Acc@1   0.50 (  1.06)	Acc@5   4.50 (  5.24)
[TRAIN] E: [94][200/250]	Loss -1.6689e-06 (-7.0221e-07)	Acc@1   0.00 (  1.02)	Acc@5   2.50 (  5.10)
[TRAIN] E: [94][249/250]	Loss -3.0398e-06 (-1.0889e-06)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [94][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [94][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0024510589091271354 -- best acc so far 53.69
***[2023-04-24 22:41:45]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [95][  0/250]	Loss -3.0398e-06 (-3.0398e-06)	Acc@1   0.00 (  0.00)	Acc@5   3.00 (  3.00)
[TRAIN] E: [95][100/250]	Loss 3.3975e-06 (2.8652e-06)	Acc@1   1.00 (  1.02)	Acc@5   3.50 (  5.00)
[TRAIN] E: [95][200/250]	Loss 7.7486e-07 (2.0968e-06)	Acc@1   0.00 (  0.99)	Acc@5   2.50 (  5.01)
[TRAIN] E: [95][249/250]	Loss 1.1325e-06 (1.8773e-06)	Acc@1   2.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [95][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [95][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.001573968602350917 -- best acc so far 53.69
***[2023-04-24 22:43:36]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [96][  0/250]	Loss 1.1325e-06 (1.1325e-06)	Acc@1   1.50 (  1.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [96][100/250]	Loss -1.2517e-06 (-8.7164e-07)	Acc@1   0.00 (  0.95)	Acc@5   2.00 (  5.07)
[TRAIN] E: [96][200/250]	Loss -2.4438e-06 (-1.4281e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.02)
[TRAIN] E: [96][249/250]	Loss -1.6093e-06 (-1.5774e-06)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [96][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [96][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.000887993717751917 -- best acc so far 53.69
***[2023-04-24 22:45:24]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [97][  0/250]	Loss -1.6093e-06 (-1.6093e-06)	Acc@1   1.00 (  1.00)	Acc@5   7.00 (  7.00)
[TRAIN] E: [97][100/250]	Loss -2.9206e-06 (-2.7731e-06)	Acc@1   0.50 (  0.95)	Acc@5   6.50 (  5.01)
[TRAIN] E: [97][200/250]	Loss -2.9206e-06 (-2.8684e-06)	Acc@1   2.50 (  1.01)	Acc@5   6.00 (  4.95)
[TRAIN] E: [97][249/250]	Loss -2.8610e-06 (-2.8672e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [97][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [97][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0003958414848075243 -- best acc so far 53.69
***[2023-04-24 22:47:07]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [98][  0/250]	Loss -2.8610e-06 (-2.8610e-06)	Acc@1   1.50 (  1.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [98][100/250]	Loss 3.2783e-06 (3.1655e-06)	Acc@1   0.00 (  1.04)	Acc@5   3.50 (  5.08)
[TRAIN] E: [98][200/250]	Loss 3.5167e-06 (3.2492e-06)	Acc@1   1.50 (  1.01)	Acc@5   6.00 (  5.06)
[TRAIN] E: [98][249/250]	Loss 3.6955e-06 (3.3150e-06)	Acc@1   0.50 (  1.00)	Acc@5   2.50 (  5.00)
[EVAL] E: [98][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [98][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=9.945420353821844e-05 -- best acc so far 53.69
***[2023-04-24 22:48:52]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [99][  0/250]	Loss 3.6955e-06 (3.6955e-06)	Acc@1   3.00 (  3.00)	Acc@5   9.50 (  9.50)
[TRAIN] E: [99][100/250]	Loss 3.7551e-06 (3.8005e-06)	Acc@1   0.00 (  1.00)	Acc@5   4.00 (  5.00)
[TRAIN] E: [99][200/250]	Loss 3.8147e-06 (3.8046e-06)	Acc@1   1.00 (  0.97)	Acc@5   4.50 (  4.96)
[TRAIN] E: [99][249/250]	Loss 3.8147e-06 (3.8066e-06)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [99][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [99][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=1.57913669363019e-09 -- best acc so far 53.69
***[2023-04-24 22:50:35]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [100][  0/250]	Loss 3.8147e-06 (3.8147e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [100][100/250]	Loss -1.7285e-06 (1.8058e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  5.03)
[TRAIN] E: [100][200/250]	Loss -8.3447e-07 (1.9186e-07)	Acc@1   1.00 (  0.98)	Acc@5   8.00 (  4.99)
[TRAIN] E: [100][249/250]	Loss -3.5763e-06 (1.9312e-07)	Acc@1   1.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [100][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [100][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09990212389432412 -- best acc so far 53.69
***[2023-04-24 22:52:22]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [101][  0/250]	Loss -3.0994e-06 (-3.0994e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [101][100/250]	Loss -8.9407e-07 (1.4695e-07)	Acc@1   0.00 (  1.01)	Acc@5   3.50 (  4.91)
[TRAIN] E: [101][200/250]	Loss -1.6689e-06 (3.2975e-07)	Acc@1   1.00 (  1.03)	Acc@5   6.50 (  4.96)
[TRAIN] E: [101][249/250]	Loss -8.9407e-07 (4.0269e-07)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [101][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [101][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09960730848288585 -- best acc so far 53.69
***[2023-04-24 22:54:11]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [102][  0/250]	Loss -4.1723e-06 (-4.1723e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [102][100/250]	Loss 1.1921e-06 (7.8489e-08)	Acc@1   0.00 (  0.94)	Acc@5   3.00 (  4.95)
[TRAIN] E: [102][200/250]	Loss 1.7881e-06 (7.1763e-08)	Acc@1   2.00 (  1.01)	Acc@5   5.00 (  5.03)
[TRAIN] E: [102][249/250]	Loss -1.7285e-06 (9.6083e-08)	Acc@1   1.50 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [102][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [102][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0991167156882891 -- best acc so far 53.69
***[2023-04-24 22:55:54]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [103][  0/250]	Loss -1.6093e-06 (-1.6093e-06)	Acc@1   0.50 (  0.50)	Acc@5   7.50 (  7.50)
[TRAIN] E: [103][100/250]	Loss -2.7418e-06 (-2.9212e-07)	Acc@1   1.00 (  0.87)	Acc@5   5.00 (  4.89)
[TRAIN] E: [103][200/250]	Loss -1.1325e-06 (2.3723e-09)	Acc@1   2.00 (  0.96)	Acc@5   8.50 (  4.93)
[TRAIN] E: [103][249/250]	Loss 2.5630e-06 (9.6083e-08)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [103][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [103][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0984322816561636 -- best acc so far 53.69
***[2023-04-24 22:57:41]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [104][  0/250]	Loss 2.6822e-06 (2.6822e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [104][100/250]	Loss 1.0729e-06 (4.9159e-07)	Acc@1   2.50 (  1.02)	Acc@5   4.50 (  5.05)
[TRAIN] E: [104][200/250]	Loss -1.1325e-06 (4.5104e-07)	Acc@1   1.00 (  1.03)	Acc@5   4.00 (  5.01)
[TRAIN] E: [104][249/250]	Loss -2.0266e-06 (4.7588e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [104][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [104][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09755670753494601 -- best acc so far 53.69
***[2023-04-24 22:59:26]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [105][  0/250]	Loss -1.9670e-06 (-1.9670e-06)	Acc@1   0.00 (  0.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [105][100/250]	Loss -1.4901e-06 (7.1998e-07)	Acc@1   0.00 (  0.97)	Acc@5   4.00 (  4.93)
[TRAIN] E: [105][200/250]	Loss 9.5367e-07 (7.1140e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[TRAIN] E: [105][249/250]	Loss 3.5167e-06 (6.2370e-07)	Acc@1   2.00 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [105][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [105][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09649344881568099 -- best acc so far 53.69
***[2023-04-24 23:01:10]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [106][  0/250]	Loss 3.6359e-06 (3.6359e-06)	Acc@1   1.00 (  1.00)	Acc@5   7.50 (  7.50)
[TRAIN] E: [106][100/250]	Loss -1.4305e-06 (6.3795e-07)	Acc@1   1.00 (  1.02)	Acc@5   1.00 (  4.86)
[TRAIN] E: [106][200/250]	Loss -2.7418e-06 (6.0880e-07)	Acc@1   1.00 (  1.01)	Acc@5   5.00 (  4.94)
[TRAIN] E: [106][249/250]	Loss 2.7418e-06 (5.8389e-07)	Acc@1   0.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [106][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [106][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09524670169477678 -- best acc so far 53.69
***[2023-04-24 23:02:50]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [107][  0/250]	Loss 2.6226e-06 (2.6226e-06)	Acc@1   0.00 (  0.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [107][100/250]	Loss 3.7551e-06 (1.6937e-07)	Acc@1   0.50 (  0.97)	Acc@5   7.00 (  4.92)
[TRAIN] E: [107][200/250]	Loss 3.6955e-06 (2.5502e-07)	Acc@1   1.00 (  0.98)	Acc@5   4.50 (  4.99)
[TRAIN] E: [107][249/250]	Loss 2.9206e-06 (3.8528e-07)	Acc@1   1.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [107][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [107][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09382138651353501 -- best acc so far 53.69
***[2023-04-24 23:04:35]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [108][  0/250]	Loss 2.8610e-06 (2.8610e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [108][100/250]	Loss -3.5763e-06 (9.5013e-08)	Acc@1   0.50 (  1.00)	Acc@5   3.00 (  4.88)
[TRAIN] E: [108][200/250]	Loss 3.5763e-06 (1.6043e-07)	Acc@1   1.50 (  1.05)	Acc@5   6.00 (  5.05)
[TRAIN] E: [108][249/250]	Loss 6.5565e-07 (3.4213e-07)	Acc@1   0.50 (  1.00)	Acc@5   8.50 (  5.00)
[EVAL] E: [108][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [108][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09222312833981149 -- best acc so far 53.69
***[2023-04-24 23:06:23]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [109][  0/250]	Loss -5.9605e-08 (-5.9605e-08)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [109][100/250]	Loss -1.4901e-06 (3.0983e-07)	Acc@1   1.00 (  0.92)	Acc@5   5.50 (  4.80)
[TRAIN] E: [109][200/250]	Loss 3.6359e-06 (4.4125e-07)	Acc@1   2.00 (  0.98)	Acc@5   6.00 (  4.93)
[TRAIN] E: [109][249/250]	Loss 1.1921e-06 (2.8491e-07)	Acc@1   3.50 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [109][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [109][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09045823476844317 -- best acc so far 53.69
***[2023-04-24 23:08:06]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [110][  0/250]	Loss 1.6093e-06 (1.6093e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [110][100/250]	Loss 2.5630e-06 (5.8424e-08)	Acc@1   1.50 (  0.98)	Acc@5   4.00 (  5.14)
[TRAIN] E: [110][200/250]	Loss -2.3842e-06 (4.6557e-08)	Acc@1   1.00 (  1.02)	Acc@5   6.50 (  5.12)
[TRAIN] E: [110][249/250]	Loss -3.3975e-06 (1.8191e-07)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [110][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [110][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08853367102805308 -- best acc so far 53.69
***[2023-04-24 23:09:46]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [111][  0/250]	Loss -2.0862e-06 (-2.0862e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [111][100/250]	Loss -1.9670e-06 (1.5621e-06)	Acc@1   1.50 (  0.93)	Acc@5   5.50 (  5.22)
[TRAIN] E: [111][200/250]	Loss 2.8610e-06 (1.6206e-06)	Acc@1   1.00 (  0.98)	Acc@5   3.00 (  5.01)
[TRAIN] E: [111][249/250]	Loss 2.0266e-06 (1.1966e-06)	Acc@1   1.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [111][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [111][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08645703249247501 -- best acc so far 53.69
***[2023-04-24 23:11:33]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [112][  0/250]	Loss 1.9670e-06 (1.9670e-06)	Acc@1   3.00 (  3.00)	Acc@5   7.00 (  7.00)
[TRAIN] E: [112][100/250]	Loss -4.2915e-06 (-6.6981e-07)	Acc@1   1.00 (  0.98)	Acc@5   8.00 (  5.03)
[TRAIN] E: [112][200/250]	Loss 5.9605e-08 (2.7430e-07)	Acc@1   1.00 (  0.99)	Acc@5   4.50 (  5.00)
[TRAIN] E: [112][249/250]	Loss 2.5630e-06 (-1.8263e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [112][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [112][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08423651470528298 -- best acc so far 53.69
***[2023-04-24 23:13:19]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [113][  0/250]	Loss 2.4438e-06 (2.4438e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  3.00)
[TRAIN] E: [113][100/250]	Loss -5.4836e-06 (8.3860e-07)	Acc@1   0.00 (  1.00)	Acc@5   2.50 (  4.94)
[TRAIN] E: [113][200/250]	Loss 1.9073e-06 (5.7529e-07)	Acc@1   1.50 (  0.99)	Acc@5   7.00 (  4.94)
[TRAIN] E: [113][249/250]	Loss 3.0994e-06 (1.1094e-06)	Acc@1   0.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [113][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [113][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08188088103572495 -- best acc so far 53.69
***[2023-04-24 23:15:02]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [114][  0/250]	Loss 2.2650e-06 (2.2650e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [114][100/250]	Loss -3.3975e-06 (9.6784e-08)	Acc@1   2.00 (  1.06)	Acc@5   4.50 (  5.12)
[TRAIN] E: [114][200/250]	Loss 4.3511e-06 (4.7031e-07)	Acc@1   0.00 (  1.00)	Acc@5   6.00 (  5.04)
[TRAIN] E: [114][249/250]	Loss -2.3842e-07 (9.9254e-07)	Acc@1   0.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [114][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [114][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07939942809370802 -- best acc so far 53.69
***[2023-04-24 23:16:47]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [115][  0/250]	Loss -3.5763e-07 (-3.5763e-07)	Acc@1   1.50 (  1.50)	Acc@5   6.50 (  6.50)
[TRAIN] E: [115][100/250]	Loss 0.0000e+00 (-5.1461e-07)	Acc@1   0.50 (  1.06)	Acc@5   4.00 (  5.08)
[TRAIN] E: [115][200/250]	Loss 4.2319e-06 (4.6675e-07)	Acc@1   1.00 (  0.99)	Acc@5   6.50 (  4.99)
[TRAIN] E: [115][249/250]	Loss 2.0266e-06 (9.7728e-07)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [115][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [115][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0768019490403263 -- best acc so far 53.69
***[2023-04-24 23:18:30]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [116][  0/250]	Loss 2.0862e-06 (2.0862e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [116][100/250]	Loss 5.2452e-06 (-6.8044e-07)	Acc@1   1.00 (  0.93)	Acc@5   6.00 (  4.87)
[TRAIN] E: [116][200/250]	Loss 4.1723e-06 (-1.7763e-07)	Acc@1   1.00 (  0.97)	Acc@5   4.00 (  5.00)
[TRAIN] E: [116][249/250]	Loss 5.3048e-06 (-5.3453e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [116][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [116][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07409869493872821 -- best acc so far 53.69
***[2023-04-24 23:20:10]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [117][  0/250]	Loss 5.2452e-06 (5.2452e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [117][100/250]	Loss 3.9935e-06 (3.3278e-06)	Acc@1   1.50 (  1.01)	Acc@5   5.00 (  5.06)
[TRAIN] E: [117][200/250]	Loss -4.9472e-06 (1.6470e-06)	Acc@1   0.50 (  1.01)	Acc@5   5.50 (  5.08)
[TRAIN] E: [117][249/250]	Loss 5.6624e-06 (1.5831e-06)	Acc@1   1.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [117][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [117][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07130033429785343 -- best acc so far 53.69
***[2023-04-24 23:21:52]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [118][  0/250]	Loss 5.6624e-06 (5.6624e-06)	Acc@1   1.00 (  1.00)	Acc@5   2.50 (  2.50)
[TRAIN] E: [118][100/250]	Loss 2.6822e-06 (2.5612e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.90)
[TRAIN] E: [118][200/250]	Loss 3.5763e-06 (-4.7298e-07)	Acc@1   1.00 (  1.01)	Acc@5   4.50 (  5.07)
[TRAIN] E: [118][249/250]	Loss 3.1590e-06 (3.3259e-07)	Acc@1   0.50 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [118][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [118][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06841791096870212 -- best acc so far 53.69
***[2023-04-24 23:23:33]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [119][  0/250]	Loss 2.6226e-06 (2.6226e-06)	Acc@1   1.50 (  1.50)	Acc@5   7.50 (  7.50)
[TRAIN] E: [119][100/250]	Loss 3.0398e-06 (3.2169e-06)	Acc@1   0.00 (  1.00)	Acc@5   3.00 (  5.02)
[TRAIN] E: [119][200/250]	Loss 4.1723e-07 (2.7439e-06)	Acc@1   0.00 (  1.01)	Acc@5   4.50 (  4.95)
[TRAIN] E: [119][249/250]	Loss -4.7684e-06 (2.1262e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [119][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [119][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06546280055930047 -- best acc so far 53.69
***[2023-04-24 23:25:16]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [120][  0/250]	Loss -4.7684e-06 (-4.7684e-06)	Acc@1   2.50 (  2.50)	Acc@5   8.00 (  8.00)
[TRAIN] E: [120][100/250]	Loss 2.3842e-07 (-2.2449e-06)	Acc@1   0.50 (  0.92)	Acc@5   6.00 (  5.07)
[TRAIN] E: [120][200/250]	Loss 1.7285e-06 (-1.4928e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[TRAIN] E: [120][249/250]	Loss 2.8610e-06 (-7.4577e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [120][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [120][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06244666554037286 -- best acc so far 53.69
***[2023-04-24 23:26:59]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [121][  0/250]	Loss 2.5034e-06 (2.5034e-06)	Acc@1   0.00 (  0.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [121][100/250]	Loss 2.6822e-06 (2.2638e-06)	Acc@1   1.00 (  0.90)	Acc@5   4.00 (  5.04)
[TRAIN] E: [121][200/250]	Loss 1.8477e-06 (2.1914e-06)	Acc@1   0.00 (  0.98)	Acc@5   4.50 (  4.99)
[TRAIN] E: [121][249/250]	Loss 2.2650e-06 (2.1832e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [121][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [121][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05938140921889801 -- best acc so far 53.69
***[2023-04-24 23:28:37]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [122][  0/250]	Loss 2.1458e-06 (2.1458e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [122][100/250]	Loss 2.1458e-06 (1.9870e-06)	Acc@1   1.50 (  0.97)	Acc@5   7.00 (  4.96)
[TRAIN] E: [122][200/250]	Loss 2.4438e-06 (1.9625e-06)	Acc@1   0.50 (  1.00)	Acc@5   2.50 (  5.00)
[TRAIN] E: [122][249/250]	Loss 2.3842e-06 (1.9758e-06)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [122][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [122][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05627912876119434 -- best acc so far 53.69
***[2023-04-24 23:30:15]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [123][  0/250]	Loss 1.9670e-06 (1.9670e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [123][100/250]	Loss 1.8477e-06 (2.0148e-06)	Acc@1   1.00 (  0.98)	Acc@5   3.50 (  5.04)
[TRAIN] E: [123][200/250]	Loss 2.0862e-06 (2.0174e-06)	Acc@1   3.50 (  1.00)	Acc@5   6.00 (  4.99)
[TRAIN] E: [123][249/250]	Loss 2.2054e-06 (2.0199e-06)	Acc@1   0.50 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [123][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [123][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05315206745093132 -- best acc so far 53.69
***[2023-04-24 23:31:56]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [124][  0/250]	Loss 1.8477e-06 (1.8477e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [124][100/250]	Loss 2.2650e-06 (2.0266e-06)	Acc@1   0.50 (  0.93)	Acc@5   6.00 (  4.94)
[TRAIN] E: [124][200/250]	Loss 1.8477e-06 (2.0215e-06)	Acc@1   1.00 (  0.97)	Acc@5   5.50 (  5.04)
[TRAIN] E: [124][249/250]	Loss 1.9073e-06 (2.0235e-06)	Acc@1   4.50 (  1.00)	Acc@5   9.00 (  5.00)
[EVAL] E: [124][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [124][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.050012566370482084 -- best acc so far 53.69
***[2023-04-24 23:33:35]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [125][  0/250]	Loss 2.1458e-06 (2.1458e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[TRAIN] E: [125][100/250]	Loss 2.0266e-06 (2.0230e-06)	Acc@1   0.50 (  0.96)	Acc@5   4.50 (  4.71)
[TRAIN] E: [125][200/250]	Loss 1.6093e-06 (2.0197e-06)	Acc@1   0.00 (  0.98)	Acc@5   3.50 (  4.88)
[TRAIN] E: [125][249/250]	Loss 2.0862e-06 (2.0230e-06)	Acc@1   0.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [125][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [125][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0468730156963096 -- best acc so far 53.69
***[2023-04-24 23:35:11]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [126][  0/250]	Loss 2.3842e-06 (2.3842e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [126][100/250]	Loss 2.3246e-06 (2.0183e-06)	Acc@1   1.00 (  1.05)	Acc@5   4.50 (  5.32)
[TRAIN] E: [126][200/250]	Loss 1.9670e-06 (2.0218e-06)	Acc@1   0.00 (  0.99)	Acc@5   4.00 (  5.07)
[TRAIN] E: [126][249/250]	Loss 2.4438e-06 (2.0232e-06)	Acc@1   1.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [126][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [126][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.04374580580060053 -- best acc so far 53.69
***[2023-04-24 23:36:42]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [127][  0/250]	Loss 1.9073e-06 (1.9073e-06)	Acc@1   1.50 (  1.50)	Acc@5   6.50 (  6.50)
[TRAIN] E: [127][100/250]	Loss 1.9670e-06 (2.0201e-06)	Acc@1   0.50 (  1.06)	Acc@5   5.00 (  4.95)
[TRAIN] E: [127][200/250]	Loss 1.8477e-06 (2.0200e-06)	Acc@1   1.00 (  1.03)	Acc@5   4.00 (  5.03)
[TRAIN] E: [127][249/250]	Loss 2.0862e-06 (2.0211e-06)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [127][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [127][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.04064327835212697 -- best acc so far 53.69
***[2023-04-24 23:38:10]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [128][  0/250]	Loss 2.4438e-06 (2.4438e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  6.50)
[TRAIN] E: [128][100/250]	Loss 2.0862e-06 (2.0236e-06)	Acc@1   0.00 (  0.99)	Acc@5   2.50 (  5.02)
[TRAIN] E: [128][200/250]	Loss 1.7881e-06 (2.0218e-06)	Acc@1   1.00 (  1.02)	Acc@5   6.00 (  4.97)
[TRAIN] E: [128][249/250]	Loss 2.2650e-06 (2.0225e-06)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [128][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [128][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.037577677609318 -- best acc so far 53.69
***[2023-04-24 23:39:41]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [129][  0/250]	Loss 2.2650e-06 (2.2650e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [129][100/250]	Loss 1.9073e-06 (2.0236e-06)	Acc@1   0.50 (  0.96)	Acc@5   2.50 (  5.04)
[TRAIN] E: [129][200/250]	Loss 1.9073e-06 (2.0230e-06)	Acc@1   0.50 (  0.99)	Acc@5   4.50 (  5.04)
[TRAIN] E: [129][249/250]	Loss 2.1458e-06 (2.0235e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [129][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [129][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.034561102097765826 -- best acc so far 53.69
***[2023-04-24 23:41:11]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [130][  0/250]	Loss 2.2054e-06 (2.2054e-06)	Acc@1   2.50 (  2.50)	Acc@5   9.50 (  9.50)
[TRAIN] E: [130][100/250]	Loss 2.0266e-06 (2.0260e-06)	Acc@1   0.50 (  1.01)	Acc@5   2.50 (  4.94)
[TRAIN] E: [130][200/250]	Loss 2.0862e-06 (2.0242e-06)	Acc@1   1.00 (  1.01)	Acc@5   8.00 (  5.06)
[TRAIN] E: [130][249/250]	Loss 1.7285e-06 (2.0232e-06)	Acc@1   0.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [130][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [130][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.03160545686287225 -- best acc so far 53.69
***[2023-04-24 23:42:39]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [131][  0/250]	Loss 1.7881e-06 (1.7881e-06)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [131][100/250]	Loss 2.0266e-06 (2.0189e-06)	Acc@1   1.50 (  0.95)	Acc@5   4.50 (  4.92)
[TRAIN] E: [131][200/250]	Loss 1.9670e-06 (2.0212e-06)	Acc@1   1.00 (  0.98)	Acc@5   2.50 (  4.97)
[TRAIN] E: [131][249/250]	Loss 2.2054e-06 (2.0220e-06)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [131][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [131][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.028722406486073528 -- best acc so far 53.69
***[2023-04-24 23:44:10]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [132][  0/250]	Loss 2.2650e-06 (2.2650e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [132][100/250]	Loss 2.4438e-06 (2.0218e-06)	Acc@1   1.50 (  1.02)	Acc@5   6.00 (  5.17)
[TRAIN] E: [132][200/250]	Loss 1.7285e-06 (2.0227e-06)	Acc@1   1.00 (  0.98)	Acc@5   5.00 (  5.00)
[TRAIN] E: [132][249/250]	Loss 2.0862e-06 (2.0225e-06)	Acc@1   0.50 (  1.00)	Acc@5   1.00 (  5.00)
[EVAL] E: [132][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [132][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.02592332905006647 -- best acc so far 53.69
***[2023-04-24 23:45:39]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [133][  0/250]	Loss 2.1458e-06 (2.1458e-06)	Acc@1   1.50 (  1.50)	Acc@5   7.00 (  7.00)
[TRAIN] E: [133][100/250]	Loss 1.9670e-06 (2.0212e-06)	Acc@1   2.00 (  0.97)	Acc@5   7.00 (  5.09)
[TRAIN] E: [133][200/250]	Loss 1.7285e-06 (2.0174e-06)	Acc@1   1.50 (  1.00)	Acc@5   4.00 (  4.99)
[TRAIN] E: [133][249/250]	Loss 1.9670e-06 (2.0208e-06)	Acc@1   1.50 (  1.00)	Acc@5   7.50 (  5.00)
[EVAL] E: [133][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [133][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.02321927123471412 -- best acc so far 53.69
***[2023-04-24 23:47:04]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [134][  0/250]	Loss 2.2054e-06 (2.2054e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [134][100/250]	Loss 2.3246e-06 (2.0283e-06)	Acc@1   1.00 (  0.99)	Acc@5   4.00 (  4.94)
[TRAIN] E: [134][200/250]	Loss 2.2054e-06 (2.0230e-06)	Acc@1   0.00 (  1.00)	Acc@5   5.00 (  4.98)
[TRAIN] E: [134][249/250]	Loss 2.2650e-06 (2.0239e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [134][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [134][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.02062090472084719 -- best acc so far 53.69
***[2023-04-24 23:48:26]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [135][  0/250]	Loss 1.9670e-06 (1.9670e-06)	Acc@1   1.00 (  1.00)	Acc@5   7.00 (  7.00)
[TRAIN] E: [135][100/250]	Loss 2.1458e-06 (2.0183e-06)	Acc@1   2.00 (  0.98)	Acc@5   8.50 (  5.04)
[TRAIN] E: [135][200/250]	Loss 2.3246e-06 (2.0215e-06)	Acc@1   1.50 (  1.01)	Acc@5   6.50 (  5.02)
[TRAIN] E: [135][249/250]	Loss 1.7881e-06 (2.0187e-06)	Acc@1   1.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [135][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [135][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.018138484074015165 -- best acc so far 53.69
***[2023-04-24 23:49:51]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [136][  0/250]	Loss 2.8014e-06 (2.8014e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [136][100/250]	Loss 1.4305e-06 (2.0271e-06)	Acc@1   0.00 (  0.92)	Acc@5   4.50 (  4.96)
[TRAIN] E: [136][200/250]	Loss 2.5630e-06 (2.0277e-06)	Acc@1   0.50 (  0.95)	Acc@5   6.00 (  5.00)
[TRAIN] E: [136][249/250]	Loss 2.0862e-06 (2.0249e-06)	Acc@1   0.50 (  1.00)	Acc@5   2.00 (  5.00)
[EVAL] E: [136][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [136][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.015781806274400994 -- best acc so far 53.69
***[2023-04-24 23:51:14]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [137][  0/250]	Loss 2.0862e-06 (2.0862e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [137][100/250]	Loss 1.9670e-06 (2.0224e-06)	Acc@1   1.50 (  0.99)	Acc@5   4.00 (  5.01)
[TRAIN] E: [137][200/250]	Loss 2.0266e-06 (2.0236e-06)	Acc@1   1.00 (  1.02)	Acc@5   4.50 (  5.03)
[TRAIN] E: [137][249/250]	Loss 1.6689e-06 (2.0208e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [137][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [137][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.01356017205261605 -- best acc so far 53.69
***[2023-04-24 23:52:37]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [138][  0/250]	Loss 2.3246e-06 (2.3246e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [138][100/250]	Loss 1.9670e-06 (2.0283e-06)	Acc@1   2.00 (  0.95)	Acc@5   6.50 (  4.98)
[TRAIN] E: [138][200/250]	Loss 1.9670e-06 (2.0227e-06)	Acc@1   3.00 (  0.99)	Acc@5   8.50 (  4.91)
[TRAIN] E: [138][249/250]	Loss 1.8477e-06 (2.0237e-06)	Acc@1   0.50 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [138][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [138][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.011482349183965603 -- best acc so far 53.69
***[2023-04-24 23:54:01]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [139][  0/250]	Loss 2.0862e-06 (2.0862e-06)	Acc@1   0.00 (  0.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [139][100/250]	Loss 1.5497e-06 (2.0189e-06)	Acc@1   1.00 (  1.01)	Acc@5   6.00 (  4.98)
[TRAIN] E: [139][200/250]	Loss 2.3246e-06 (2.0248e-06)	Acc@1   0.50 (  0.98)	Acc@5   5.50 (  5.03)
[TRAIN] E: [139][249/250]	Loss 2.0266e-06 (2.0225e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [139][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [139][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.009556537886045241 -- best acc so far 53.69
***[2023-04-24 23:55:24]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [140][  0/250]	Loss 2.0862e-06 (2.0862e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  6.50)
[TRAIN] E: [140][100/250]	Loss 1.6689e-06 (2.0207e-06)	Acc@1   1.50 (  0.97)	Acc@5   6.00 (  5.07)
[TRAIN] E: [140][200/250]	Loss 2.2650e-06 (2.0212e-06)	Acc@1   0.00 (  1.02)	Acc@5   5.00 (  5.09)
[TRAIN] E: [140][249/250]	Loss 2.2650e-06 (2.0230e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [140][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [140][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.007790338456228368 -- best acc so far 53.69
***[2023-04-24 23:56:48]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [141][  0/250]	Loss 2.5034e-06 (2.5034e-06)	Acc@1   1.50 (  1.50)	Acc@5   7.00 (  7.00)
[TRAIN] E: [141][100/250]	Loss 2.0862e-06 (2.0165e-06)	Acc@1   0.00 (  1.01)	Acc@5   4.00 (  5.00)
[TRAIN] E: [141][200/250]	Loss 2.4438e-06 (2.0191e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  5.01)
[TRAIN] E: [141][249/250]	Loss 2.4438e-06 (2.0204e-06)	Acc@1   2.50 (  1.00)	Acc@5   8.00 (  5.00)
[EVAL] E: [141][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [141][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.006190721276764699 -- best acc so far 53.69
***[2023-04-24 23:58:10]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [142][  0/250]	Loss 1.7285e-06 (1.7285e-06)	Acc@1   0.00 (  0.00)	Acc@5   7.50 (  7.50)
[TRAIN] E: [142][100/250]	Loss 1.8477e-06 (2.0207e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  5.02)
[TRAIN] E: [142][200/250]	Loss 1.9670e-06 (2.0239e-06)	Acc@1   1.00 (  0.98)	Acc@5   5.00 (  4.99)
[TRAIN] E: [142][249/250]	Loss 1.7881e-06 (2.0208e-06)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [142][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [142][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.004763999305866018 -- best acc so far 53.69
***[2023-04-24 23:59:34]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [143][  0/250]	Loss 1.9670e-06 (1.9670e-06)	Acc@1   0.00 (  0.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [143][100/250]	Loss 1.7285e-06 (2.0271e-06)	Acc@1   2.50 (  0.94)	Acc@5   7.00 (  4.76)
[TRAIN] E: [143][200/250]	Loss 1.8477e-06 (2.0236e-06)	Acc@1   0.50 (  0.98)	Acc@5   3.50 (  4.92)
[TRAIN] E: [143][249/250]	Loss 1.9073e-06 (2.0213e-06)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [143][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [143][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.003515803163344161 -- best acc so far 53.69
***[2023-04-25 00:00:58]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [144][  0/250]	Loss 2.0266e-06 (2.0266e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [144][100/250]	Loss 2.3842e-06 (2.0313e-06)	Acc@1   0.00 (  0.94)	Acc@5   6.50 (  5.00)
[TRAIN] E: [144][200/250]	Loss 2.3246e-06 (2.0272e-06)	Acc@1   1.50 (  0.98)	Acc@5   4.50 (  4.98)
[TRAIN] E: [144][249/250]	Loss 2.0266e-06 (2.0242e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [144][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [144][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.00245105890912713 -- best acc so far 53.69
***[2023-04-25 00:02:20]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [145][  0/250]	Loss 2.0862e-06 (2.0862e-06)	Acc@1   2.00 (  2.00)	Acc@5   8.50 (  8.50)
[TRAIN] E: [145][100/250]	Loss 2.0266e-06 (2.0271e-06)	Acc@1   1.50 (  0.95)	Acc@5   7.00 (  4.98)
[TRAIN] E: [145][200/250]	Loss 1.9073e-06 (2.0200e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  4.98)
[TRAIN] E: [145][249/250]	Loss 2.1458e-06 (2.0208e-06)	Acc@1   2.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [145][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [145][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.001573968602350906 -- best acc so far 53.69
***[2023-04-25 00:03:42]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [146][  0/250]	Loss 2.2650e-06 (2.2650e-06)	Acc@1   0.00 (  0.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [146][100/250]	Loss 1.6689e-06 (2.0189e-06)	Acc@1   0.50 (  0.98)	Acc@5   2.00 (  4.96)
[TRAIN] E: [146][200/250]	Loss 1.9073e-06 (2.0230e-06)	Acc@1   1.00 (  0.97)	Acc@5   5.50 (  5.00)
[TRAIN] E: [146][249/250]	Loss 1.6093e-06 (2.0194e-06)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [146][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [146][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.000887993717751906 -- best acc so far 53.69
***[2023-04-25 00:05:06]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [147][  0/250]	Loss 2.3246e-06 (2.3246e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [147][100/250]	Loss 2.3246e-06 (2.0254e-06)	Acc@1   0.00 (  0.92)	Acc@5   4.00 (  4.97)
[TRAIN] E: [147][200/250]	Loss 1.4901e-06 (2.0233e-06)	Acc@1   0.00 (  0.99)	Acc@5   5.00 (  4.98)
[TRAIN] E: [147][249/250]	Loss 2.2054e-06 (2.0185e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [147][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [147][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0003958414848075243 -- best acc so far 53.69
***[2023-04-25 00:06:31]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [148][  0/250]	Loss 2.9206e-06 (2.9206e-06)	Acc@1   1.50 (  1.50)	Acc@5   9.50 (  9.50)
[TRAIN] E: [148][100/250]	Loss 1.7881e-06 (2.0094e-06)	Acc@1   2.00 (  1.01)	Acc@5  10.50 (  5.14)
[TRAIN] E: [148][200/250]	Loss 2.6226e-06 (1.9981e-06)	Acc@1   1.00 (  1.02)	Acc@5   4.00 (  4.97)
[TRAIN] E: [148][249/250]	Loss 1.9073e-06 (2.0039e-06)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [148][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [148][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=9.945420353821844e-05 -- best acc so far 53.69
***[2023-04-25 00:07:52]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [149][  0/250]	Loss 2.6226e-06 (2.6226e-06)	Acc@1   0.00 (  0.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [149][100/250]	Loss 2.0266e-06 (2.2449e-06)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.09)
[TRAIN] E: [149][200/250]	Loss 3.0398e-06 (2.5568e-06)	Acc@1   0.50 (  0.98)	Acc@5   5.50 (  5.07)
[TRAIN] E: [149][249/250]	Loss 3.0398e-06 (2.6515e-06)	Acc@1   2.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [149][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [149][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=1.57913669363019e-09 -- best acc so far 53.69
***[2023-04-25 00:09:16]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [150][  0/250]	Loss 3.0398e-06 (3.0398e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [150][100/250]	Loss 2.9206e-06 (1.9599e-06)	Acc@1   1.00 (  0.98)	Acc@5   4.00 (  4.94)
[TRAIN] E: [150][200/250]	Loss 2.8610e-06 (2.0011e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  5.00)
[TRAIN] E: [150][249/250]	Loss 2.6822e-06 (2.0108e-06)	Acc@1   3.00 (  1.00)	Acc@5   7.50 (  5.00)
[EVAL] E: [150][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [150][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09990212389432412 -- best acc so far 53.69
***[2023-04-25 00:10:42]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [151][  0/250]	Loss 2.7418e-06 (2.7418e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  6.50)
[TRAIN] E: [151][100/250]	Loss 2.1458e-06 (2.0083e-06)	Acc@1   1.00 (  0.99)	Acc@5   4.50 (  5.00)
[TRAIN] E: [151][200/250]	Loss 2.4438e-06 (2.0183e-06)	Acc@1   2.00 (  1.01)	Acc@5   3.00 (  5.01)
[TRAIN] E: [151][249/250]	Loss 2.0862e-06 (2.0242e-06)	Acc@1   2.50 (  1.00)	Acc@5   8.50 (  5.00)
[EVAL] E: [151][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [151][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09960730848288585 -- best acc so far 53.69
***[2023-04-25 00:12:09]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [152][  0/250]	Loss 1.8477e-06 (1.8477e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [152][100/250]	Loss 2.1458e-06 (2.0071e-06)	Acc@1   1.00 (  1.06)	Acc@5   5.50 (  5.03)
[TRAIN] E: [152][200/250]	Loss 1.6689e-06 (2.0186e-06)	Acc@1   0.50 (  1.03)	Acc@5   7.00 (  5.03)
[TRAIN] E: [152][249/250]	Loss 3.2187e-06 (2.0216e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [152][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [152][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09911671568828909 -- best acc so far 53.69
***[2023-04-25 00:13:32]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [153][  0/250]	Loss 2.5630e-06 (2.5630e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [153][100/250]	Loss 2.3246e-06 (2.0094e-06)	Acc@1   1.50 (  0.93)	Acc@5   4.50 (  5.04)
[TRAIN] E: [153][200/250]	Loss 1.8477e-06 (2.0183e-06)	Acc@1   0.50 (  0.98)	Acc@5   5.50 (  4.99)
[TRAIN] E: [153][249/250]	Loss 1.8477e-06 (2.0156e-06)	Acc@1   1.00 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [153][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [153][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0984322816561636 -- best acc so far 53.69
***[2023-04-25 00:14:56]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [154][  0/250]	Loss 3.3379e-06 (3.3379e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [154][100/250]	Loss 2.1458e-06 (2.0313e-06)	Acc@1   0.50 (  1.02)	Acc@5   6.00 (  5.04)
[TRAIN] E: [154][200/250]	Loss 1.7881e-06 (2.0280e-06)	Acc@1   1.00 (  1.01)	Acc@5   4.00 (  4.99)
[TRAIN] E: [154][249/250]	Loss 1.7285e-06 (2.0239e-06)	Acc@1   2.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [154][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [154][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.097556707534946 -- best acc so far 53.69
***[2023-04-25 00:16:21]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [155][  0/250]	Loss 2.3246e-06 (2.3246e-06)	Acc@1   1.50 (  1.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [155][100/250]	Loss 1.7881e-06 (2.0260e-06)	Acc@1   1.00 (  1.01)	Acc@5   6.00 (  4.97)
[TRAIN] E: [155][200/250]	Loss 2.0266e-06 (2.0269e-06)	Acc@1   0.00 (  1.03)	Acc@5   3.00 (  4.97)
[TRAIN] E: [155][249/250]	Loss 1.6689e-06 (2.0225e-06)	Acc@1   1.50 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [155][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [155][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09649344881568098 -- best acc so far 53.69
***[2023-04-25 00:17:45]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [156][  0/250]	Loss 1.9670e-06 (1.9670e-06)	Acc@1   1.50 (  1.50)	Acc@5   9.00 (  9.00)
[TRAIN] E: [156][100/250]	Loss 2.0266e-06 (2.0289e-06)	Acc@1   1.00 (  1.06)	Acc@5   4.50 (  4.98)
[TRAIN] E: [156][200/250]	Loss 1.9670e-06 (2.0292e-06)	Acc@1   1.00 (  1.03)	Acc@5   6.00 (  4.98)
[TRAIN] E: [156][249/250]	Loss 2.2054e-06 (2.0254e-06)	Acc@1   1.50 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [156][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [156][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09524670169477677 -- best acc so far 53.69
***[2023-04-25 00:19:06]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [157][  0/250]	Loss 1.9073e-06 (1.9073e-06)	Acc@1   0.50 (  0.50)	Acc@5   2.50 (  2.50)
[TRAIN] E: [157][100/250]	Loss 1.6689e-06 (2.0236e-06)	Acc@1   1.00 (  0.96)	Acc@5   5.00 (  4.90)
[TRAIN] E: [157][200/250]	Loss 2.2054e-06 (2.0254e-06)	Acc@1   1.50 (  0.95)	Acc@5   7.00 (  4.97)
[TRAIN] E: [157][249/250]	Loss 2.0266e-06 (2.0227e-06)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [157][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [157][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.093821386513535 -- best acc so far 53.69
***[2023-04-25 00:20:29]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [158][  0/250]	Loss 1.6689e-06 (1.6689e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [158][100/250]	Loss 1.7285e-06 (2.0218e-06)	Acc@1   0.00 (  0.97)	Acc@5   4.50 (  5.17)
[TRAIN] E: [158][200/250]	Loss 1.9670e-06 (2.0227e-06)	Acc@1   2.00 (  1.00)	Acc@5   6.00 (  5.00)
[TRAIN] E: [158][249/250]	Loss 1.7285e-06 (2.0213e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [158][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [158][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09222312833981146 -- best acc so far 53.69
***[2023-04-25 00:21:52]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [159][  0/250]	Loss 1.9073e-06 (1.9073e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [159][100/250]	Loss 2.2054e-06 (2.0289e-06)	Acc@1   1.00 (  1.05)	Acc@5   5.00 (  4.94)
[TRAIN] E: [159][200/250]	Loss 2.3246e-06 (2.0209e-06)	Acc@1   0.50 (  0.99)	Acc@5   4.50 (  4.98)
[TRAIN] E: [159][249/250]	Loss 1.9073e-06 (2.0237e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [159][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [159][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09045823476844314 -- best acc so far 53.69
***[2023-04-25 00:23:16]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [160][  0/250]	Loss 2.0266e-06 (2.0266e-06)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [160][100/250]	Loss 2.2650e-06 (2.0260e-06)	Acc@1   0.00 (  1.04)	Acc@5   6.50 (  5.02)
[TRAIN] E: [160][200/250]	Loss 2.2650e-06 (2.0183e-06)	Acc@1   1.00 (  1.03)	Acc@5   6.00 (  5.07)
[TRAIN] E: [160][249/250]	Loss 2.1458e-06 (2.0227e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [160][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [160][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08853367102805305 -- best acc so far 53.69
***[2023-04-25 00:24:39]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [161][  0/250]	Loss 2.0266e-06 (2.0266e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [161][100/250]	Loss 2.8610e-06 (2.0201e-06)	Acc@1   1.50 (  0.89)	Acc@5   3.50 (  5.01)
[TRAIN] E: [161][200/250]	Loss 2.0266e-06 (2.0180e-06)	Acc@1   0.00 (  1.00)	Acc@5   2.50 (  4.92)
[TRAIN] E: [161][249/250]	Loss 2.3842e-06 (2.0239e-06)	Acc@1   0.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [161][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [161][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08645703249247498 -- best acc so far 53.69
***[2023-04-25 00:26:03]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [162][  0/250]	Loss 1.6689e-06 (1.6689e-06)	Acc@1   0.50 (  0.50)	Acc@5   2.50 (  2.50)
[TRAIN] E: [162][100/250]	Loss 2.1458e-06 (2.0089e-06)	Acc@1   1.00 (  0.98)	Acc@5   3.00 (  4.84)
[TRAIN] E: [162][200/250]	Loss 1.9670e-06 (2.0165e-06)	Acc@1   1.50 (  1.01)	Acc@5   6.50 (  4.93)
[TRAIN] E: [162][249/250]	Loss 3.3379e-06 (2.0194e-06)	Acc@1   0.50 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [162][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [162][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08423651470528294 -- best acc so far 53.69
***[2023-04-25 00:27:24]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [163][  0/250]	Loss 3.2187e-06 (3.2187e-06)	Acc@1   1.50 (  1.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [163][100/250]	Loss 2.2054e-06 (2.0189e-06)	Acc@1   0.00 (  0.92)	Acc@5   4.00 (  4.81)
[TRAIN] E: [163][200/250]	Loss 1.5497e-06 (2.0188e-06)	Acc@1   0.50 (  0.97)	Acc@5   4.50 (  4.94)
[TRAIN] E: [163][249/250]	Loss 2.5034e-06 (2.0201e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [163][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [163][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08188088103572491 -- best acc so far 53.69
***[2023-04-25 00:28:49]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [164][  0/250]	Loss 3.0994e-06 (3.0994e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [164][100/250]	Loss 2.2054e-06 (2.0271e-06)	Acc@1   0.50 (  1.05)	Acc@5   3.00 (  4.89)
[TRAIN] E: [164][200/250]	Loss 2.0266e-06 (2.0251e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  4.99)
[TRAIN] E: [164][249/250]	Loss 2.4438e-06 (2.0230e-06)	Acc@1   2.50 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [164][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [164][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07939942809370798 -- best acc so far 53.69
***[2023-04-25 00:30:11]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [165][  0/250]	Loss 2.2650e-06 (2.2650e-06)	Acc@1   0.00 (  0.00)	Acc@5   1.00 (  1.00)
[TRAIN] E: [165][100/250]	Loss 1.5497e-06 (2.0218e-06)	Acc@1   2.00 (  1.00)	Acc@5   5.50 (  4.90)
[TRAIN] E: [165][200/250]	Loss 1.9670e-06 (2.0248e-06)	Acc@1   1.00 (  0.98)	Acc@5   5.50 (  5.00)
[TRAIN] E: [165][249/250]	Loss 2.0266e-06 (2.0201e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [165][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [165][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07680194904032628 -- best acc so far 53.69
***[2023-04-25 00:31:33]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [166][  0/250]	Loss 2.3842e-06 (2.3842e-06)	Acc@1   1.50 (  1.50)	Acc@5   6.50 (  6.50)
[TRAIN] E: [166][100/250]	Loss 2.0266e-06 (2.0319e-06)	Acc@1   0.50 (  0.95)	Acc@5   4.00 (  4.95)
[TRAIN] E: [166][200/250]	Loss 2.0266e-06 (2.0292e-06)	Acc@1   1.50 (  1.01)	Acc@5   5.00 (  4.96)
[TRAIN] E: [166][249/250]	Loss 2.1458e-06 (2.0263e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [166][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [166][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07409869493872817 -- best acc so far 53.69
***[2023-04-25 00:32:57]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [167][  0/250]	Loss 1.6689e-06 (1.6689e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [167][100/250]	Loss 1.6689e-06 (2.0189e-06)	Acc@1   0.50 (  1.03)	Acc@5   6.00 (  5.13)
[TRAIN] E: [167][200/250]	Loss 2.0266e-06 (2.0245e-06)	Acc@1   1.00 (  1.02)	Acc@5   5.00 (  4.98)
[TRAIN] E: [167][249/250]	Loss 1.9670e-06 (2.0208e-06)	Acc@1   2.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [167][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [167][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07130033429785339 -- best acc so far 53.69
***[2023-04-25 00:34:20]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [168][  0/250]	Loss 2.2054e-06 (2.2054e-06)	Acc@1   0.00 (  0.00)	Acc@5   3.00 (  3.00)
[TRAIN] E: [168][100/250]	Loss 2.0862e-06 (2.0271e-06)	Acc@1   1.50 (  1.03)	Acc@5   5.50 (  5.10)
[TRAIN] E: [168][200/250]	Loss 1.6689e-06 (2.0239e-06)	Acc@1   1.00 (  0.98)	Acc@5   6.50 (  4.97)
[TRAIN] E: [168][249/250]	Loss 2.2054e-06 (2.0244e-06)	Acc@1   1.50 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [168][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [168][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06841791096870208 -- best acc so far 53.69
***[2023-04-25 00:35:41]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [169][  0/250]	Loss 1.8477e-06 (1.8477e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [169][100/250]	Loss 2.3246e-06 (2.0289e-06)	Acc@1   1.50 (  1.07)	Acc@5   6.00 (  5.19)
[TRAIN] E: [169][200/250]	Loss 1.7881e-06 (2.0183e-06)	Acc@1   1.00 (  1.03)	Acc@5   4.50 (  5.04)
[TRAIN] E: [169][249/250]	Loss 1.5497e-06 (2.0206e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [169][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [169][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06546280055930041 -- best acc so far 53.69
***[2023-04-25 00:37:04]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [170][  0/250]	Loss 1.9073e-06 (1.9073e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [170][100/250]	Loss 2.1458e-06 (2.0271e-06)	Acc@1   0.00 (  0.95)	Acc@5   5.00 (  5.05)
[TRAIN] E: [170][200/250]	Loss 1.9670e-06 (2.0186e-06)	Acc@1   0.50 (  1.02)	Acc@5   5.50 (  5.04)
[TRAIN] E: [170][249/250]	Loss 1.7285e-06 (2.0244e-06)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [170][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [170][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06244666554037283 -- best acc so far 53.69
***[2023-04-25 00:38:27]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [171][  0/250]	Loss 1.9073e-06 (1.9073e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [171][100/250]	Loss 2.0266e-06 (2.0130e-06)	Acc@1   1.50 (  0.97)	Acc@5   6.00 (  4.77)
[TRAIN] E: [171][200/250]	Loss 2.0266e-06 (2.0180e-06)	Acc@1   1.50 (  0.97)	Acc@5   5.50 (  4.95)
[TRAIN] E: [171][249/250]	Loss 2.0266e-06 (2.0225e-06)	Acc@1   0.50 (  1.00)	Acc@5   2.00 (  5.00)
[EVAL] E: [171][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [171][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.059381409218897965 -- best acc so far 53.69
***[2023-04-25 00:39:51]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [172][  0/250]	Loss 2.1458e-06 (2.1458e-06)	Acc@1   0.00 (  0.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [172][100/250]	Loss 1.9670e-06 (2.0100e-06)	Acc@1   1.00 (  1.02)	Acc@5   2.50 (  5.17)
[TRAIN] E: [172][200/250]	Loss 1.7285e-06 (2.0162e-06)	Acc@1   0.00 (  1.02)	Acc@5   6.50 (  4.99)
[TRAIN] E: [172][249/250]	Loss 2.2650e-06 (2.0189e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [172][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [172][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0562791287611943 -- best acc so far 53.69
***[2023-04-25 00:41:14]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [173][  0/250]	Loss 2.6822e-06 (2.6822e-06)	Acc@1   0.50 (  0.50)	Acc@5   2.50 (  2.50)
[TRAIN] E: [173][100/250]	Loss 1.9073e-06 (2.0195e-06)	Acc@1   2.00 (  0.91)	Acc@5   4.50 (  5.07)
[TRAIN] E: [173][200/250]	Loss 1.9670e-06 (2.0218e-06)	Acc@1   0.50 (  0.94)	Acc@5   3.50 (  5.02)
[TRAIN] E: [173][249/250]	Loss 1.9073e-06 (2.0192e-06)	Acc@1   2.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [173][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [173][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05315206745093126 -- best acc so far 53.69
***[2023-04-25 00:42:37]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [174][  0/250]	Loss 2.5630e-06 (2.5630e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [174][100/250]	Loss 1.9073e-06 (2.0271e-06)	Acc@1   2.50 (  0.98)	Acc@5   9.00 (  4.98)
[TRAIN] E: [174][200/250]	Loss 1.6093e-06 (2.0266e-06)	Acc@1   1.50 (  1.00)	Acc@5   9.00 (  5.09)
[TRAIN] E: [174][249/250]	Loss 2.1458e-06 (2.0235e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [174][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [174][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05001256637048204 -- best acc so far 53.69
***[2023-04-25 00:43:58]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [175][  0/250]	Loss 2.0862e-06 (2.0862e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [175][100/250]	Loss 2.0266e-06 (2.0230e-06)	Acc@1   2.00 (  0.95)	Acc@5   5.50 (  4.97)
[TRAIN] E: [175][200/250]	Loss 2.0266e-06 (2.0292e-06)	Acc@1   2.00 (  1.00)	Acc@5   6.00 (  5.05)
[TRAIN] E: [175][249/250]	Loss 2.1458e-06 (2.0232e-06)	Acc@1   2.50 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [175][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [175][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.046873015696309556 -- best acc so far 53.69
***[2023-04-25 00:45:22]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [176][  0/250]	Loss 2.1458e-06 (2.1458e-06)	Acc@1   1.50 (  1.50)	Acc@5   9.00 (  9.00)
[TRAIN] E: [176][100/250]	Loss 1.7285e-06 (2.0271e-06)	Acc@1   0.50 (  0.98)	Acc@5   6.50 (  5.08)
[TRAIN] E: [176][200/250]	Loss 2.5034e-06 (2.0245e-06)	Acc@1   1.00 (  0.99)	Acc@5   5.00 (  5.10)
[TRAIN] E: [176][249/250]	Loss 1.7881e-06 (2.0235e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [176][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [176][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.04374580580060049 -- best acc so far 53.69
***[2023-04-25 00:46:47]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [177][  0/250]	Loss 1.7881e-06 (1.7881e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[TRAIN] E: [177][100/250]	Loss 2.0862e-06 (2.0271e-06)	Acc@1   1.50 (  1.02)	Acc@5   4.50 (  4.96)
[TRAIN] E: [177][200/250]	Loss 2.6822e-06 (2.0245e-06)	Acc@1   1.50 (  1.03)	Acc@5   6.50 (  5.00)
[TRAIN] E: [177][249/250]	Loss 1.8477e-06 (2.0213e-06)	Acc@1   1.00 (  1.00)	Acc@5   8.50 (  5.00)
[EVAL] E: [177][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [177][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.040643278352126916 -- best acc so far 53.69
***[2023-04-25 00:48:10]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [178][  0/250]	Loss 2.2650e-06 (2.2650e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [178][100/250]	Loss 2.0862e-06 (2.0336e-06)	Acc@1   1.50 (  1.04)	Acc@5   5.50 (  4.88)
[TRAIN] E: [178][200/250]	Loss 2.2650e-06 (2.0197e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  4.94)
[TRAIN] E: [178][249/250]	Loss 1.9670e-06 (2.0251e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [178][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [178][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.037577677609318 -- best acc so far 53.69
***[2023-04-25 00:49:31]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [179][  0/250]	Loss 1.8477e-06 (1.8477e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [179][100/250]	Loss 2.2650e-06 (2.0207e-06)	Acc@1   1.50 (  1.08)	Acc@5   6.50 (  5.10)
[TRAIN] E: [179][200/250]	Loss 2.0862e-06 (2.0162e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.03)
[TRAIN] E: [179][249/250]	Loss 2.7418e-06 (2.0230e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [179][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [179][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.034561102097765826 -- best acc so far 53.69
***[2023-04-25 00:50:53]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [180][  0/250]	Loss 1.9670e-06 (1.9670e-06)	Acc@1   2.50 (  2.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [180][100/250]	Loss 2.1458e-06 (2.0094e-06)	Acc@1   1.00 (  0.99)	Acc@5   6.00 (  5.10)
[TRAIN] E: [180][200/250]	Loss 2.1458e-06 (2.0186e-06)	Acc@1   0.50 (  0.99)	Acc@5   2.00 (  4.96)
[TRAIN] E: [180][249/250]	Loss 3.0398e-06 (2.0192e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [180][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [180][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.03160545686287225 -- best acc so far 53.69
***[2023-04-25 00:52:17]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [181][  0/250]	Loss 1.8477e-06 (1.8477e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [181][100/250]	Loss 2.0862e-06 (2.0195e-06)	Acc@1   1.50 (  0.99)	Acc@5   8.00 (  4.95)
[TRAIN] E: [181][200/250]	Loss 1.6093e-06 (2.0212e-06)	Acc@1   0.50 (  1.01)	Acc@5   4.00 (  5.01)
[TRAIN] E: [181][249/250]	Loss 2.6822e-06 (2.0206e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [181][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [181][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.028722406486073528 -- best acc so far 53.69
***[2023-04-25 00:53:39]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [182][  0/250]	Loss 3.0398e-06 (3.0398e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  6.50)
[TRAIN] E: [182][100/250]	Loss 1.7881e-06 (2.0195e-06)	Acc@1   2.00 (  1.06)	Acc@5   8.50 (  5.17)
[TRAIN] E: [182][200/250]	Loss 1.9670e-06 (2.0236e-06)	Acc@1   0.50 (  1.04)	Acc@5   4.50 (  5.08)
[TRAIN] E: [182][249/250]	Loss 1.6689e-06 (2.0213e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [182][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [182][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.02592332905006647 -- best acc so far 53.69
***[2023-04-25 00:55:02]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [183][  0/250]	Loss 1.7285e-06 (1.7285e-06)	Acc@1   0.00 (  0.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [183][100/250]	Loss 1.7285e-06 (2.0242e-06)	Acc@1   0.00 (  0.90)	Acc@5   2.50 (  4.93)
[TRAIN] E: [183][200/250]	Loss 1.6093e-06 (2.0248e-06)	Acc@1   2.50 (  0.97)	Acc@5   5.50 (  4.99)
[TRAIN] E: [183][249/250]	Loss 1.8477e-06 (2.0213e-06)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [183][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [183][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.02321927123471412 -- best acc so far 53.69
***[2023-04-25 00:56:27]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [184][  0/250]	Loss 2.0862e-06 (2.0862e-06)	Acc@1   1.50 (  1.50)	Acc@5   7.00 (  7.00)
[TRAIN] E: [184][100/250]	Loss 1.9670e-06 (2.0295e-06)	Acc@1   1.50 (  1.06)	Acc@5   4.50 (  5.00)
[TRAIN] E: [184][200/250]	Loss 2.6226e-06 (2.0274e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  4.97)
[TRAIN] E: [184][249/250]	Loss 2.0266e-06 (2.0256e-06)	Acc@1   2.00 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [184][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [184][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.02062090472084719 -- best acc so far 53.69
***[2023-04-25 00:57:51]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [185][  0/250]	Loss 2.0862e-06 (2.0862e-06)	Acc@1   1.50 (  1.50)	Acc@5   6.50 (  6.50)
[TRAIN] E: [185][100/250]	Loss 2.2054e-06 (2.0242e-06)	Acc@1   2.50 (  1.07)	Acc@5   7.50 (  4.90)
[TRAIN] E: [185][200/250]	Loss 1.9073e-06 (2.0221e-06)	Acc@1   1.00 (  1.02)	Acc@5   7.00 (  4.94)
[TRAIN] E: [185][249/250]	Loss 1.6689e-06 (2.0220e-06)	Acc@1   0.50 (  1.00)	Acc@5   1.50 (  5.00)
[EVAL] E: [185][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [185][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.018138484074015165 -- best acc so far 53.69
***[2023-04-25 00:59:15]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [186][  0/250]	Loss 1.4901e-06 (1.4901e-06)	Acc@1   1.00 (  1.00)	Acc@5   7.00 (  7.00)
[TRAIN] E: [186][100/250]	Loss 2.1458e-06 (2.0212e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.00)
[TRAIN] E: [186][200/250]	Loss 1.5497e-06 (2.0153e-06)	Acc@1   0.50 (  1.00)	Acc@5   3.00 (  4.99)
[TRAIN] E: [186][249/250]	Loss 2.0266e-06 (2.0242e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [186][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [186][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.015781806274400994 -- best acc so far 53.69
***[2023-04-25 01:00:39]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [187][  0/250]	Loss 1.6093e-06 (1.6093e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [187][100/250]	Loss 2.0266e-06 (2.0171e-06)	Acc@1   0.50 (  1.06)	Acc@5   4.00 (  5.07)
[TRAIN] E: [187][200/250]	Loss 2.5034e-06 (2.0168e-06)	Acc@1   0.00 (  1.01)	Acc@5   4.00 (  5.04)
[TRAIN] E: [187][249/250]	Loss 2.2650e-06 (2.0196e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [187][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [187][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.01356017205261605 -- best acc so far 53.69
***[2023-04-25 01:02:02]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [188][  0/250]	Loss 2.6226e-06 (2.6226e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [188][100/250]	Loss 2.6226e-06 (2.0171e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.03)
[TRAIN] E: [188][200/250]	Loss 2.0266e-06 (2.0209e-06)	Acc@1   0.00 (  0.98)	Acc@5   5.00 (  5.00)
[TRAIN] E: [188][249/250]	Loss 2.6226e-06 (2.0216e-06)	Acc@1   2.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [188][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [188][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.011482349183965603 -- best acc so far 53.69
***[2023-04-25 01:03:27]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [189][  0/250]	Loss 2.0862e-06 (2.0862e-06)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [189][100/250]	Loss 2.1458e-06 (2.0130e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  4.95)
[TRAIN] E: [189][200/250]	Loss 1.7285e-06 (2.0197e-06)	Acc@1   1.50 (  0.98)	Acc@5   6.00 (  4.96)
[TRAIN] E: [189][249/250]	Loss 1.7285e-06 (2.0206e-06)	Acc@1   2.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [189][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [189][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.009556537886045241 -- best acc so far 53.69
***[2023-04-25 01:04:49]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [190][  0/250]	Loss 2.2054e-06 (2.2054e-06)	Acc@1   2.00 (  2.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [190][100/250]	Loss 2.0266e-06 (2.0183e-06)	Acc@1   2.50 (  0.98)	Acc@5   6.00 (  4.92)
[TRAIN] E: [190][200/250]	Loss 1.7285e-06 (2.0242e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.08)
[TRAIN] E: [190][249/250]	Loss 2.0266e-06 (2.0218e-06)	Acc@1   0.50 (  1.00)	Acc@5   2.50 (  5.00)
[EVAL] E: [190][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [190][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.007790338456228368 -- best acc so far 53.69
***[2023-04-25 01:06:14]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [191][  0/250]	Loss 2.1458e-06 (2.1458e-06)	Acc@1   2.00 (  2.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [191][100/250]	Loss 1.9073e-06 (2.0277e-06)	Acc@1   0.50 (  1.04)	Acc@5   5.50 (  5.17)
[TRAIN] E: [191][200/250]	Loss 2.0266e-06 (2.0242e-06)	Acc@1   1.50 (  0.99)	Acc@5   5.50 (  5.05)
[TRAIN] E: [191][249/250]	Loss 1.6689e-06 (2.0218e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [191][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [191][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.006190721276764699 -- best acc so far 53.69
***[2023-04-25 01:07:34]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [192][  0/250]	Loss 1.9073e-06 (1.9073e-06)	Acc@1   1.50 (  1.50)	Acc@5   7.00 (  7.00)
[TRAIN] E: [192][100/250]	Loss 1.7285e-06 (2.0283e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.03)
[TRAIN] E: [192][200/250]	Loss 2.1458e-06 (2.0236e-06)	Acc@1   0.00 (  1.00)	Acc@5   6.00 (  5.03)
[TRAIN] E: [192][249/250]	Loss 1.9670e-06 (2.0223e-06)	Acc@1   1.50 (  1.00)	Acc@5   8.00 (  5.00)
[EVAL] E: [192][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [192][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.004763999305866018 -- best acc so far 53.69
***[2023-04-25 01:08:36]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [193][  0/250]	Loss 2.2054e-06 (2.2054e-06)	Acc@1   0.00 (  0.00)	Acc@5   7.50 (  7.50)
[TRAIN] E: [193][100/250]	Loss 2.5034e-06 (2.0283e-06)	Acc@1   1.50 (  1.00)	Acc@5   3.00 (  5.07)
[TRAIN] E: [193][200/250]	Loss 1.7285e-06 (2.0183e-06)	Acc@1   0.00 (  1.00)	Acc@5   4.00 (  5.04)
[TRAIN] E: [193][249/250]	Loss 2.0266e-06 (2.0244e-06)	Acc@1   0.00 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [193][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [193][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.003515803163344161 -- best acc so far 53.69
***[2023-04-25 01:09:38]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [194][  0/250]	Loss 1.8477e-06 (1.8477e-06)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [194][100/250]	Loss 2.0862e-06 (2.0207e-06)	Acc@1   1.00 (  0.95)	Acc@5   6.00 (  4.95)
[TRAIN] E: [194][200/250]	Loss 2.0266e-06 (2.0177e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.03)
[TRAIN] E: [194][249/250]	Loss 1.6689e-06 (2.0196e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [194][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [194][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.00245105890912713 -- best acc so far 53.69
***[2023-04-25 01:10:39]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [195][  0/250]	Loss 1.8477e-06 (1.8477e-06)	Acc@1   2.00 (  2.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [195][100/250]	Loss 2.0266e-06 (2.0130e-06)	Acc@1   1.50 (  0.94)	Acc@5   4.00 (  4.84)
[TRAIN] E: [195][200/250]	Loss 1.7285e-06 (2.0180e-06)	Acc@1   2.00 (  1.00)	Acc@5   5.50 (  4.99)
[TRAIN] E: [195][249/250]	Loss 1.7881e-06 (2.0237e-06)	Acc@1   0.50 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [195][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [195][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.001573968602350906 -- best acc so far 53.69
***[2023-04-25 01:11:41]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [196][  0/250]	Loss 2.1458e-06 (2.1458e-06)	Acc@1   1.50 (  1.50)	Acc@5   7.50 (  7.50)
[TRAIN] E: [196][100/250]	Loss 1.7285e-06 (2.0112e-06)	Acc@1   2.00 (  1.00)	Acc@5   4.50 (  5.06)
[TRAIN] E: [196][200/250]	Loss 1.7881e-06 (2.0203e-06)	Acc@1   1.00 (  1.00)	Acc@5   7.00 (  5.03)
[TRAIN] E: [196][249/250]	Loss 1.9670e-06 (2.0173e-06)	Acc@1   1.50 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [196][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [196][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.000887993717751906 -- best acc so far 53.69
***[2023-04-25 01:12:42]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [197][  0/250]	Loss 1.9670e-06 (1.9670e-06)	Acc@1   2.00 (  2.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [197][100/250]	Loss 1.9670e-06 (2.0207e-06)	Acc@1   1.00 (  1.06)	Acc@5   5.50 (  5.09)
[TRAIN] E: [197][200/250]	Loss 1.8477e-06 (2.0289e-06)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.05)
[TRAIN] E: [197][249/250]	Loss 1.6093e-06 (2.0206e-06)	Acc@1   2.50 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [197][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [197][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0003958414848075243 -- best acc so far 53.69
***[2023-04-25 01:13:44]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [198][  0/250]	Loss 1.9073e-06 (1.9073e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [198][100/250]	Loss 1.9073e-06 (2.0024e-06)	Acc@1   1.50 (  0.99)	Acc@5   6.00 (  5.17)
[TRAIN] E: [198][200/250]	Loss 1.3709e-06 (2.0102e-06)	Acc@1   0.50 (  0.99)	Acc@5   5.50 (  5.06)
[TRAIN] E: [198][249/250]	Loss 2.0862e-06 (2.0330e-06)	Acc@1   3.00 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [198][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [198][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=9.945420353821844e-05 -- best acc so far 53.69
***[2023-04-25 01:14:45]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [199][  0/250]	Loss 1.9073e-06 (1.9073e-06)	Acc@1   0.00 (  0.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [199][100/250]	Loss 2.1458e-06 (2.1233e-06)	Acc@1   1.00 (  1.01)	Acc@5   8.00 (  4.99)
[TRAIN] E: [199][200/250]	Loss 3.0398e-06 (2.2555e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.01)
[TRAIN] E: [199][249/250]	Loss 3.0398e-06 (2.4092e-06)	Acc@1   0.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [199][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [199][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=1.57913669363019e-09 -- best acc so far 53.69
***[2023-04-25 01:15:46]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
