Main Function with logger : Logger(dir=meta_results, use-tf=False, writer=None)
Arguments : -------------------------------
batch_size       : 200
checkpoint_dir   : ./checkpoint
class_num        : 100
cutout_length    : 16
data_path        : /home/prathamesh/code/data/cifar/
dataset          : cifar100
epochs           : 200
eval_batch_size  : 200
eval_frequency   : 1
global_rand_seed : -1
input_size       : 32
inst_based       : True
log_dir          : ./log
lr               : 0.1
mcd_weight       : 0.01
meta_interval    : 1
meta_lr          : 0.01
meta_weight_decay : 0.0
model_name       : ResNet10_s
momentum         : 0.9
print_freq       : 100
print_freq_eval  : 100
rand_seed        : 22905
save_dir         : ./meta_results/
unsup_adapt      : False
wd               : 0.0005
workers          : 8
Python  Version  : 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0]
Pillow  Version  : 9.2.0
PyTorch Version  : 1.13.1
cuDNN   Version  : 8500
CUDA available   : True
CUDA GPU numbers : 1
CUDA_VISIBLE_DEVICES : 0
model information : EfficientNetV2_s (CIFAR)
--------------------------------------------------
[Student]Params=0.08 MB, FLOPs=4.16 M ... = 0.00 G
--------------------------------------------------
train_data : Dataset CIFAR100
    Number of datapoints: 50000
    Root location: /home/prathamesh/code/data/cifar/
    Split: Train
    StandardTransform
Transform: Compose(
               RandomCrop(size=(32, 32), padding=4)
               RandomHorizontalFlip(p=0.5)
               AutoAugment CIFAR10 Policy
               ToTensor()
               CUTOUT(length=16)
               Normalize(mean=[0.5070588235294118, 0.48666666666666664, 0.4407843137254902], std=[0.26745098039215687, 0.2564705882352941, 0.27607843137254906])
           )
valid_data : Dataset CIFAR100
    Number of datapoints: 10000
    Root location: /home/prathamesh/code/data/cifar/
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.5070588235294118, 0.48666666666666664, 0.4407843137254902], std=[0.26745098039215687, 0.2564705882352941, 0.27607843137254906])
           )
[TRAIN] E: [0][  0/250]	Loss 5.7645e-02 (5.7645e-02)	Acc@1  46.50 ( 46.50)	Acc@5  81.00 ( 81.00)
[TRAIN] E: [0][100/250]	Loss 5.3756e-08 (5.7082e-04)	Acc@1  39.50 ( 42.49)	Acc@5  70.50 ( 72.09)
[TRAIN] E: [0][200/250]	Loss 1.6309e-07 (2.8686e-04)	Acc@1  33.00 ( 42.43)	Acc@5  70.00 ( 72.15)
[TRAIN] E: [0][249/250]	Loss -1.0300e-07 (2.3065e-04)	Acc@1  45.50 ( 42.52)	Acc@5  68.50 ( 72.20)
[EVAL] E: [0][ 0/50]	Loss 1.6489e+00 (1.6489e+00)	Acc@1  61.00 ( 61.00)	Acc@5  80.00 ( 80.00)
[EVAL] E: [0][49/50]	Loss 1.6774e+00 (1.7064e+00)	Acc@1  54.50 ( 53.37)	Acc@5  83.00 ( 82.41)
		 LR=0.09990212389432412 -- best acc so far 53.37
***[2023-04-24 14:02:19]*** [Post-train] [Student] EVALUATION loss = 1.706374, accuracy@1 = 53.37, accuracy@5 = 82.41, error@1 = 46.63, error@5 = 17.59
[TRAIN] E: [1][  0/250]	Loss 1.2551e-07 (1.2551e-07)	Acc@1  41.00 ( 41.00)	Acc@5  70.50 ( 70.50)
[TRAIN] E: [1][100/250]	Loss 9.9614e-08 (9.5817e-08)	Acc@1  41.50 ( 42.31)	Acc@5  75.00 ( 72.35)
[TRAIN] E: [1][200/250]	Loss 1.3418e-07 (1.0001e-07)	Acc@1  46.50 ( 42.16)	Acc@5  75.00 ( 72.35)
[TRAIN] E: [1][249/250]	Loss 1.2964e-07 (9.7985e-08)	Acc@1  44.00 ( 42.28)	Acc@5  74.00 ( 72.32)
[EVAL] E: [1][ 0/50]	Loss 1.7590e+00 (1.7590e+00)	Acc@1  60.00 ( 60.00)	Acc@5  80.00 ( 80.00)
[EVAL] E: [1][49/50]	Loss 1.8134e+00 (1.8319e+00)	Acc@1  52.50 ( 53.29)	Acc@5  83.50 ( 82.49)
		 LR=0.09960730848288585 -- best acc so far 53.37
***[2023-04-24 14:04:01]*** [Post-train] [Student] EVALUATION loss = 1.831903, accuracy@1 = 53.29, accuracy@5 = 82.49, error@1 = 46.71, error@5 = 17.51
[TRAIN] E: [2][  0/250]	Loss 1.6727e-07 (1.6727e-07)	Acc@1  43.50 ( 43.50)	Acc@5  72.00 ( 72.00)
[TRAIN] E: [2][100/250]	Loss 2.8491e-07 (8.8786e-08)	Acc@1  46.50 ( 42.35)	Acc@5  72.00 ( 72.36)
[TRAIN] E: [2][200/250]	Loss 3.2455e-07 (1.1218e-07)	Acc@1  41.00 ( 42.00)	Acc@5  74.50 ( 72.29)
[TRAIN] E: [2][249/250]	Loss 2.3544e-08 (1.0914e-07)	Acc@1  46.00 ( 42.04)	Acc@5  75.00 ( 72.37)
[EVAL] E: [2][ 0/50]	Loss 1.9645e+00 (1.9645e+00)	Acc@1  60.50 ( 60.50)	Acc@5  80.50 ( 80.50)
[EVAL] E: [2][49/50]	Loss 2.0327e+00 (2.0429e+00)	Acc@1  54.00 ( 53.46)	Acc@5  83.50 ( 82.60)
		 LR=0.0991167156882891 -- best acc so far 53.46
***[2023-04-24 14:05:46]*** [Post-train] [Student] EVALUATION loss = 2.042881, accuracy@1 = 53.46, accuracy@5 = 82.60, error@1 = 46.54, error@5 = 17.40
[TRAIN] E: [3][  0/250]	Loss 1.0602e-07 (1.0602e-07)	Acc@1  39.00 ( 39.00)	Acc@5  67.00 ( 67.00)
[TRAIN] E: [3][100/250]	Loss 2.2635e-07 (1.1507e-07)	Acc@1  40.50 ( 41.64)	Acc@5  71.00 ( 71.67)
[TRAIN] E: [3][200/250]	Loss 2.7537e-07 (1.2811e-07)	Acc@1  46.00 ( 41.97)	Acc@5  72.00 ( 72.05)
[TRAIN] E: [3][249/250]	Loss 1.4991e-07 (1.3091e-07)	Acc@1  41.50 ( 41.91)	Acc@5  71.00 ( 71.99)
[EVAL] E: [3][ 0/50]	Loss 2.2396e+00 (2.2396e+00)	Acc@1  59.50 ( 59.50)	Acc@5  80.00 ( 80.00)
[EVAL] E: [3][49/50]	Loss 2.3161e+00 (2.3223e+00)	Acc@1  55.00 ( 53.33)	Acc@5  82.50 ( 82.47)
		 LR=0.0984322816561636 -- best acc so far 53.46
***[2023-04-24 14:07:32]*** [Post-train] [Student] EVALUATION loss = 2.322339, accuracy@1 = 53.33, accuracy@5 = 82.47, error@1 = 46.67, error@5 = 17.53
[TRAIN] E: [4][  0/250]	Loss -1.1325e-08 (-1.1325e-08)	Acc@1  45.50 ( 45.50)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [4][100/250]	Loss 2.1577e-07 (1.1647e-07)	Acc@1  47.00 ( 42.54)	Acc@5  75.50 ( 72.33)
[TRAIN] E: [4][200/250]	Loss 1.2562e-07 (1.2912e-07)	Acc@1  40.00 ( 42.22)	Acc@5  70.50 ( 72.18)
[TRAIN] E: [4][249/250]	Loss 3.0696e-08 (1.2621e-07)	Acc@1  38.50 ( 42.15)	Acc@5  65.00 ( 72.11)
[EVAL] E: [4][ 0/50]	Loss 2.5602e+00 (2.5602e+00)	Acc@1  59.50 ( 59.50)	Acc@5  79.50 ( 79.50)
[EVAL] E: [4][49/50]	Loss 2.6316e+00 (2.6379e+00)	Acc@1  54.50 ( 53.39)	Acc@5  82.50 ( 82.41)
		 LR=0.09755670753494601 -- best acc so far 53.46
***[2023-04-24 14:09:15]*** [Post-train] [Student] EVALUATION loss = 2.637925, accuracy@1 = 53.39, accuracy@5 = 82.41, error@1 = 46.61, error@5 = 17.59
[TRAIN] E: [5][  0/250]	Loss 2.1130e-07 (2.1130e-07)	Acc@1  40.00 ( 40.00)	Acc@5  70.00 ( 70.00)
[TRAIN] E: [5][100/250]	Loss -1.6987e-08 (1.4393e-07)	Acc@1  41.50 ( 42.27)	Acc@5  73.00 ( 72.33)
[TRAIN] E: [5][200/250]	Loss 1.3486e-07 (1.4911e-07)	Acc@1  42.00 ( 41.99)	Acc@5  66.00 ( 72.26)
[TRAIN] E: [5][249/250]	Loss -1.1206e-07 (1.4381e-07)	Acc@1  42.00 ( 42.01)	Acc@5  73.50 ( 72.30)
[EVAL] E: [5][ 0/50]	Loss 2.8800e+00 (2.8800e+00)	Acc@1  59.00 ( 59.00)	Acc@5  79.50 ( 79.50)
[EVAL] E: [5][49/50]	Loss 2.9444e+00 (2.9499e+00)	Acc@1  54.00 ( 53.16)	Acc@5  82.00 ( 82.44)
		 LR=0.09649344881568099 -- best acc so far 53.46
***[2023-04-24 14:11:01]*** [Post-train] [Student] EVALUATION loss = 2.949894, accuracy@1 = 53.16, accuracy@5 = 82.44, error@1 = 46.84, error@5 = 17.56
[TRAIN] E: [6][  0/250]	Loss 4.4256e-08 (4.4256e-08)	Acc@1  38.00 ( 38.00)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [6][100/250]	Loss -2.7016e-07 (1.4077e-07)	Acc@1  42.50 ( 42.49)	Acc@5  70.50 ( 72.07)
[TRAIN] E: [6][200/250]	Loss 3.0428e-07 (1.4369e-07)	Acc@1  40.50 ( 42.29)	Acc@5  73.50 ( 71.77)
[TRAIN] E: [6][249/250]	Loss 2.5034e-07 (1.4187e-07)	Acc@1  39.00 ( 42.27)	Acc@5  73.00 ( 71.89)
[EVAL] E: [6][ 0/50]	Loss 3.1674e+00 (3.1674e+00)	Acc@1  59.50 ( 59.50)	Acc@5  79.50 ( 79.50)
[EVAL] E: [6][49/50]	Loss 3.2222e+00 (3.2276e+00)	Acc@1  54.50 ( 53.22)	Acc@5  82.50 ( 82.47)
		 LR=0.09524670169477678 -- best acc so far 53.46
***[2023-04-24 14:12:48]*** [Post-train] [Student] EVALUATION loss = 3.227615, accuracy@1 = 53.22, accuracy@5 = 82.47, error@1 = 46.78, error@5 = 17.53
[TRAIN] E: [7][  0/250]	Loss 1.4454e-07 (1.4454e-07)	Acc@1  38.50 ( 38.50)	Acc@5  72.00 ( 72.00)
[TRAIN] E: [7][100/250]	Loss 6.2287e-08 (1.4019e-07)	Acc@1  43.50 ( 41.72)	Acc@5  68.50 ( 71.92)
[TRAIN] E: [7][200/250]	Loss 3.2216e-07 (1.3655e-07)	Acc@1  44.00 ( 41.97)	Acc@5  70.50 ( 71.96)
[TRAIN] E: [7][249/250]	Loss 2.1577e-07 (1.3877e-07)	Acc@1  44.50 ( 42.11)	Acc@5  72.00 ( 72.10)
[EVAL] E: [7][ 0/50]	Loss 3.4374e+00 (3.4374e+00)	Acc@1  59.00 ( 59.00)	Acc@5  79.00 ( 79.00)
[EVAL] E: [7][49/50]	Loss 3.4811e+00 (3.4854e+00)	Acc@1  54.00 ( 53.28)	Acc@5  81.50 ( 82.27)
		 LR=0.093821386513535 -- best acc so far 53.46
***[2023-04-24 14:14:30]*** [Post-train] [Student] EVALUATION loss = 3.485397, accuracy@1 = 53.28, accuracy@5 = 82.27, error@1 = 46.72, error@5 = 17.73
[TRAIN] E: [8][  0/250]	Loss 4.6343e-07 (4.6343e-07)	Acc@1  37.00 ( 37.00)	Acc@5  69.00 ( 69.00)
[TRAIN] E: [8][100/250]	Loss 9.0003e-08 (1.4446e-07)	Acc@1  44.50 ( 42.08)	Acc@5  76.00 ( 72.05)
[TRAIN] E: [8][200/250]	Loss 1.0371e-07 (1.4849e-07)	Acc@1  45.00 ( 42.26)	Acc@5  71.50 ( 72.06)
[TRAIN] E: [8][249/250]	Loss -2.4140e-07 (1.4024e-07)	Acc@1  45.00 ( 42.24)	Acc@5  70.50 ( 72.03)
[EVAL] E: [8][ 0/50]	Loss 3.6552e+00 (3.6552e+00)	Acc@1  59.00 ( 59.00)	Acc@5  79.00 ( 79.00)
[EVAL] E: [8][49/50]	Loss 3.6898e+00 (3.6946e+00)	Acc@1  55.00 ( 53.18)	Acc@5  82.50 ( 82.29)
		 LR=0.09222312833981147 -- best acc so far 53.46
***[2023-04-24 14:16:13]*** [Post-train] [Student] EVALUATION loss = 3.694556, accuracy@1 = 53.18, accuracy@5 = 82.29, error@1 = 46.82, error@5 = 17.71
[TRAIN] E: [9][  0/250]	Loss 1.7434e-07 (1.7434e-07)	Acc@1  39.50 ( 39.50)	Acc@5  73.50 ( 73.50)
[TRAIN] E: [9][100/250]	Loss -2.1905e-07 (1.4581e-07)	Acc@1  45.50 ( 42.40)	Acc@5  74.50 ( 72.13)
[TRAIN] E: [9][200/250]	Loss -2.0862e-08 (1.5133e-07)	Acc@1  41.00 ( 42.10)	Acc@5  69.50 ( 71.93)
[TRAIN] E: [9][249/250]	Loss -1.7881e-07 (1.4984e-07)	Acc@1  47.50 ( 42.07)	Acc@5  75.00 ( 71.95)
[EVAL] E: [9][ 0/50]	Loss 3.8421e+00 (3.8421e+00)	Acc@1  59.00 ( 59.00)	Acc@5  78.50 ( 78.50)
[EVAL] E: [9][49/50]	Loss 3.8691e+00 (3.8731e+00)	Acc@1  54.50 ( 53.09)	Acc@5  82.00 ( 82.23)
		 LR=0.09045823476844315 -- best acc so far 53.46
***[2023-04-24 14:18:08]*** [Post-train] [Student] EVALUATION loss = 3.873056, accuracy@1 = 53.09, accuracy@5 = 82.23, error@1 = 46.91, error@5 = 17.77
[TRAIN] E: [10][  0/250]	Loss 3.7223e-07 (3.7223e-07)	Acc@1  40.00 ( 40.00)	Acc@5  73.00 ( 73.00)
[TRAIN] E: [10][100/250]	Loss -5.3942e-08 (1.2480e-07)	Acc@1  51.50 ( 41.97)	Acc@5  76.50 ( 71.71)
[TRAIN] E: [10][200/250]	Loss 1.6510e-07 (1.0372e-07)	Acc@1  43.00 ( 42.05)	Acc@5  69.50 ( 71.89)
[TRAIN] E: [10][249/250]	Loss 1.6093e-07 (1.0570e-07)	Acc@1  39.50 ( 42.05)	Acc@5  69.00 ( 71.97)
[EVAL] E: [10][ 0/50]	Loss 3.9900e+00 (3.9900e+00)	Acc@1  59.00 ( 59.00)	Acc@5  79.50 ( 79.50)
[EVAL] E: [10][49/50]	Loss 4.0125e+00 (4.0153e+00)	Acc@1  55.00 ( 52.99)	Acc@5  82.00 ( 82.27)
		 LR=0.08853367102805307 -- best acc so far 53.46
***[2023-04-24 14:20:10]*** [Post-train] [Student] EVALUATION loss = 4.015319, accuracy@1 = 52.99, accuracy@5 = 82.27, error@1 = 47.01, error@5 = 17.73
[TRAIN] E: [11][  0/250]	Loss -5.9605e-10 (-5.9605e-10)	Acc@1  43.50 ( 43.50)	Acc@5  71.00 ( 71.00)
[TRAIN] E: [11][100/250]	Loss -6.6161e-08 (1.0011e-07)	Acc@1  49.50 ( 41.76)	Acc@5  76.50 ( 71.59)
[TRAIN] E: [11][200/250]	Loss 3.4541e-07 (1.1540e-07)	Acc@1  37.50 ( 41.59)	Acc@5  74.00 ( 71.41)
[TRAIN] E: [11][249/250]	Loss -5.3644e-08 (1.1562e-07)	Acc@1  38.00 ( 41.75)	Acc@5  72.00 ( 71.62)
[EVAL] E: [11][ 0/50]	Loss 4.1128e+00 (4.1128e+00)	Acc@1  58.50 ( 58.50)	Acc@5  79.00 ( 79.00)
[EVAL] E: [11][49/50]	Loss 4.1309e+00 (4.1328e+00)	Acc@1  52.50 ( 53.01)	Acc@5  82.00 ( 82.16)
		 LR=0.086457032492475 -- best acc so far 53.46
***[2023-04-24 14:22:04]*** [Post-train] [Student] EVALUATION loss = 4.132770, accuracy@1 = 53.01, accuracy@5 = 82.16, error@1 = 46.99, error@5 = 17.84
[TRAIN] E: [12][  0/250]	Loss 1.3053e-07 (1.3053e-07)	Acc@1  43.00 ( 43.00)	Acc@5  72.50 ( 72.50)
[TRAIN] E: [12][100/250]	Loss 1.9073e-07 (1.2267e-07)	Acc@1  37.00 ( 41.73)	Acc@5  70.00 ( 71.56)
[TRAIN] E: [12][200/250]	Loss 3.3647e-07 (1.1475e-07)	Acc@1  47.00 ( 41.73)	Acc@5  73.50 ( 71.56)
[TRAIN] E: [12][249/250]	Loss -8.9407e-10 (1.0795e-07)	Acc@1  42.00 ( 41.70)	Acc@5  70.50 ( 71.53)
[EVAL] E: [12][ 0/50]	Loss 4.2131e+00 (4.2131e+00)	Acc@1  59.00 ( 59.00)	Acc@5  79.50 ( 79.50)
[EVAL] E: [12][49/50]	Loss 4.2274e+00 (4.2289e+00)	Acc@1  53.00 ( 52.86)	Acc@5  83.00 ( 82.05)
		 LR=0.08423651470528296 -- best acc so far 53.46
***[2023-04-24 14:23:54]*** [Post-train] [Student] EVALUATION loss = 4.228852, accuracy@1 = 52.86, accuracy@5 = 82.05, error@1 = 47.14, error@5 = 17.95
[TRAIN] E: [13][  0/250]	Loss 3.4124e-07 (3.4124e-07)	Acc@1  40.00 ( 40.00)	Acc@5  74.00 ( 74.00)
[TRAIN] E: [13][100/250]	Loss -7.4506e-09 (7.8436e-08)	Acc@1  40.50 ( 40.61)	Acc@5  69.00 ( 70.97)
[TRAIN] E: [13][200/250]	Loss 8.3447e-08 (6.9632e-08)	Acc@1  47.50 ( 41.31)	Acc@5  74.00 ( 71.44)
[TRAIN] E: [13][249/250]	Loss -1.5140e-07 (7.1027e-08)	Acc@1  42.00 ( 41.30)	Acc@5  72.00 ( 71.27)
[EVAL] E: [13][ 0/50]	Loss 4.2954e+00 (4.2954e+00)	Acc@1  58.50 ( 58.50)	Acc@5  78.50 ( 78.50)
[EVAL] E: [13][49/50]	Loss 4.3066e+00 (4.3078e+00)	Acc@1  54.00 ( 52.37)	Acc@5  83.50 ( 81.72)
		 LR=0.08188088103572494 -- best acc so far 53.46
***[2023-04-24 14:25:45]*** [Post-train] [Student] EVALUATION loss = 4.307794, accuracy@1 = 52.37, accuracy@5 = 81.72, error@1 = 47.63, error@5 = 18.28
[TRAIN] E: [14][  0/250]	Loss 8.9705e-08 (8.9705e-08)	Acc@1  41.00 ( 41.00)	Acc@5  71.00 ( 71.00)
[TRAIN] E: [14][100/250]	Loss -4.7684e-08 (8.7244e-08)	Acc@1  34.50 ( 40.61)	Acc@5  67.00 ( 70.63)
[TRAIN] E: [14][200/250]	Loss -1.0848e-07 (7.1300e-08)	Acc@1  42.50 ( 40.86)	Acc@5  71.00 ( 70.74)
[TRAIN] E: [14][249/250]	Loss 1.2517e-08 (7.8948e-08)	Acc@1  42.50 ( 40.83)	Acc@5  67.50 ( 70.65)
[EVAL] E: [14][ 0/50]	Loss 4.3610e+00 (4.3610e+00)	Acc@1  59.50 ( 59.50)	Acc@5  78.50 ( 78.50)
[EVAL] E: [14][49/50]	Loss 4.3702e+00 (4.3709e+00)	Acc@1  53.50 ( 52.26)	Acc@5  83.00 ( 81.69)
		 LR=0.079399428093708 -- best acc so far 53.46
***[2023-04-24 14:27:36]*** [Post-train] [Student] EVALUATION loss = 4.370911, accuracy@1 = 52.26, accuracy@5 = 81.69, error@1 = 47.74, error@5 = 18.31
[TRAIN] E: [15][  0/250]	Loss -1.4663e-07 (-1.4663e-07)	Acc@1  38.50 ( 38.50)	Acc@5  69.50 ( 69.50)
[TRAIN] E: [15][100/250]	Loss -4.3511e-08 (3.9265e-08)	Acc@1  39.50 ( 40.10)	Acc@5  74.00 ( 70.32)
[TRAIN] E: [15][200/250]	Loss 1.9550e-07 (3.8034e-08)	Acc@1  46.50 ( 40.41)	Acc@5  72.00 ( 70.30)
[TRAIN] E: [15][249/250]	Loss 1.3411e-07 (3.7354e-08)	Acc@1  42.50 ( 40.21)	Acc@5  68.00 ( 69.98)
[EVAL] E: [15][ 0/50]	Loss 4.4159e+00 (4.4159e+00)	Acc@1  59.00 ( 59.00)	Acc@5  78.00 ( 78.00)
[EVAL] E: [15][49/50]	Loss 4.4231e+00 (4.4235e+00)	Acc@1  51.00 ( 51.56)	Acc@5  81.50 ( 81.23)
		 LR=0.07680194904032629 -- best acc so far 53.46
***[2023-04-24 14:29:34]*** [Post-train] [Student] EVALUATION loss = 4.423486, accuracy@1 = 51.56, accuracy@5 = 81.23, error@1 = 48.44, error@5 = 18.77
[TRAIN] E: [16][  0/250]	Loss 1.4096e-07 (1.4096e-07)	Acc@1  36.00 ( 36.00)	Acc@5  69.50 ( 69.50)
[TRAIN] E: [16][100/250]	Loss -6.4075e-08 (4.2086e-08)	Acc@1  35.50 ( 39.13)	Acc@5  74.00 ( 69.66)
[TRAIN] E: [16][200/250]	Loss 2.8312e-08 (3.1341e-08)	Acc@1  41.50 ( 39.17)	Acc@5  73.50 ( 69.51)
[TRAIN] E: [16][249/250]	Loss -4.9770e-08 (2.2467e-08)	Acc@1  34.00 ( 39.08)	Acc@5  68.00 ( 69.36)
[EVAL] E: [16][ 0/50]	Loss 4.4598e+00 (4.4598e+00)	Acc@1  58.00 ( 58.00)	Acc@5  79.00 ( 79.00)
[EVAL] E: [16][49/50]	Loss 4.4654e+00 (4.4655e+00)	Acc@1  51.50 ( 50.72)	Acc@5  79.50 ( 80.73)
		 LR=0.07409869493872821 -- best acc so far 53.46
***[2023-04-24 14:31:26]*** [Post-train] [Student] EVALUATION loss = 4.465531, accuracy@1 = 50.72, accuracy@5 = 80.73, error@1 = 49.28, error@5 = 19.27
[TRAIN] E: [17][  0/250]	Loss 2.2143e-07 (2.2143e-07)	Acc@1  45.50 ( 45.50)	Acc@5  70.50 ( 70.50)
[TRAIN] E: [17][100/250]	Loss -1.6689e-08 (-3.0994e-08)	Acc@1  38.50 ( 39.04)	Acc@5  68.00 ( 68.50)
[TRAIN] E: [17][200/250]	Loss -5.6028e-08 (-3.4560e-08)	Acc@1  37.00 ( 38.24)	Acc@5  70.50 ( 67.67)
[TRAIN] E: [17][249/250]	Loss -3.3379e-07 (-3.5293e-08)	Acc@1  38.50 ( 38.08)	Acc@5  70.00 ( 67.57)
[EVAL] E: [17][ 0/50]	Loss 4.4948e+00 (4.4948e+00)	Acc@1  57.50 ( 57.50)	Acc@5  79.00 ( 79.00)
[EVAL] E: [17][49/50]	Loss 4.4992e+00 (4.4990e+00)	Acc@1  48.50 ( 49.69)	Acc@5  79.50 ( 79.94)
		 LR=0.07130033429785342 -- best acc so far 53.46
***[2023-04-24 14:33:20]*** [Post-train] [Student] EVALUATION loss = 4.499048, accuracy@1 = 49.69, accuracy@5 = 79.94, error@1 = 50.31, error@5 = 20.06
[TRAIN] E: [18][  0/250]	Loss -9.5367e-08 (-9.5367e-08)	Acc@1  36.50 ( 36.50)	Acc@5  69.50 ( 69.50)
[TRAIN] E: [18][100/250]	Loss 1.8865e-07 (-5.0487e-08)	Acc@1  37.50 ( 35.84)	Acc@5  71.00 ( 65.91)
[TRAIN] E: [18][200/250]	Loss -7.0035e-08 (-4.6511e-08)	Acc@1  34.50 ( 35.56)	Acc@5  61.00 ( 65.62)
[TRAIN] E: [18][249/250]	Loss 4.9174e-08 (-5.2515e-08)	Acc@1  38.00 ( 35.46)	Acc@5  69.50 ( 65.56)
[EVAL] E: [18][ 0/50]	Loss 4.5238e+00 (4.5238e+00)	Acc@1  54.50 ( 54.50)	Acc@5  79.00 ( 79.00)
[EVAL] E: [18][49/50]	Loss 4.5271e+00 (4.5268e+00)	Acc@1  46.50 ( 47.43)	Acc@5  79.50 ( 78.13)
		 LR=0.06841791096870209 -- best acc so far 53.46
***[2023-04-24 14:35:39]*** [Post-train] [Student] EVALUATION loss = 4.526783, accuracy@1 = 47.43, accuracy@5 = 78.13, error@1 = 52.57, error@5 = 21.87
[TRAIN] E: [19][  0/250]	Loss 1.7017e-07 (1.7017e-07)	Acc@1  40.00 ( 40.00)	Acc@5  70.50 ( 70.50)
[TRAIN] E: [19][100/250]	Loss -5.3942e-08 (-5.1511e-08)	Acc@1  37.00 ( 33.38)	Acc@5  67.00 ( 63.18)
[TRAIN] E: [19][200/250]	Loss -3.6955e-08 (-6.0242e-08)	Acc@1  29.50 ( 32.74)	Acc@5  60.00 ( 62.21)
[TRAIN] E: [19][249/250]	Loss 8.7321e-08 (-6.0936e-08)	Acc@1  27.00 ( 32.27)	Acc@5  55.50 ( 61.63)
[EVAL] E: [19][ 0/50]	Loss 4.5461e+00 (4.5461e+00)	Acc@1  50.00 ( 50.00)	Acc@5  77.00 ( 77.00)
[EVAL] E: [19][49/50]	Loss 4.5485e+00 (4.5481e+00)	Acc@1  41.00 ( 43.88)	Acc@5  76.50 ( 74.64)
		 LR=0.06546280055930045 -- best acc so far 53.46
***[2023-04-24 14:38:32]*** [Post-train] [Student] EVALUATION loss = 4.548078, accuracy@1 = 43.88, accuracy@5 = 74.64, error@1 = 56.12, error@5 = 25.36
[TRAIN] E: [20][  0/250]	Loss -1.0878e-07 (-1.0878e-07)	Acc@1  29.00 ( 29.00)	Acc@5  61.00 ( 61.00)
[TRAIN] E: [20][100/250]	Loss 1.0669e-07 (-9.1794e-08)	Acc@1  32.50 ( 29.61)	Acc@5  56.00 ( 57.64)
[TRAIN] E: [20][200/250]	Loss -7.2420e-08 (-8.5629e-08)	Acc@1  28.00 ( 28.38)	Acc@5  53.50 ( 56.53)
[TRAIN] E: [20][249/250]	Loss -4.2915e-07 (-9.3061e-08)	Acc@1  27.50 ( 27.78)	Acc@5  51.50 ( 55.65)
[EVAL] E: [20][ 0/50]	Loss 4.5640e+00 (4.5640e+00)	Acc@1  40.00 ( 40.00)	Acc@5  74.50 ( 74.50)
[EVAL] E: [20][49/50]	Loss 4.5656e+00 (4.5652e+00)	Acc@1  35.00 ( 37.61)	Acc@5  70.00 ( 69.07)
		 LR=0.06244666554037285 -- best acc so far 53.46
***[2023-04-24 14:41:23]*** [Post-train] [Student] EVALUATION loss = 4.565181, accuracy@1 = 37.61, accuracy@5 = 69.07, error@1 = 62.39, error@5 = 30.93
[TRAIN] E: [21][  0/250]	Loss -1.8090e-07 (-1.8090e-07)	Acc@1  24.50 ( 24.50)	Acc@5  55.00 ( 55.00)
[TRAIN] E: [21][100/250]	Loss -2.1964e-07 (-9.6462e-08)	Acc@1  20.50 ( 23.47)	Acc@5  47.00 ( 49.47)
[TRAIN] E: [21][200/250]	Loss -2.5868e-07 (-8.3365e-08)	Acc@1  16.00 ( 22.29)	Acc@5  41.50 ( 47.83)
[TRAIN] E: [21][249/250]	Loss 8.3148e-08 (-7.7018e-08)	Acc@1  19.50 ( 21.51)	Acc@5  43.50 ( 46.78)
[EVAL] E: [21][ 0/50]	Loss 4.5779e+00 (4.5779e+00)	Acc@1  30.00 ( 30.00)	Acc@5  62.00 ( 62.00)
[EVAL] E: [21][49/50]	Loss 4.5789e+00 (4.5784e+00)	Acc@1  28.50 ( 29.17)	Acc@5  55.00 ( 59.06)
		 LR=0.059381409218897986 -- best acc so far 53.46
***[2023-04-24 14:44:14]*** [Post-train] [Student] EVALUATION loss = 4.578430, accuracy@1 = 29.17, accuracy@5 = 59.06, error@1 = 70.83, error@5 = 40.94
[TRAIN] E: [22][  0/250]	Loss 1.0729e-08 (1.0729e-08)	Acc@1  19.50 ( 19.50)	Acc@5  41.50 ( 41.50)
[TRAIN] E: [22][100/250]	Loss -2.2948e-08 (-5.8112e-08)	Acc@1  15.50 ( 16.74)	Acc@5  37.50 ( 39.68)
[TRAIN] E: [22][200/250]	Loss 8.0466e-09 (-5.5386e-08)	Acc@1   8.50 ( 15.37)	Acc@5  33.00 ( 37.07)
[TRAIN] E: [22][249/250]	Loss -6.1691e-08 (-5.8289e-08)	Acc@1  12.00 ( 14.75)	Acc@5  29.00 ( 35.90)
[EVAL] E: [22][ 0/50]	Loss 4.5879e+00 (4.5879e+00)	Acc@1  17.00 ( 17.00)	Acc@5  49.50 ( 49.50)
[EVAL] E: [22][49/50]	Loss 4.5882e+00 (4.5879e+00)	Acc@1  19.00 ( 19.19)	Acc@5  41.00 ( 46.13)
		 LR=0.05627912876119434 -- best acc so far 53.46
***[2023-04-24 14:47:02]*** [Post-train] [Student] EVALUATION loss = 4.587925, accuracy@1 = 19.19, accuracy@5 = 46.13, error@1 = 80.81, error@5 = 53.87
[TRAIN] E: [23][  0/250]	Loss 5.4538e-08 (5.4538e-08)	Acc@1  13.50 ( 13.50)	Acc@5  34.50 ( 34.50)
[TRAIN] E: [23][100/250]	Loss -3.3170e-07 (-1.8740e-08)	Acc@1  11.00 ( 10.43)	Acc@5  28.00 ( 28.32)
[TRAIN] E: [23][200/250]	Loss -1.0580e-07 (-5.5260e-09)	Acc@1   6.00 (  9.67)	Acc@5  20.00 ( 26.03)
[TRAIN] E: [23][249/250]	Loss -3.4600e-07 (-7.6485e-09)	Acc@1   8.50 (  9.29)	Acc@5  21.00 ( 25.08)
[EVAL] E: [23][ 0/50]	Loss 4.5948e+00 (4.5948e+00)	Acc@1  10.00 ( 10.00)	Acc@5  28.50 ( 28.50)
[EVAL] E: [23][49/50]	Loss 4.5947e+00 (4.5945e+00)	Acc@1  11.00 ( 10.54)	Acc@5  29.00 ( 32.05)
		 LR=0.05315206745093131 -- best acc so far 53.46
***[2023-04-24 14:49:52]*** [Post-train] [Student] EVALUATION loss = 4.594516, accuracy@1 = 10.54, accuracy@5 = 32.05, error@1 = 89.46, error@5 = 67.95
[TRAIN] E: [24][  0/250]	Loss -5.2154e-08 (-5.2154e-08)	Acc@1   6.00 (  6.00)	Acc@5  18.00 ( 18.00)
[TRAIN] E: [24][100/250]	Loss -1.6093e-08 (8.5955e-09)	Acc@1   5.50 (  6.47)	Acc@5  16.50 ( 18.53)
[TRAIN] E: [24][200/250]	Loss 9.2387e-09 (3.6065e-08)	Acc@1   5.00 (  6.01)	Acc@5  11.50 ( 16.98)
[TRAIN] E: [24][249/250]	Loss -3.0845e-07 (4.6040e-08)	Acc@1   4.00 (  5.69)	Acc@5  10.50 ( 16.23)
[EVAL] E: [24][ 0/50]	Loss 4.5994e+00 (4.5994e+00)	Acc@1   5.50 (  5.50)	Acc@5  18.00 ( 18.00)
[EVAL] E: [24][49/50]	Loss 4.5990e+00 (4.5989e+00)	Acc@1   6.00 (  5.44)	Acc@5  16.00 ( 18.77)
		 LR=0.05001256637048207 -- best acc so far 53.46
***[2023-04-24 14:52:39]*** [Post-train] [Student] EVALUATION loss = 4.598911, accuracy@1 = 5.44, accuracy@5 = 18.77, error@1 = 94.56, error@5 = 81.23
[TRAIN] E: [25][  0/250]	Loss -2.5451e-07 (-2.5451e-07)	Acc@1   4.00 (  4.00)	Acc@5  12.00 ( 12.00)
[TRAIN] E: [25][100/250]	Loss -1.0103e-07 (3.4172e-08)	Acc@1   2.00 (  3.73)	Acc@5   8.00 ( 10.96)
[TRAIN] E: [25][200/250]	Loss 1.3471e-07 (4.1016e-08)	Acc@1   1.50 (  3.39)	Acc@5   9.50 ( 10.25)
[TRAIN] E: [25][249/250]	Loss 8.1360e-08 (3.7062e-08)	Acc@1   5.00 (  3.23)	Acc@5  11.50 (  9.91)
[EVAL] E: [25][ 0/50]	Loss 4.6023e+00 (4.6023e+00)	Acc@1   3.50 (  3.50)	Acc@5   9.00 (  9.00)
[EVAL] E: [25][49/50]	Loss 4.6018e+00 (4.6017e+00)	Acc@1   2.00 (  2.61)	Acc@5   9.00 ( 10.11)
		 LR=0.04687301569630958 -- best acc so far 53.46
***[2023-04-24 14:55:26]*** [Post-train] [Student] EVALUATION loss = 4.601741, accuracy@1 = 2.61, accuracy@5 = 10.11, error@1 = 97.39, error@5 = 89.89
[TRAIN] E: [26][  0/250]	Loss 4.5896e-08 (4.5896e-08)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [26][100/250]	Loss 4.1425e-08 (5.2169e-08)	Acc@1   2.50 (  2.08)	Acc@5  10.00 (  7.76)
[TRAIN] E: [26][200/250]	Loss 6.7651e-08 (6.9666e-08)	Acc@1   2.50 (  1.93)	Acc@5   6.50 (  7.26)
[TRAIN] E: [26][249/250]	Loss -8.5533e-08 (7.0131e-08)	Acc@1   2.00 (  1.82)	Acc@5   7.50 (  7.08)
[EVAL] E: [26][ 0/50]	Loss 4.6040e+00 (4.6040e+00)	Acc@1   2.00 (  2.00)	Acc@5   8.50 (  8.50)
[EVAL] E: [26][49/50]	Loss 4.6035e+00 (4.6034e+00)	Acc@1   1.50 (  1.49)	Acc@5   6.50 (  6.67)
		 LR=0.04374580580060053 -- best acc so far 53.46
***[2023-04-24 14:58:15]*** [Post-train] [Student] EVALUATION loss = 4.603450, accuracy@1 = 1.49, accuracy@5 = 6.67, error@1 = 98.51, error@5 = 93.33
[TRAIN] E: [27][  0/250]	Loss 1.1265e-07 (1.1265e-07)	Acc@1   0.00 (  0.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [27][100/250]	Loss 1.8120e-07 (9.2128e-08)	Acc@1   1.50 (  1.26)	Acc@5   8.00 (  6.08)
[TRAIN] E: [27][200/250]	Loss 1.5259e-07 (9.7597e-08)	Acc@1   0.00 (  1.21)	Acc@5   5.00 (  5.90)
[TRAIN] E: [27][249/250]	Loss 1.5169e-07 (9.7150e-08)	Acc@1   1.00 (  1.17)	Acc@5   6.50 (  5.82)
[EVAL] E: [27][ 0/50]	Loss 4.6049e+00 (4.6049e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [27][49/50]	Loss 4.6044e+00 (4.6044e+00)	Acc@1   1.50 (  1.06)	Acc@5   5.50 (  5.27)
		 LR=0.04064327835212695 -- best acc so far 53.46
***[2023-04-24 15:01:00]*** [Post-train] [Student] EVALUATION loss = 4.604385, accuracy@1 = 1.06, accuracy@5 = 5.27, error@1 = 98.94, error@5 = 94.73
[TRAIN] E: [28][  0/250]	Loss 2.1011e-07 (2.1011e-07)	Acc@1   2.50 (  2.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [28][100/250]	Loss 2.3842e-09 (1.5260e-07)	Acc@1   0.00 (  1.09)	Acc@5   5.50 (  5.34)
[TRAIN] E: [28][200/250]	Loss -9.1493e-08 (1.3019e-07)	Acc@1   0.50 (  1.03)	Acc@5   4.00 (  5.38)
[TRAIN] E: [28][249/250]	Loss 3.2485e-07 (1.2411e-07)	Acc@1   1.00 (  1.01)	Acc@5   4.50 (  5.35)
[EVAL] E: [28][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [28][49/50]	Loss 4.6048e+00 (4.6048e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.06)
		 LR=0.03757767760931802 -- best acc so far 53.46
***[2023-04-24 15:03:49]*** [Post-train] [Student] EVALUATION loss = 4.604833, accuracy@1 = 1.00, accuracy@5 = 5.06, error@1 = 99.00, error@5 = 94.94
[TRAIN] E: [29][  0/250]	Loss 1.8954e-07 (1.8954e-07)	Acc@1   0.00 (  0.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [29][100/250]	Loss 2.6226e-08 (1.0285e-07)	Acc@1   0.50 (  0.96)	Acc@5   4.00 (  5.47)
[TRAIN] E: [29][200/250]	Loss -7.2122e-08 (1.1570e-07)	Acc@1   2.00 (  1.01)	Acc@5   5.50 (  5.26)
[TRAIN] E: [29][249/250]	Loss 2.1785e-07 (1.1529e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.22)
[EVAL] E: [29][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [29][49/50]	Loss 4.6050e+00 (4.6050e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.05)
		 LR=0.034561102097765854 -- best acc so far 53.46
***[2023-04-24 15:06:36]*** [Post-train] [Student] EVALUATION loss = 4.605020, accuracy@1 = 1.00, accuracy@5 = 5.05, error@1 = 99.00, error@5 = 94.95
[TRAIN] E: [30][  0/250]	Loss -1.8477e-08 (-1.8477e-08)	Acc@1   2.00 (  2.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [30][100/250]	Loss 2.5421e-07 (1.3918e-07)	Acc@1   1.50 (  1.01)	Acc@5   8.00 (  5.19)
[TRAIN] E: [30][200/250]	Loss 1.6302e-07 (1.3558e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  5.11)
[TRAIN] E: [30][249/250]	Loss 4.8339e-07 (1.3850e-07)	Acc@1   2.00 (  1.00)	Acc@5   6.50 (  5.16)
[EVAL] E: [30][ 0/50]	Loss 4.6056e+00 (4.6056e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [30][49/50]	Loss 4.6051e+00 (4.6051e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.05)
		 LR=0.0316054568628723 -- best acc so far 53.46
***[2023-04-24 15:09:20]*** [Post-train] [Student] EVALUATION loss = 4.605096, accuracy@1 = 1.00, accuracy@5 = 5.05, error@1 = 99.00, error@5 = 94.95
[TRAIN] E: [31][  0/250]	Loss 1.8895e-07 (1.8895e-07)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [31][100/250]	Loss 1.4633e-07 (1.1137e-07)	Acc@1   1.00 (  1.04)	Acc@5   5.00 (  5.11)
[TRAIN] E: [31][200/250]	Loss 2.0057e-07 (1.2561e-07)	Acc@1   0.50 (  1.01)	Acc@5   5.00 (  5.14)
[TRAIN] E: [31][249/250]	Loss -8.0764e-08 (1.3073e-07)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  5.15)
[EVAL] E: [31][ 0/50]	Loss 4.6056e+00 (4.6056e+00)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [31][49/50]	Loss 4.6051e+00 (4.6051e+00)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.08)
		 LR=0.028722406486073566 -- best acc so far 53.46
***[2023-04-24 15:12:05]*** [Post-train] [Student] EVALUATION loss = 4.605131, accuracy@1 = 1.00, accuracy@5 = 5.08, error@1 = 99.00, error@5 = 94.92
[TRAIN] E: [32][  0/250]	Loss -7.7784e-08 (-7.7784e-08)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [32][100/250]	Loss 3.7432e-07 (1.2321e-07)	Acc@1   0.50 (  1.04)	Acc@5   4.00 (  5.31)
[TRAIN] E: [32][200/250]	Loss -8.1658e-08 (1.1851e-07)	Acc@1   0.00 (  1.00)	Acc@5   4.50 (  5.26)
[TRAIN] E: [32][249/250]	Loss 3.3855e-07 (1.2844e-07)	Acc@1   2.50 (  1.00)	Acc@5   5.00 (  5.18)
[EVAL] E: [32][ 0/50]	Loss 4.6056e+00 (4.6056e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [32][49/50]	Loss 4.6052e+00 (4.6051e+00)	Acc@1   1.50 (  1.00)	Acc@5   4.50 (  5.08)
		 LR=0.02592332905006647 -- best acc so far 53.46
***[2023-04-24 15:15:03]*** [Post-train] [Student] EVALUATION loss = 4.605149, accuracy@1 = 1.00, accuracy@5 = 5.08, error@1 = 99.00, error@5 = 94.92
[TRAIN] E: [33][  0/250]	Loss 1.0103e-07 (1.0103e-07)	Acc@1   0.00 (  0.00)	Acc@5   2.00 (  2.00)
[TRAIN] E: [33][100/250]	Loss 3.0071e-07 (1.5257e-07)	Acc@1   0.00 (  1.18)	Acc@5   5.00 (  5.28)
[TRAIN] E: [33][200/250]	Loss 3.4511e-07 (1.6764e-07)	Acc@1   0.50 (  1.08)	Acc@5   5.50 (  5.22)
[TRAIN] E: [33][249/250]	Loss 9.1195e-08 (1.6901e-07)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.13)
[EVAL] E: [33][ 0/50]	Loss 4.6056e+00 (4.6056e+00)	Acc@1   1.50 (  1.50)	Acc@5   7.00 (  7.00)
[EVAL] E: [33][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   4.50 (  5.18)
		 LR=0.02321927123471414 -- best acc so far 53.46
***[2023-04-24 15:18:10]*** [Post-train] [Student] EVALUATION loss = 4.605159, accuracy@1 = 1.00, accuracy@5 = 5.18, error@1 = 99.00, error@5 = 94.82
[TRAIN] E: [34][  0/250]	Loss -6.0201e-08 (-6.0201e-08)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [34][100/250]	Loss 2.3961e-07 (1.3417e-07)	Acc@1   0.50 (  0.96)	Acc@5   5.00 (  4.98)
[TRAIN] E: [34][200/250]	Loss 1.6689e-07 (1.3398e-07)	Acc@1   1.00 (  0.99)	Acc@5   6.00 (  5.02)
[TRAIN] E: [34][249/250]	Loss 3.5882e-07 (1.3211e-07)	Acc@1   0.00 (  1.00)	Acc@5   2.50 (  5.05)
[EVAL] E: [34][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   7.00 (  7.00)
[EVAL] E: [34][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.03)
		 LR=0.020620904720847207 -- best acc so far 53.46
***[2023-04-24 15:21:21]*** [Post-train] [Student] EVALUATION loss = 4.605164, accuracy@1 = 1.00, accuracy@5 = 5.03, error@1 = 99.00, error@5 = 94.97
[TRAIN] E: [35][  0/250]	Loss -7.1526e-09 (-7.1526e-09)	Acc@1   2.00 (  2.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [35][100/250]	Loss -1.8746e-07 (1.5356e-07)	Acc@1   1.00 (  1.01)	Acc@5   3.50 (  4.96)
[TRAIN] E: [35][200/250]	Loss 4.0621e-07 (1.7284e-07)	Acc@1   1.00 (  1.01)	Acc@5   5.00 (  4.98)
[TRAIN] E: [35][249/250]	Loss 2.1070e-07 (1.8690e-07)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.01)
[EVAL] E: [35][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [35][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.018138484074015183 -- best acc so far 53.46
***[2023-04-24 15:24:30]*** [Post-train] [Student] EVALUATION loss = 4.605168, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [36][  0/250]	Loss 1.8686e-07 (1.8686e-07)	Acc@1   0.00 (  0.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [36][100/250]	Loss 2.5004e-07 (1.5936e-07)	Acc@1   1.00 (  0.95)	Acc@5   6.00 (  4.95)
[TRAIN] E: [36][200/250]	Loss 2.4140e-07 (1.9099e-07)	Acc@1   1.50 (  0.99)	Acc@5   7.00 (  5.02)
[TRAIN] E: [36][249/250]	Loss 1.2755e-07 (1.8344e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [36][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [36][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.015781806274400994 -- best acc so far 53.46
***[2023-04-24 15:27:40]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [37][  0/250]	Loss 2.9802e-09 (2.9802e-09)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [37][100/250]	Loss -1.1742e-07 (1.7150e-07)	Acc@1   0.50 (  1.10)	Acc@5   5.50 (  5.13)
[TRAIN] E: [37][200/250]	Loss -6.1393e-08 (1.6432e-07)	Acc@1   0.50 (  1.01)	Acc@5   4.00 (  5.05)
[TRAIN] E: [37][249/250]	Loss 4.8459e-07 (1.9215e-07)	Acc@1   2.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [37][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [37][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.013560172052616067 -- best acc so far 53.46
***[2023-04-24 15:30:46]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [38][  0/250]	Loss 3.3319e-07 (3.3319e-07)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [38][100/250]	Loss 1.2368e-07 (2.2531e-07)	Acc@1   1.00 (  1.02)	Acc@5   3.50 (  5.00)
[TRAIN] E: [38][200/250]	Loss 3.8892e-07 (2.1226e-07)	Acc@1   1.50 (  0.98)	Acc@5   5.50 (  5.03)
[TRAIN] E: [38][249/250]	Loss 2.7686e-07 (2.3189e-07)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [38][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [38][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.011482349183965618 -- best acc so far 53.46
***[2023-04-24 15:33:31]*** [Post-train] [Student] EVALUATION loss = 4.605172, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [39][  0/250]	Loss 6.4969e-07 (6.4969e-07)	Acc@1   0.00 (  0.00)	Acc@5   2.50 (  2.50)
[TRAIN] E: [39][100/250]	Loss 2.6882e-07 (1.3509e-07)	Acc@1   2.00 (  1.00)	Acc@5   4.50 (  5.03)
[TRAIN] E: [39][200/250]	Loss 8.1360e-08 (1.5069e-07)	Acc@1   1.50 (  1.01)	Acc@5   6.00 (  5.07)
[TRAIN] E: [39][249/250]	Loss 5.5313e-07 (1.4529e-07)	Acc@1   0.00 (  1.00)	Acc@5   7.50 (  5.00)
[EVAL] E: [39][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [39][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.009556537886045253 -- best acc so far 53.46
***[2023-04-24 15:36:12]*** [Post-train] [Student] EVALUATION loss = 4.605173, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [40][  0/250]	Loss 4.8697e-07 (4.8697e-07)	Acc@1   0.00 (  0.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [40][100/250]	Loss 1.4186e-07 (1.9243e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  5.12)
[TRAIN] E: [40][200/250]	Loss -1.5706e-07 (1.9599e-07)	Acc@1   0.50 (  0.98)	Acc@5   4.50 (  4.97)
[TRAIN] E: [40][249/250]	Loss 3.5077e-07 (2.1113e-07)	Acc@1   1.00 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [40][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [40][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.00779033845622838 -- best acc so far 53.46
***[2023-04-24 15:38:55]*** [Post-train] [Student] EVALUATION loss = 4.605173, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [41][  0/250]	Loss 1.3381e-07 (1.3381e-07)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [41][100/250]	Loss 6.9857e-07 (1.0513e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  5.01)
[TRAIN] E: [41][200/250]	Loss 6.9022e-07 (2.0038e-07)	Acc@1   0.50 (  0.99)	Acc@5   4.50 (  4.98)
[TRAIN] E: [41][249/250]	Loss 1.3679e-07 (1.7633e-07)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [41][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [41][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.006190721276764722 -- best acc so far 53.46
***[2023-04-24 15:41:39]*** [Post-train] [Student] EVALUATION loss = 4.605173, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [42][  0/250]	Loss 4.7535e-07 (4.7535e-07)	Acc@1   0.50 (  0.50)	Acc@5   7.50 (  7.50)
[TRAIN] E: [42][100/250]	Loss 5.3197e-07 (2.3358e-08)	Acc@1   0.00 (  0.92)	Acc@5   5.00 (  4.95)
[TRAIN] E: [42][200/250]	Loss 7.1824e-08 (1.9563e-07)	Acc@1   0.50 (  1.00)	Acc@5   3.00 (  5.01)
[TRAIN] E: [42][249/250]	Loss 5.0336e-07 (2.1769e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [42][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [42][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.004763999305866018 -- best acc so far 53.46
***[2023-04-24 15:44:23]*** [Post-train] [Student] EVALUATION loss = 4.605173, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [43][  0/250]	Loss 2.2560e-07 (2.2560e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [43][100/250]	Loss -3.1590e-07 (3.5952e-08)	Acc@1   1.00 (  0.98)	Acc@5   3.00 (  4.99)
[TRAIN] E: [43][200/250]	Loss 3.6865e-07 (7.4402e-09)	Acc@1   2.00 (  0.99)	Acc@5   5.50 (  4.93)
[TRAIN] E: [43][249/250]	Loss 1.7643e-07 (1.0467e-07)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [43][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [43][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.003515803163344178 -- best acc so far 53.46
***[2023-04-24 15:46:59]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [44][  0/250]	Loss 5.2869e-07 (5.2869e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [44][100/250]	Loss 2.3514e-07 (3.2472e-07)	Acc@1   0.00 (  1.00)	Acc@5   5.00 (  5.20)
[TRAIN] E: [44][200/250]	Loss -1.9163e-07 (2.8734e-07)	Acc@1   1.50 (  0.97)	Acc@5   3.00 (  4.98)
[TRAIN] E: [44][249/250]	Loss -9.9540e-08 (2.3527e-07)	Acc@1   1.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [44][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [44][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0024510589091271354 -- best acc so far 53.46
***[2023-04-24 15:49:39]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [45][  0/250]	Loss 3.0100e-08 (3.0100e-08)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [45][100/250]	Loss -5.7846e-07 (-6.9838e-08)	Acc@1   0.50 (  1.02)	Acc@5   6.50 (  4.99)
[TRAIN] E: [45][200/250]	Loss -2.6077e-07 (2.3310e-08)	Acc@1   0.50 (  1.01)	Acc@5   5.00 (  4.99)
[TRAIN] E: [45][249/250]	Loss -2.0742e-07 (-5.8354e-08)	Acc@1   1.00 (  1.00)	Acc@5   9.00 (  5.00)
[EVAL] E: [45][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [45][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0015739686023509116 -- best acc so far 53.46
***[2023-04-24 15:51:26]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [46][  0/250]	Loss -1.3262e-07 (-1.3262e-07)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [46][100/250]	Loss 9.2298e-07 (2.9484e-07)	Acc@1   1.00 (  1.11)	Acc@5   5.50 (  5.12)
[TRAIN] E: [46][200/250]	Loss 4.6790e-08 (4.0607e-07)	Acc@1   0.50 (  1.07)	Acc@5   4.50 (  5.11)
[TRAIN] E: [46][249/250]	Loss 5.6922e-08 (3.2152e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [46][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [46][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.000887993717751906 -- best acc so far 53.46
***[2023-04-24 15:52:16]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [47][  0/250]	Loss -2.9802e-10 (-2.9802e-10)	Acc@1   2.00 (  2.00)	Acc@5  10.50 ( 10.50)
[TRAIN] E: [47][100/250]	Loss 8.4519e-07 (3.6356e-07)	Acc@1   1.50 (  0.95)	Acc@5   7.00 (  5.01)
[TRAIN] E: [47][200/250]	Loss 6.6906e-07 (4.7475e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.01)
[TRAIN] E: [47][249/250]	Loss 2.4736e-07 (4.8478e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [47][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [47][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0003958414848075243 -- best acc so far 53.46
***[2023-04-24 15:53:01]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [48][  0/250]	Loss 5.5581e-07 (5.5581e-07)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [48][100/250]	Loss -1.0639e-07 (1.1971e-07)	Acc@1   1.00 (  0.97)	Acc@5   3.00 (  4.99)
[TRAIN] E: [48][200/250]	Loss 5.9605e-08 (1.6404e-07)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  4.98)
[TRAIN] E: [48][249/250]	Loss 4.3631e-07 (1.8117e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [48][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [48][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=9.945420353821844e-05 -- best acc so far 53.46
***[2023-04-24 15:53:46]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [49][  0/250]	Loss 3.8981e-07 (3.8981e-07)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [49][100/250]	Loss 6.2704e-07 (3.8431e-07)	Acc@1   0.00 (  0.97)	Acc@5   3.50 (  5.01)
[TRAIN] E: [49][200/250]	Loss 6.0081e-07 (3.7903e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  4.98)
[TRAIN] E: [49][249/250]	Loss 4.0174e-07 (3.7854e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [49][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [49][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=1.57913669363019e-09 -- best acc so far 53.46
***[2023-04-24 15:54:31]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [50][  0/250]	Loss 4.4316e-07 (4.4316e-07)	Acc@1   1.50 (  1.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [50][100/250]	Loss 4.3929e-07 (1.7937e-07)	Acc@1   2.00 (  1.07)	Acc@5   5.00 (  5.26)
[TRAIN] E: [50][200/250]	Loss 3.9220e-07 (2.1726e-07)	Acc@1   0.00 (  0.98)	Acc@5   3.50 (  5.00)
[TRAIN] E: [50][249/250]	Loss -8.0854e-07 (1.7075e-07)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [50][ 0/50]	Loss 4.6055e+00 (4.6055e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [50][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09990212389432412 -- best acc so far 53.46
***[2023-04-24 15:55:16]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [51][  0/250]	Loss -9.7722e-07 (-9.7722e-07)	Acc@1   2.00 (  2.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [51][100/250]	Loss -1.1632e-06 (2.6991e-07)	Acc@1   1.00 (  1.06)	Acc@5  10.00 (  4.92)
[TRAIN] E: [51][200/250]	Loss -2.2539e-06 (1.7971e-07)	Acc@1   1.00 (  1.01)	Acc@5   4.50 (  4.97)
[TRAIN] E: [51][249/250]	Loss 4.7177e-07 (1.9384e-07)	Acc@1   1.50 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [51][ 0/50]	Loss 4.6054e+00 (4.6054e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [51][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09960730848288585 -- best acc so far 53.46
***[2023-04-24 15:56:00]*** [Post-train] [Student] EVALUATION loss = 4.605174, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [52][  0/250]	Loss 2.7779e-06 (2.7779e-06)	Acc@1   0.00 (  0.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [52][100/250]	Loss -2.3979e-06 (2.1950e-07)	Acc@1   1.00 (  1.03)	Acc@5   5.50 (  4.95)
[TRAIN] E: [52][200/250]	Loss 6.4939e-07 (1.7377e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.03)
[TRAIN] E: [52][249/250]	Loss -1.6421e-06 (1.4139e-07)	Acc@1   0.00 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [52][ 0/50]	Loss 4.6054e+00 (4.6054e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [52][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0991167156882891 -- best acc so far 53.46
***[2023-04-24 15:56:45]*** [Post-train] [Student] EVALUATION loss = 4.605173, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [53][  0/250]	Loss 2.2259e-06 (2.2259e-06)	Acc@1   1.50 (  1.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [53][100/250]	Loss -2.8628e-06 (2.4917e-07)	Acc@1   0.50 (  1.07)	Acc@5   5.50 (  4.98)
[TRAIN] E: [53][200/250]	Loss 3.3063e-06 (3.5688e-07)	Acc@1   0.50 (  0.99)	Acc@5   2.00 (  5.01)
[TRAIN] E: [53][249/250]	Loss -3.1620e-06 (3.1810e-07)	Acc@1   1.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [53][ 0/50]	Loss 4.6054e+00 (4.6054e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [53][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0984322816561636 -- best acc so far 53.46
***[2023-04-24 15:57:30]*** [Post-train] [Student] EVALUATION loss = 4.605172, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [54][  0/250]	Loss 2.9397e-06 (2.9397e-06)	Acc@1   2.50 (  2.50)	Acc@5   6.50 (  6.50)
[TRAIN] E: [54][100/250]	Loss 4.8161e-07 (3.5410e-07)	Acc@1   1.00 (  0.98)	Acc@5   4.50 (  4.76)
[TRAIN] E: [54][200/250]	Loss -3.2651e-06 (2.9633e-07)	Acc@1   2.50 (  1.00)	Acc@5   5.00 (  4.95)
[TRAIN] E: [54][249/250]	Loss -2.6399e-06 (2.7170e-07)	Acc@1   0.00 (  1.00)	Acc@5   2.00 (  5.00)
[EVAL] E: [54][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [54][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09755670753494601 -- best acc so far 53.46
***[2023-04-24 15:58:15]*** [Post-train] [Student] EVALUATION loss = 4.605172, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [55][  0/250]	Loss -2.7236e-06 (-2.7236e-06)	Acc@1   2.00 (  2.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [55][100/250]	Loss 3.7566e-06 (5.6246e-07)	Acc@1   2.00 (  0.98)	Acc@5   6.50 (  5.09)
[TRAIN] E: [55][200/250]	Loss 3.5763e-06 (3.1589e-07)	Acc@1   0.50 (  0.97)	Acc@5   5.50 (  5.01)
[TRAIN] E: [55][249/250]	Loss -1.4317e-06 (2.9452e-07)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [55][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [55][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09649344881568099 -- best acc so far 53.46
***[2023-04-24 15:59:01]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [56][  0/250]	Loss 4.4703e-07 (4.4703e-07)	Acc@1   1.50 (  1.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [56][100/250]	Loss 1.7285e-06 (2.5602e-07)	Acc@1   0.50 (  0.99)	Acc@5   5.00 (  4.83)
[TRAIN] E: [56][200/250]	Loss 3.0398e-06 (4.2682e-07)	Acc@1   1.50 (  1.00)	Acc@5   3.50 (  5.03)
[TRAIN] E: [56][249/250]	Loss -7.1526e-07 (4.3018e-07)	Acc@1   0.50 (  0.98)	Acc@5   3.50 (  5.00)
[EVAL] E: [56][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [56][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09524670169477678 -- best acc so far 53.46
***[2023-04-24 15:59:47]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [57][  0/250]	Loss 1.7881e-07 (1.7881e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  6.50)
[TRAIN] E: [57][100/250]	Loss -2.5630e-06 (2.1098e-07)	Acc@1   1.00 (  0.96)	Acc@5   3.50 (  5.05)
[TRAIN] E: [57][200/250]	Loss 4.7684e-07 (2.8349e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  4.96)
[TRAIN] E: [57][249/250]	Loss -1.9073e-06 (3.3020e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [57][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [57][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.093821386513535 -- best acc so far 53.46
***[2023-04-24 16:00:32]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [58][  0/250]	Loss 5.9605e-07 (5.9605e-07)	Acc@1   1.50 (  1.50)	Acc@5   8.50 (  8.50)
[TRAIN] E: [58][100/250]	Loss 2.3842e-07 (6.3804e-08)	Acc@1   0.00 (  0.99)	Acc@5   3.00 (  5.13)
[TRAIN] E: [58][200/250]	Loss -1.2517e-06 (1.8912e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  4.98)
[TRAIN] E: [58][249/250]	Loss 2.5034e-06 (9.1988e-08)	Acc@1   1.50 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [58][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [58][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09222312833981147 -- best acc so far 53.46
***[2023-04-24 16:01:17]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [59][  0/250]	Loss -7.1526e-07 (-7.1526e-07)	Acc@1   0.50 (  0.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [59][100/250]	Loss 2.5034e-06 (5.1008e-07)	Acc@1   1.00 (  1.05)	Acc@5   5.50 (  4.69)
[TRAIN] E: [59][200/250]	Loss -1.5497e-06 (4.4978e-07)	Acc@1   1.00 (  1.04)	Acc@5   3.50 (  4.98)
[TRAIN] E: [59][249/250]	Loss 5.9605e-08 (2.8557e-07)	Acc@1   0.00 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [59][ 0/50]	Loss 4.6053e+00 (4.6053e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [59][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09045823476844315 -- best acc so far 53.46
***[2023-04-24 16:02:01]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [60][  0/250]	Loss -3.6955e-06 (-3.6955e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [60][100/250]	Loss 3.2187e-06 (-1.8735e-07)	Acc@1   3.50 (  1.03)	Acc@5  10.00 (  4.90)
[TRAIN] E: [60][200/250]	Loss 2.8610e-06 (7.5404e-08)	Acc@1   1.00 (  0.96)	Acc@5   5.50 (  4.91)
[TRAIN] E: [60][249/250]	Loss 7.7486e-07 (1.7578e-07)	Acc@1   1.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [60][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [60][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08853367102805307 -- best acc so far 53.46
***[2023-04-24 16:02:47]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [61][  0/250]	Loss -2.3842e-06 (-2.3842e-06)	Acc@1   2.00 (  2.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [61][100/250]	Loss -3.8147e-06 (2.5975e-08)	Acc@1   0.50 (  0.99)	Acc@5   7.00 (  5.05)
[TRAIN] E: [61][200/250]	Loss -1.8477e-06 (-7.8875e-08)	Acc@1   0.50 (  0.96)	Acc@5   4.50 (  4.97)
[TRAIN] E: [61][249/250]	Loss 4.1723e-07 (-2.9083e-08)	Acc@1   2.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [61][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [61][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.086457032492475 -- best acc so far 53.46
***[2023-04-24 16:03:31]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [62][  0/250]	Loss -1.9670e-06 (-1.9670e-06)	Acc@1   1.50 (  1.50)	Acc@5   7.50 (  7.50)
[TRAIN] E: [62][100/250]	Loss 0.0000e+00 (3.2871e-07)	Acc@1   0.00 (  1.05)	Acc@5   6.00 (  4.98)
[TRAIN] E: [62][200/250]	Loss 3.1590e-06 (3.6534e-07)	Acc@1   2.00 (  1.00)	Acc@5   5.50 (  4.99)
[TRAIN] E: [62][249/250]	Loss 4.1723e-07 (3.9339e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [62][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [62][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08423651470528296 -- best acc so far 53.46
***[2023-04-24 16:04:16]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [63][  0/250]	Loss -2.1458e-06 (-2.1458e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [63][100/250]	Loss -5.9605e-07 (1.6878e-07)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.01)
[TRAIN] E: [63][200/250]	Loss -2.8610e-06 (9.9045e-08)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  4.98)
[TRAIN] E: [63][249/250]	Loss 1.7285e-06 (1.1754e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [63][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [63][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08188088103572494 -- best acc so far 53.46
***[2023-04-24 16:05:01]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [64][  0/250]	Loss -8.9407e-07 (-8.9407e-07)	Acc@1   0.50 (  0.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [64][100/250]	Loss -5.3644e-07 (-1.1685e-07)	Acc@1   2.50 (  1.11)	Acc@5   5.00 (  5.12)
[TRAIN] E: [64][200/250]	Loss -4.5896e-06 (-1.4115e-07)	Acc@1   1.00 (  1.02)	Acc@5   6.00 (  5.04)
[TRAIN] E: [64][249/250]	Loss 4.1723e-07 (-6.8426e-08)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [64][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [64][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07939942809370802 -- best acc so far 53.46
***[2023-04-24 16:05:45]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [65][  0/250]	Loss -2.3842e-06 (-2.3842e-06)	Acc@1   1.50 (  1.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [65][100/250]	Loss 3.2783e-06 (6.2319e-07)	Acc@1   1.00 (  0.91)	Acc@5   3.00 (  4.82)
[TRAIN] E: [65][200/250]	Loss 2.6226e-06 (6.1087e-07)	Acc@1   1.00 (  0.98)	Acc@5   7.00 (  5.00)
[TRAIN] E: [65][249/250]	Loss 2.0862e-06 (5.6314e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [65][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [65][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0768019490403263 -- best acc so far 53.46
***[2023-04-24 16:06:31]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [66][  0/250]	Loss 8.3447e-07 (8.3447e-07)	Acc@1   1.50 (  1.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [66][100/250]	Loss -2.5034e-06 (4.7625e-07)	Acc@1   0.50 (  0.93)	Acc@5   6.50 (  4.84)
[TRAIN] E: [66][200/250]	Loss 4.0531e-06 (5.6521e-07)	Acc@1   1.50 (  1.01)	Acc@5   5.50 (  4.98)
[TRAIN] E: [66][249/250]	Loss -5.3644e-07 (4.2558e-07)	Acc@1   0.50 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [66][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [66][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07409869493872821 -- best acc so far 53.46
***[2023-04-24 16:07:16]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [67][  0/250]	Loss -9.5367e-07 (-9.5367e-07)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [67][100/250]	Loss 2.3842e-07 (3.3166e-07)	Acc@1   0.50 (  1.05)	Acc@5   3.50 (  5.09)
[TRAIN] E: [67][200/250]	Loss 2.9802e-06 (2.0847e-07)	Acc@1   2.00 (  1.00)	Acc@5   6.50 (  5.04)
[TRAIN] E: [67][249/250]	Loss -1.1921e-07 (2.1482e-07)	Acc@1   1.50 (  1.00)	Acc@5   8.00 (  5.00)
[EVAL] E: [67][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [67][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07130033429785343 -- best acc so far 53.46
***[2023-04-24 16:08:00]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [68][  0/250]	Loss -1.6689e-06 (-1.6689e-06)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [68][100/250]	Loss 3.6955e-06 (4.4261e-08)	Acc@1   1.00 (  0.99)	Acc@5   2.50 (  4.95)
[TRAIN] E: [68][200/250]	Loss -2.0266e-06 (6.0494e-08)	Acc@1   0.00 (  0.99)	Acc@5   5.00 (  4.97)
[TRAIN] E: [68][249/250]	Loss 3.1590e-06 (4.8876e-08)	Acc@1   1.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [68][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [68][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06841791096870212 -- best acc so far 53.46
***[2023-04-24 16:08:45]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [69][  0/250]	Loss 1.6689e-06 (1.6689e-06)	Acc@1   2.00 (  2.00)	Acc@5   7.50 (  7.50)
[TRAIN] E: [69][100/250]	Loss -8.3447e-07 (2.2012e-07)	Acc@1   1.50 (  0.98)	Acc@5   7.50 (  4.98)
[TRAIN] E: [69][200/250]	Loss 1.4901e-06 (1.5865e-07)	Acc@1   0.00 (  0.98)	Acc@5   4.00 (  4.98)
[TRAIN] E: [69][249/250]	Loss -1.0133e-06 (1.9121e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [69][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [69][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06546280055930047 -- best acc so far 53.46
***[2023-04-24 16:09:31]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [70][  0/250]	Loss -3.4571e-06 (-3.4571e-06)	Acc@1   1.50 (  1.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [70][100/250]	Loss -1.0729e-06 (-2.0655e-07)	Acc@1   0.50 (  0.95)	Acc@5   2.50 (  4.96)
[TRAIN] E: [70][200/250]	Loss -8.3447e-07 (-1.0498e-07)	Acc@1   1.00 (  0.98)	Acc@5   4.50 (  5.01)
[TRAIN] E: [70][249/250]	Loss 2.0862e-06 (-4.8637e-08)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [70][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [70][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06244666554037286 -- best acc so far 53.46
***[2023-04-24 16:10:15]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [71][  0/250]	Loss 8.3447e-07 (8.3447e-07)	Acc@1   0.50 (  0.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [71][100/250]	Loss -5.9605e-07 (5.9605e-08)	Acc@1   1.50 (  1.03)	Acc@5   8.00 (  4.84)
[TRAIN] E: [71][200/250]	Loss 2.6822e-06 (7.7990e-08)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.02)
[TRAIN] E: [71][249/250]	Loss -3.3379e-06 (2.9325e-08)	Acc@1   0.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [71][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [71][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05938140921889801 -- best acc so far 53.46
***[2023-04-24 16:11:00]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [72][  0/250]	Loss 1.6093e-06 (1.6093e-06)	Acc@1   0.00 (  0.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [72][100/250]	Loss -2.1458e-06 (-2.2839e-07)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  4.87)
[TRAIN] E: [72][200/250]	Loss 2.5630e-06 (-8.0066e-08)	Acc@1   2.50 (  0.97)	Acc@5   5.00 (  5.01)
[TRAIN] E: [72][249/250]	Loss -1.2517e-06 (-1.1683e-08)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [72][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [72][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05627912876119434 -- best acc so far 53.46
***[2023-04-24 16:11:46]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [73][  0/250]	Loss -2.9802e-06 (-2.9802e-06)	Acc@1   2.00 (  2.00)	Acc@5   6.50 (  6.50)
[TRAIN] E: [73][100/250]	Loss -4.7684e-07 (-3.4819e-08)	Acc@1   0.00 (  0.95)	Acc@5   5.00 (  4.88)
[TRAIN] E: [73][200/250]	Loss -1.2517e-06 (-1.2277e-07)	Acc@1   1.00 (  1.01)	Acc@5   3.50 (  5.00)
[TRAIN] E: [73][249/250]	Loss 7.7486e-07 (-5.1737e-08)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [73][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [73][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05315206745093132 -- best acc so far 53.46
***[2023-04-24 16:12:31]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [74][  0/250]	Loss -1.0133e-06 (-1.0133e-06)	Acc@1   1.50 (  1.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [74][100/250]	Loss 5.3644e-07 (1.1921e-07)	Acc@1   0.50 (  1.00)	Acc@5   3.00 (  4.79)
[TRAIN] E: [74][200/250]	Loss 7.7486e-07 (-4.4778e-08)	Acc@1   1.50 (  1.01)	Acc@5   3.50 (  5.01)
[TRAIN] E: [74][249/250]	Loss -3.9935e-06 (-3.1233e-08)	Acc@1   2.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [74][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [74][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.050012566370482084 -- best acc so far 53.46
***[2023-04-24 16:13:16]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [75][  0/250]	Loss -3.7551e-06 (-3.7551e-06)	Acc@1   1.50 (  1.50)	Acc@5   6.50 (  6.50)
[TRAIN] E: [75][100/250]	Loss -1.6689e-06 (-2.7088e-07)	Acc@1   1.50 (  1.04)	Acc@5   5.00 (  5.01)
[TRAIN] E: [75][200/250]	Loss 3.5167e-06 (-1.3018e-07)	Acc@1   2.00 (  1.01)	Acc@5   6.50 (  4.99)
[TRAIN] E: [75][249/250]	Loss 3.5763e-06 (-5.3406e-08)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [75][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [75][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0468730156963096 -- best acc so far 53.46
***[2023-04-24 16:14:01]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [76][  0/250]	Loss 1.6689e-06 (1.6689e-06)	Acc@1   1.50 (  1.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [76][100/250]	Loss 3.2783e-06 (-5.0162e-08)	Acc@1   0.50 (  0.99)	Acc@5   5.50 (  5.20)
[TRAIN] E: [76][200/250]	Loss -2.5630e-06 (1.8504e-07)	Acc@1   0.50 (  1.01)	Acc@5   3.50 (  5.08)
[TRAIN] E: [76][249/250]	Loss 8.9407e-07 (2.1434e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [76][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [76][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.04374580580060053 -- best acc so far 53.46
***[2023-04-24 16:14:46]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [77][  0/250]	Loss 8.9407e-07 (8.9407e-07)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [77][100/250]	Loss -1.1325e-06 (-2.0950e-07)	Acc@1   0.50 (  1.04)	Acc@5   3.00 (  5.00)
[TRAIN] E: [77][200/250]	Loss -7.7486e-07 (1.9394e-07)	Acc@1   0.00 (  1.00)	Acc@5   5.50 (  5.01)
[TRAIN] E: [77][249/250]	Loss -2.7418e-06 (2.7657e-08)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [77][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [77][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.04064327835212697 -- best acc so far 53.46
***[2023-04-24 16:15:31]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [78][  0/250]	Loss -2.9206e-06 (-2.9206e-06)	Acc@1   0.50 (  0.50)	Acc@5   2.50 (  2.50)
[TRAIN] E: [78][100/250]	Loss -3.5763e-07 (6.5506e-07)	Acc@1   1.50 (  1.05)	Acc@5   5.00 (  5.03)
[TRAIN] E: [78][200/250]	Loss -2.2054e-06 (4.2198e-07)	Acc@1   0.50 (  1.01)	Acc@5   2.50 (  5.03)
[TRAIN] E: [78][249/250]	Loss 2.9206e-06 (4.1127e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [78][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [78][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.037577677609318044 -- best acc so far 53.46
***[2023-04-24 16:16:17]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [79][  0/250]	Loss 2.8014e-06 (2.8014e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [79][100/250]	Loss -2.6822e-06 (5.8365e-07)	Acc@1   2.50 (  1.00)	Acc@5   6.50 (  5.11)
[TRAIN] E: [79][200/250]	Loss -2.0266e-06 (3.7216e-07)	Acc@1   1.00 (  0.99)	Acc@5   2.00 (  5.01)
[TRAIN] E: [79][249/250]	Loss -1.3709e-06 (5.0974e-07)	Acc@1   1.00 (  1.00)	Acc@5   2.50 (  5.00)
[EVAL] E: [79][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [79][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.034561102097765875 -- best acc so far 53.46
***[2023-04-24 16:17:01]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [80][  0/250]	Loss -1.4901e-06 (-1.4901e-06)	Acc@1   1.50 (  1.50)	Acc@5   6.50 (  6.50)
[TRAIN] E: [80][100/250]	Loss 2.5630e-06 (-6.7867e-08)	Acc@1   0.50 (  1.06)	Acc@5   4.00 (  4.98)
[TRAIN] E: [80][200/250]	Loss 2.9802e-07 (1.9216e-07)	Acc@1   1.00 (  1.01)	Acc@5   6.50 (  5.00)
[TRAIN] E: [80][249/250]	Loss 3.6359e-06 (2.9087e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [80][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [80][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0316054568628723 -- best acc so far 53.46
***[2023-04-24 16:17:46]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [81][  0/250]	Loss 3.6955e-06 (3.6955e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [81][100/250]	Loss 2.6226e-06 (-2.5494e-07)	Acc@1   1.50 (  0.99)	Acc@5   6.50 (  4.92)
[TRAIN] E: [81][200/250]	Loss 3.5763e-06 (1.2662e-07)	Acc@1   1.00 (  0.99)	Acc@5   6.50 (  4.99)
[TRAIN] E: [81][249/250]	Loss 1.1325e-06 (2.4366e-07)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [81][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [81][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.028722406486073583 -- best acc so far 53.46
***[2023-04-24 16:18:50]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [82][  0/250]	Loss 1.1325e-06 (1.1325e-06)	Acc@1   0.00 (  0.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [82][100/250]	Loss 2.2650e-06 (2.1717e-07)	Acc@1   2.50 (  1.06)	Acc@5   9.00 (  5.04)
[TRAIN] E: [82][200/250]	Loss -8.3447e-07 (1.4886e-07)	Acc@1   1.50 (  1.00)	Acc@5   4.00 (  4.99)
[TRAIN] E: [82][249/250]	Loss -1.6093e-06 (6.8665e-08)	Acc@1   1.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [82][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [82][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.02592332905006651 -- best acc so far 53.46
***[2023-04-24 16:20:00]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [83][  0/250]	Loss -2.9802e-06 (-2.9802e-06)	Acc@1   2.00 (  2.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [83][100/250]	Loss 1.7285e-06 (1.0192e-06)	Acc@1   1.00 (  1.02)	Acc@5   3.50 (  4.94)
[TRAIN] E: [83][200/250]	Loss -6.5565e-07 (3.1018e-07)	Acc@1   0.00 (  1.00)	Acc@5   6.00 (  4.97)
[TRAIN] E: [83][249/250]	Loss -5.9605e-08 (3.1972e-07)	Acc@1   0.00 (  1.00)	Acc@5   8.00 (  5.00)
[EVAL] E: [83][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [83][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.023219271234714157 -- best acc so far 53.46
***[2023-04-24 16:21:31]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [84][  0/250]	Loss -1.0729e-06 (-1.0729e-06)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [84][100/250]	Loss -2.5034e-06 (1.8294e-07)	Acc@1   0.50 (  1.03)	Acc@5   5.50 (  5.10)
[TRAIN] E: [84][200/250]	Loss -1.4305e-06 (6.8857e-07)	Acc@1   1.00 (  1.01)	Acc@5   6.00 (  4.97)
[TRAIN] E: [84][249/250]	Loss -1.1325e-06 (7.8535e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [84][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [84][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.020620904720847225 -- best acc so far 53.46
***[2023-04-24 16:23:05]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [85][  0/250]	Loss -1.3113e-06 (-1.3113e-06)	Acc@1   0.00 (  0.00)	Acc@5   3.00 (  3.00)
[TRAIN] E: [85][100/250]	Loss 1.0133e-06 (-2.1540e-07)	Acc@1   0.00 (  1.05)	Acc@5   5.00 (  5.02)
[TRAIN] E: [85][200/250]	Loss 2.5630e-06 (-2.3783e-07)	Acc@1   1.00 (  1.01)	Acc@5   6.50 (  5.00)
[TRAIN] E: [85][249/250]	Loss -2.0862e-06 (-1.3757e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [85][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [85][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0181384840740152 -- best acc so far 53.46
***[2023-04-24 16:24:38]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [86][  0/250]	Loss -2.2054e-06 (-2.2054e-06)	Acc@1   1.50 (  1.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [86][100/250]	Loss 7.7486e-07 (1.2251e-06)	Acc@1   0.00 (  1.00)	Acc@5   8.00 (  5.03)
[TRAIN] E: [86][200/250]	Loss -2.5630e-06 (8.3951e-07)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.03)
[TRAIN] E: [86][249/250]	Loss 1.7881e-07 (1.0996e-06)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [86][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [86][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.01578180627440101 -- best acc so far 53.46
***[2023-04-24 16:26:11]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [87][  0/250]	Loss 0.0000e+00 (0.0000e+00)	Acc@1   2.00 (  2.00)	Acc@5   7.50 (  7.50)
[TRAIN] E: [87][100/250]	Loss -3.1590e-06 (-4.3494e-07)	Acc@1   1.00 (  0.94)	Acc@5   4.50 (  4.83)
[TRAIN] E: [87][200/250]	Loss -3.3975e-06 (-4.1071e-07)	Acc@1   1.50 (  1.02)	Acc@5   4.00 (  5.04)
[TRAIN] E: [87][249/250]	Loss -5.9605e-08 (-1.7691e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [87][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [87][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.013560172052616067 -- best acc so far 53.46
***[2023-04-24 16:27:42]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [88][  0/250]	Loss -1.1921e-07 (-1.1921e-07)	Acc@1   0.00 (  0.00)	Acc@5   1.50 (  1.50)
[TRAIN] E: [88][100/250]	Loss 2.9802e-07 (2.9684e-07)	Acc@1   0.00 (  0.92)	Acc@5   2.00 (  4.88)
[TRAIN] E: [88][200/250]	Loss 2.9802e-07 (3.8699e-07)	Acc@1   0.00 (  0.95)	Acc@5   4.50 (  5.00)
[TRAIN] E: [88][249/250]	Loss 2.8610e-06 (-3.3379e-09)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [88][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [88][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.01148234918396563 -- best acc so far 53.46
***[2023-04-24 16:29:16]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [89][  0/250]	Loss 2.6822e-06 (2.6822e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [89][100/250]	Loss 3.0398e-06 (2.1481e-07)	Acc@1   1.50 (  1.01)	Acc@5   5.00 (  4.98)
[TRAIN] E: [89][200/250]	Loss -2.8610e-06 (2.2211e-07)	Acc@1   2.00 (  1.00)	Acc@5  10.00 (  4.99)
[TRAIN] E: [89][249/250]	Loss 7.7486e-07 (7.0477e-07)	Acc@1   0.50 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [89][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [89][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.009556537886045269 -- best acc so far 53.46
***[2023-04-24 16:31:07]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [90][  0/250]	Loss 7.7486e-07 (7.7486e-07)	Acc@1   0.00 (  0.00)	Acc@5   6.50 (  6.50)
[TRAIN] E: [90][100/250]	Loss -3.3379e-06 (-1.3119e-06)	Acc@1   1.00 (  1.04)	Acc@5   3.00 (  4.99)
[TRAIN] E: [90][200/250]	Loss -2.1458e-06 (-7.2771e-07)	Acc@1   1.00 (  1.02)	Acc@5   5.50 (  5.04)
[TRAIN] E: [90][249/250]	Loss 3.0994e-06 (-1.0540e-06)	Acc@1   1.50 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [90][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [90][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.007790338456228391 -- best acc so far 53.46
***[2023-04-24 16:32:57]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [91][  0/250]	Loss 3.0994e-06 (3.0994e-06)	Acc@1   0.50 (  0.50)	Acc@5   7.00 (  7.00)
[TRAIN] E: [91][100/250]	Loss -1.9670e-06 (9.8200e-07)	Acc@1   0.50 (  1.03)	Acc@5   2.50 (  5.03)
[TRAIN] E: [91][200/250]	Loss 2.6226e-06 (6.8234e-07)	Acc@1   1.50 (  1.03)	Acc@5   8.00 (  5.04)
[TRAIN] E: [91][249/250]	Loss 1.1921e-07 (9.5677e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [91][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [91][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.006190721276764732 -- best acc so far 53.46
***[2023-04-24 16:34:47]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [92][  0/250]	Loss 5.9605e-08 (5.9605e-08)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  3.00)
[TRAIN] E: [92][100/250]	Loss -1.9073e-06 (-1.6849e-06)	Acc@1   1.00 (  1.10)	Acc@5   5.50 (  5.11)
[TRAIN] E: [92][200/250]	Loss 2.6226e-06 (8.4218e-08)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  5.01)
[TRAIN] E: [92][249/250]	Loss 3.5763e-07 (1.7142e-07)	Acc@1   1.50 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [92][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [92][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.004763999305866029 -- best acc so far 53.46
***[2023-04-24 16:36:38]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [93][  0/250]	Loss 2.3842e-07 (2.3842e-07)	Acc@1   0.50 (  0.50)	Acc@5   2.50 (  2.50)
[TRAIN] E: [93][100/250]	Loss -3.8743e-06 (-2.0071e-06)	Acc@1   1.50 (  1.05)	Acc@5   8.00 (  5.16)
[TRAIN] E: [93][200/250]	Loss 1.6689e-06 (-1.9601e-07)	Acc@1   0.50 (  0.97)	Acc@5   3.50 (  4.95)
[TRAIN] E: [93][249/250]	Loss 8.9407e-07 (1.3137e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [93][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [93][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.003515803163344189 -- best acc so far 53.46
***[2023-04-24 16:38:31]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [94][  0/250]	Loss 8.3447e-07 (8.3447e-07)	Acc@1   0.00 (  0.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [94][100/250]	Loss -2.0862e-06 (-3.9363e-07)	Acc@1   1.00 (  1.01)	Acc@5   6.00 (  4.90)
[TRAIN] E: [94][200/250]	Loss -3.0398e-06 (-1.5346e-06)	Acc@1   0.00 (  0.99)	Acc@5   6.50 (  4.99)
[TRAIN] E: [94][249/250]	Loss 2.8014e-06 (-1.0715e-06)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [94][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [94][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0024510589091271354 -- best acc so far 53.46
***[2023-04-24 16:40:22]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [95][  0/250]	Loss 2.7418e-06 (2.7418e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [95][100/250]	Loss 1.6093e-06 (2.5099e-06)	Acc@1   0.50 (  0.96)	Acc@5   5.00 (  4.93)
[TRAIN] E: [95][200/250]	Loss 9.5367e-07 (1.6494e-06)	Acc@1   0.00 (  0.98)	Acc@5   2.00 (  4.97)
[TRAIN] E: [95][249/250]	Loss 8.9407e-07 (1.4918e-06)	Acc@1   1.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [95][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [95][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.001573968602350917 -- best acc so far 53.46
***[2023-04-24 16:42:18]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [96][  0/250]	Loss 8.9407e-07 (8.9407e-07)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [96][100/250]	Loss -1.6689e-06 (-8.6279e-07)	Acc@1   2.00 (  1.13)	Acc@5   6.50 (  5.00)
[TRAIN] E: [96][200/250]	Loss -1.6093e-06 (-1.3321e-06)	Acc@1   2.00 (  1.00)	Acc@5   9.50 (  4.98)
[TRAIN] E: [96][249/250]	Loss -1.7881e-06 (-1.3914e-06)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [96][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [96][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.000887993717751917 -- best acc so far 53.46
***[2023-04-24 16:44:11]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [97][  0/250]	Loss -1.7881e-06 (-1.7881e-06)	Acc@1   1.50 (  1.50)	Acc@5   6.50 (  6.50)
[TRAIN] E: [97][100/250]	Loss -3.2783e-06 (-3.2352e-06)	Acc@1   0.50 (  1.05)	Acc@5   4.50 (  4.99)
[TRAIN] E: [97][200/250]	Loss -2.8610e-06 (-3.1878e-06)	Acc@1   0.00 (  1.03)	Acc@5   2.50 (  4.99)
[TRAIN] E: [97][249/250]	Loss -3.1590e-06 (-3.1593e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [97][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [97][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0003958414848075243 -- best acc so far 53.46
***[2023-04-24 16:45:59]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [98][  0/250]	Loss -3.1590e-06 (-3.1590e-06)	Acc@1   1.50 (  1.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [98][100/250]	Loss 3.3379e-06 (3.1827e-06)	Acc@1   1.00 (  1.08)	Acc@5   4.00 (  5.00)
[TRAIN] E: [98][200/250]	Loss 3.3379e-06 (3.2456e-06)	Acc@1   1.00 (  1.02)	Acc@5   4.00 (  4.96)
[TRAIN] E: [98][249/250]	Loss 3.5167e-06 (3.2895e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [98][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [98][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=9.945420353821844e-05 -- best acc so far 53.46
***[2023-04-24 16:47:54]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [99][  0/250]	Loss 3.5167e-06 (3.5167e-06)	Acc@1   0.00 (  0.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [99][100/250]	Loss 3.6955e-06 (3.6678e-06)	Acc@1   1.00 (  0.93)	Acc@5   6.50 (  5.03)
[TRAIN] E: [99][200/250]	Loss 3.8147e-06 (3.7053e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.04)
[TRAIN] E: [99][249/250]	Loss 3.8147e-06 (3.7267e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [99][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [99][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=1.57913669363019e-09 -- best acc so far 53.46
***[2023-04-24 16:50:08]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [100][  0/250]	Loss 3.8147e-06 (3.8147e-06)	Acc@1   0.50 (  0.50)	Acc@5   2.50 (  2.50)
[TRAIN] E: [100][100/250]	Loss -1.6093e-06 (4.0956e-07)	Acc@1   0.00 (  1.02)	Acc@5   1.50 (  5.15)
[TRAIN] E: [100][200/250]	Loss -7.7486e-07 (3.6089e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  4.95)
[TRAIN] E: [100][249/250]	Loss -4.1723e-06 (3.9601e-07)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [100][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [100][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09990212389432412 -- best acc so far 53.46
***[2023-04-24 16:52:24]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [101][  0/250]	Loss -3.8147e-06 (-3.8147e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [101][100/250]	Loss -1.4305e-06 (1.9829e-07)	Acc@1   0.50 (  1.06)	Acc@5   3.50 (  5.22)
[TRAIN] E: [101][200/250]	Loss -1.8477e-06 (2.9061e-07)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  4.99)
[TRAIN] E: [101][249/250]	Loss -1.5497e-06 (4.5848e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [101][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [101][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09960730848288585 -- best acc so far 53.46
***[2023-04-24 16:54:46]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [102][  0/250]	Loss -1.1325e-06 (-1.1325e-06)	Acc@1   3.00 (  3.00)	Acc@5   8.50 (  8.50)
[TRAIN] E: [102][100/250]	Loss 8.9407e-07 (-1.1213e-08)	Acc@1   0.00 (  1.00)	Acc@5   5.00 (  5.02)
[TRAIN] E: [102][200/250]	Loss 2.3246e-06 (1.4234e-07)	Acc@1   1.00 (  1.02)	Acc@5   3.50 (  5.05)
[TRAIN] E: [102][249/250]	Loss -1.6689e-06 (1.9431e-07)	Acc@1   0.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [102][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [102][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0991167156882891 -- best acc so far 53.46
***[2023-04-24 16:57:09]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [103][  0/250]	Loss -1.4901e-06 (-1.4901e-06)	Acc@1   1.50 (  1.50)	Acc@5   8.00 (  8.00)
[TRAIN] E: [103][100/250]	Loss -3.2187e-06 (-8.5571e-08)	Acc@1   0.00 (  1.04)	Acc@5   3.00 (  4.98)
[TRAIN] E: [103][200/250]	Loss -8.3447e-07 (1.7081e-07)	Acc@1   0.50 (  1.06)	Acc@5   8.00 (  4.97)
[TRAIN] E: [103][249/250]	Loss -2.9206e-06 (1.8954e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [103][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [103][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0984322816561636 -- best acc so far 53.46
***[2023-04-24 16:59:31]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [104][  0/250]	Loss 1.4901e-06 (1.4901e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [104][100/250]	Loss 1.3113e-06 (3.3520e-07)	Acc@1   0.50 (  0.98)	Acc@5   3.50 (  5.07)
[TRAIN] E: [104][200/250]	Loss -1.0133e-06 (2.2952e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.01)
[TRAIN] E: [104][249/250]	Loss -1.4305e-06 (2.3866e-07)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [104][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [104][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09755670753494601 -- best acc so far 53.46
***[2023-04-24 17:01:50]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [105][  0/250]	Loss -1.5497e-06 (-1.5497e-06)	Acc@1   2.00 (  2.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [105][100/250]	Loss -1.7881e-06 (7.6070e-07)	Acc@1   2.00 (  1.05)	Acc@5   8.00 (  5.19)
[TRAIN] E: [105][200/250]	Loss 5.9605e-08 (5.9101e-07)	Acc@1   0.50 (  1.04)	Acc@5   4.00 (  5.05)
[TRAIN] E: [105][249/250]	Loss 2.8014e-06 (5.3787e-07)	Acc@1   1.00 (  1.00)	Acc@5   7.50 (  5.00)
[EVAL] E: [105][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [105][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09649344881568099 -- best acc so far 53.46
***[2023-04-24 17:04:10]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [106][  0/250]	Loss 9.5367e-07 (9.5367e-07)	Acc@1   2.00 (  2.00)	Acc@5   8.00 (  8.00)
[TRAIN] E: [106][100/250]	Loss -3.2187e-06 (-3.3638e-08)	Acc@1   1.50 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [106][200/250]	Loss -2.2650e-06 (1.5687e-07)	Acc@1   0.50 (  0.98)	Acc@5   4.50 (  4.97)
[TRAIN] E: [106][249/250]	Loss 8.3447e-07 (3.2496e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [106][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [106][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09524670169477678 -- best acc so far 53.46
***[2023-04-24 17:06:31]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [107][  0/250]	Loss 1.3709e-06 (1.3709e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [107][100/250]	Loss 3.6359e-06 (4.0543e-07)	Acc@1   0.50 (  1.02)	Acc@5   5.00 (  5.16)
[TRAIN] E: [107][200/250]	Loss 3.5167e-06 (2.3160e-07)	Acc@1   1.50 (  1.03)	Acc@5   4.00 (  5.04)
[TRAIN] E: [107][249/250]	Loss 5.3644e-07 (3.5095e-07)	Acc@1   2.50 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [107][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [107][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09382138651353501 -- best acc so far 53.46
***[2023-04-24 17:08:55]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [108][  0/250]	Loss 5.3644e-07 (5.3644e-07)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [108][100/250]	Loss 3.1590e-06 (4.6917e-07)	Acc@1   1.00 (  0.95)	Acc@5   3.50 (  4.95)
[TRAIN] E: [108][200/250]	Loss 1.6689e-06 (4.3295e-07)	Acc@1   1.00 (  0.98)	Acc@5   5.00 (  4.93)
[TRAIN] E: [108][249/250]	Loss -3.0994e-06 (5.1546e-07)	Acc@1   1.00 (  1.00)	Acc@5   7.50 (  5.00)
[EVAL] E: [108][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [108][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09222312833981149 -- best acc so far 53.46
***[2023-04-24 17:11:17]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [109][  0/250]	Loss -2.6226e-06 (-2.6226e-06)	Acc@1   0.00 (  0.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [109][100/250]	Loss -3.5167e-06 (-1.4754e-08)	Acc@1   0.50 (  1.04)	Acc@5   4.50 (  5.15)
[TRAIN] E: [109][200/250]	Loss -3.0398e-06 (4.3176e-07)	Acc@1   0.50 (  0.97)	Acc@5   3.50 (  4.93)
[TRAIN] E: [109][249/250]	Loss 1.3113e-06 (2.6083e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [109][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [109][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.09045823476844317 -- best acc so far 53.46
***[2023-04-24 17:13:39]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [110][  0/250]	Loss 1.2517e-06 (1.2517e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [110][100/250]	Loss 2.8014e-06 (8.2620e-08)	Acc@1   1.00 (  0.93)	Acc@5   7.00 (  4.76)
[TRAIN] E: [110][200/250]	Loss -3.0994e-06 (9.4893e-09)	Acc@1   0.00 (  1.01)	Acc@5   4.50 (  4.99)
[TRAIN] E: [110][249/250]	Loss -4.1127e-06 (-3.0279e-08)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [110][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [110][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08853367102805308 -- best acc so far 53.46
***[2023-04-24 17:16:01]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [111][  0/250]	Loss -3.9339e-06 (-3.9339e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [111][100/250]	Loss 2.2054e-06 (1.1626e-06)	Acc@1   1.00 (  1.08)	Acc@5   5.50 (  5.15)
[TRAIN] E: [111][200/250]	Loss -3.7551e-06 (8.1430e-07)	Acc@1   1.50 (  1.02)	Acc@5   4.50 (  5.02)
[TRAIN] E: [111][249/250]	Loss -1.7881e-07 (5.5933e-07)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [111][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [111][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08645703249247501 -- best acc so far 53.46
***[2023-04-24 17:18:23]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [112][  0/250]	Loss -1.1921e-07 (-1.1921e-07)	Acc@1   1.50 (  1.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [112][100/250]	Loss 2.9206e-06 (-3.2871e-07)	Acc@1   0.50 (  1.12)	Acc@5   4.00 (  5.10)
[TRAIN] E: [112][200/250]	Loss 4.1723e-07 (3.6741e-07)	Acc@1   1.00 (  1.01)	Acc@5   8.50 (  4.98)
[TRAIN] E: [112][249/250]	Loss 4.2319e-06 (3.2830e-07)	Acc@1   2.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [112][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [112][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08423651470528298 -- best acc so far 53.46
***[2023-04-24 17:20:48]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [113][  0/250]	Loss 4.0531e-06 (4.0531e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [113][100/250]	Loss -7.1526e-07 (-3.0865e-07)	Acc@1   2.00 (  0.99)	Acc@5   5.00 (  4.97)
[TRAIN] E: [113][200/250]	Loss 3.9935e-06 (4.9048e-07)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  4.97)
[TRAIN] E: [113][249/250]	Loss -3.8743e-06 (7.4577e-07)	Acc@1   2.00 (  1.00)	Acc@5   7.50 (  5.00)
[EVAL] E: [113][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [113][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.08188088103572495 -- best acc so far 53.46
***[2023-04-24 17:23:08]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [114][  0/250]	Loss -3.6359e-06 (-3.6359e-06)	Acc@1   0.00 (  0.00)	Acc@5   7.00 (  7.00)
[TRAIN] E: [114][100/250]	Loss -6.3777e-06 (-1.6011e-06)	Acc@1   0.50 (  1.02)	Acc@5   2.50 (  5.02)
[TRAIN] E: [114][200/250]	Loss 6.2585e-06 (9.1246e-07)	Acc@1   1.00 (  0.99)	Acc@5   5.00 (  4.90)
[TRAIN] E: [114][249/250]	Loss -3.6955e-06 (7.8034e-07)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [114][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [114][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07939942809370802 -- best acc so far 53.46
***[2023-04-24 17:25:30]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [115][  0/250]	Loss -3.6955e-06 (-3.6955e-06)	Acc@1   0.50 (  0.50)	Acc@5   2.50 (  2.50)
[TRAIN] E: [115][100/250]	Loss 0.0000e+00 (-2.4727e-07)	Acc@1   0.00 (  1.00)	Acc@5   3.00 (  4.91)
[TRAIN] E: [115][200/250]	Loss 2.9802e-06 (1.0963e-06)	Acc@1   1.50 (  0.98)	Acc@5   5.50 (  5.07)
[TRAIN] E: [115][249/250]	Loss 2.1458e-06 (1.2939e-06)	Acc@1   1.50 (  1.00)	Acc@5   2.50 (  5.00)
[EVAL] E: [115][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [115][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.0768019490403263 -- best acc so far 53.46
***[2023-04-24 17:27:56]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [116][  0/250]	Loss 2.2054e-06 (2.2054e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [116][100/250]	Loss 3.5763e-07 (-1.0210e-06)	Acc@1   1.00 (  1.07)	Acc@5   5.50 (  5.25)
[TRAIN] E: [116][200/250]	Loss -3.6955e-06 (6.0198e-08)	Acc@1   1.00 (  1.01)	Acc@5   5.00 (  5.05)
[TRAIN] E: [116][249/250]	Loss 2.7418e-06 (-1.0109e-07)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [116][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [116][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07409869493872821 -- best acc so far 53.46
***[2023-04-24 17:30:23]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [117][  0/250]	Loss 2.7418e-06 (2.7418e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [117][100/250]	Loss 2.8014e-06 (3.4358e-06)	Acc@1   2.50 (  1.11)	Acc@5   5.00 (  5.03)
[TRAIN] E: [117][200/250]	Loss 1.1921e-06 (1.0420e-06)	Acc@1   0.50 (  1.02)	Acc@5   5.00 (  5.02)
[TRAIN] E: [117][249/250]	Loss 2.2054e-06 (1.3697e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [117][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [117][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.07130033429785343 -- best acc so far 53.46
***[2023-04-24 17:32:42]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [118][  0/250]	Loss 2.3246e-06 (2.3246e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [118][100/250]	Loss -1.1921e-07 (-2.1375e-06)	Acc@1   1.00 (  1.06)	Acc@5   4.50 (  5.11)
[TRAIN] E: [118][200/250]	Loss 2.5630e-06 (-3.7453e-07)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.03)
[TRAIN] E: [118][249/250]	Loss 2.6226e-06 (3.2282e-07)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [118][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[EVAL] E: [118][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06841791096870212 -- best acc so far 53.46
***[2023-04-24 17:35:03]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [119][  0/250]	Loss 2.5630e-06 (2.5630e-06)	Acc@1   2.00 (  2.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [119][100/250]	Loss 2.9802e-07 (1.7899e-06)	Acc@1   0.00 (  0.90)	Acc@5   3.50 (  4.92)
[TRAIN] E: [119][200/250]	Loss 3.0994e-06 (-6.5743e-07)	Acc@1   0.50 (  0.95)	Acc@5   5.50 (  4.99)
[TRAIN] E: [119][249/250]	Loss 5.9605e-07 (9.0122e-08)	Acc@1   2.00 (  1.00)	Acc@5   8.50 (  5.01)
[EVAL] E: [119][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [119][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06546280055930047 -- best acc so far 53.46
***[2023-04-24 17:37:23]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [120][  0/250]	Loss 5.9605e-07 (5.9605e-07)	Acc@1   2.00 (  2.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [120][100/250]	Loss 5.3644e-07 (-8.0260e-07)	Acc@1   0.50 (  1.01)	Acc@5   5.50 (  5.18)
[TRAIN] E: [120][200/250]	Loss 2.3842e-06 (6.9005e-07)	Acc@1   1.50 (  1.02)	Acc@5   6.50 (  5.01)
[TRAIN] E: [120][249/250]	Loss 5.3644e-07 (9.9635e-07)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  4.99)
[EVAL] E: [120][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.50 (  6.50)
[EVAL] E: [120][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.06244666554037286 -- best acc so far 53.46
***[2023-04-24 17:39:50]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [121][  0/250]	Loss 4.7684e-07 (4.7684e-07)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [121][100/250]	Loss 4.1127e-06 (1.7875e-06)	Acc@1   1.50 (  1.08)	Acc@5   4.00 (  4.87)
[TRAIN] E: [121][200/250]	Loss 1.9073e-06 (2.2051e-06)	Acc@1   1.00 (  0.96)	Acc@5   2.50 (  4.94)
[TRAIN] E: [121][249/250]	Loss 1.7285e-06 (2.1548e-06)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [121][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.50 (  6.50)
[EVAL] E: [121][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05938140921889801 -- best acc so far 53.46
***[2023-04-24 17:42:13]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [122][  0/250]	Loss 1.6093e-06 (1.6093e-06)	Acc@1   1.00 (  1.00)	Acc@5   7.00 (  7.00)
[TRAIN] E: [122][100/250]	Loss 2.2650e-06 (1.1242e-06)	Acc@1   1.00 (  1.02)	Acc@5   4.00 (  4.99)
[TRAIN] E: [122][200/250]	Loss 2.5034e-06 (1.7881e-06)	Acc@1   0.50 (  1.04)	Acc@5   3.00 (  4.99)
[TRAIN] E: [122][249/250]	Loss -7.6294e-06 (1.0338e-06)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [122][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.50 (  6.50)
[EVAL] E: [122][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05627912876119434 -- best acc so far 53.46
***[2023-04-24 17:44:38]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [123][  0/250]	Loss -7.6294e-06 (-7.6294e-06)	Acc@1   1.50 (  1.50)	Acc@5   8.50 (  8.50)
[TRAIN] E: [123][100/250]	Loss 0.0000e+00 (-1.2759e-06)	Acc@1   1.00 (  0.95)	Acc@5   7.00 (  4.92)
[TRAIN] E: [123][200/250]	Loss -2.5034e-06 (5.4563e-08)	Acc@1   0.00 (  0.98)	Acc@5   3.00 (  4.94)
[TRAIN] E: [123][249/250]	Loss -4.9472e-06 (-1.2877e-06)	Acc@1   2.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [123][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   6.50 (  6.50)
[EVAL] E: [123][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.05315206745093132 -- best acc so far 53.46
***[2023-04-24 17:47:02]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [124][  0/250]	Loss -4.9472e-06 (-4.9472e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [124][100/250]	Loss -8.1062e-06 (3.2163e-07)	Acc@1   2.00 (  0.91)	Acc@5   5.00 (  4.78)
[TRAIN] E: [124][200/250]	Loss 2.3842e-07 (-4.3058e-07)	Acc@1   0.50 (  0.98)	Acc@5   3.00 (  5.00)
[TRAIN] E: [124][249/250]	Loss 2.5034e-06 (2.8133e-08)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.06)
[EVAL] E: [124][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[EVAL] E: [124][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   6.00 (  5.00)
		 LR=0.050012566370482084 -- best acc so far 53.46
***[2023-04-24 17:49:24]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [125][  0/250]	Loss 2.5034e-06 (2.5034e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  3.00)
[TRAIN] E: [125][100/250]	Loss 1.1921e-07 (1.8082e-06)	Acc@1   0.00 (  1.02)	Acc@5   4.00 (  5.01)
[TRAIN] E: [125][200/250]	Loss 5.3644e-07 (-1.4370e-06)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.02)
[TRAIN] E: [125][249/250]	Loss 5.3644e-07 (-1.0448e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  4.94)
[EVAL] E: [125][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [125][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
		 LR=0.0468730156963096 -- best acc so far 53.46
***[2023-04-24 17:51:39]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [126][  0/250]	Loss 5.3644e-07 (5.3644e-07)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [126][100/250]	Loss 1.0729e-06 (1.0546e-06)	Acc@1   1.50 (  1.04)	Acc@5   4.00 (  5.04)
[TRAIN] E: [126][200/250]	Loss 1.9073e-06 (1.3579e-06)	Acc@1   1.50 (  1.03)	Acc@5   5.50 (  4.99)
[TRAIN] E: [126][249/250]	Loss 2.8610e-06 (1.5345e-06)	Acc@1   0.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [126][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   2.00 (  2.00)
[EVAL] E: [126][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.00 (  5.00)
		 LR=0.04374580580060053 -- best acc so far 53.46
***[2023-04-24 17:53:38]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [127][  0/250]	Loss 3.3975e-06 (3.3975e-06)	Acc@1   2.50 (  2.50)	Acc@5   6.50 (  6.50)
[TRAIN] E: [127][100/250]	Loss 2.9802e-06 (2.8474e-06)	Acc@1   3.00 (  0.98)	Acc@5   7.00 (  5.10)
[TRAIN] E: [127][200/250]	Loss 1.5497e-06 (2.3812e-06)	Acc@1   0.50 (  0.97)	Acc@5   5.00 (  4.95)
[TRAIN] E: [127][249/250]	Loss 1.1921e-06 (2.1737e-06)	Acc@1   1.50 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [127][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   2.00 (  2.00)
[EVAL] E: [127][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.00 (  5.00)
		 LR=0.04064327835212697 -- best acc so far 53.46
***[2023-04-24 17:55:39]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [128][  0/250]	Loss 1.3709e-06 (1.3709e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  6.50)
[TRAIN] E: [128][100/250]	Loss 1.6093e-06 (1.4341e-06)	Acc@1   0.50 (  0.99)	Acc@5   3.50 (  4.99)
[TRAIN] E: [128][200/250]	Loss -5.9605e-07 (7.8643e-07)	Acc@1   0.00 (  0.96)	Acc@5   3.50 (  4.88)
[TRAIN] E: [128][249/250]	Loss -1.3113e-06 (4.4870e-07)	Acc@1   3.00 (  1.00)	Acc@5   7.50 (  4.98)
[EVAL] E: [128][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [128][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.037577677609318 -- best acc so far 53.46
***[2023-04-24 17:57:24]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [129][  0/250]	Loss -1.3113e-06 (-1.3113e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [129][100/250]	Loss 3.8743e-06 (1.5214e-06)	Acc@1   1.00 (  0.96)	Acc@5   6.00 (  5.06)
[TRAIN] E: [129][200/250]	Loss -1.3709e-06 (2.0126e-06)	Acc@1   0.50 (  0.98)	Acc@5   3.00 (  5.07)
[TRAIN] E: [129][249/250]	Loss 4.1127e-06 (1.8866e-06)	Acc@1   2.00 (  1.00)	Acc@5   8.00 (  5.00)
[EVAL] E: [129][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [129][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.034561102097765826 -- best acc so far 53.46
***[2023-04-24 17:59:05]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [130][  0/250]	Loss -1.3113e-06 (-1.3113e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [130][100/250]	Loss 2.5630e-06 (1.4329e-06)	Acc@1   0.50 (  1.08)	Acc@5   5.50 (  5.00)
[TRAIN] E: [130][200/250]	Loss 1.3113e-06 (9.5872e-07)	Acc@1   0.50 (  1.05)	Acc@5   2.00 (  5.05)
[TRAIN] E: [130][249/250]	Loss 1.1921e-06 (1.0085e-06)	Acc@1   0.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [130][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [130][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.03160545686287225 -- best acc so far 53.46
***[2023-04-24 18:00:45]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [131][  0/250]	Loss 1.0133e-06 (1.0133e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [131][100/250]	Loss 1.7881e-06 (1.5592e-06)	Acc@1   2.00 (  1.04)	Acc@5   6.50 (  5.01)
[TRAIN] E: [131][200/250]	Loss 3.2783e-06 (1.8403e-06)	Acc@1   1.50 (  1.00)	Acc@5   7.00 (  4.96)
[TRAIN] E: [131][249/250]	Loss 1.6093e-06 (2.0206e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [131][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [131][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.028722406486073528 -- best acc so far 53.46
***[2023-04-24 18:02:25]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [132][  0/250]	Loss 1.6093e-06 (1.6093e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [132][100/250]	Loss 2.6226e-06 (1.6831e-06)	Acc@1   1.00 (  0.97)	Acc@5  10.50 (  5.13)
[TRAIN] E: [132][200/250]	Loss 1.6093e-06 (1.7383e-06)	Acc@1   2.50 (  0.98)	Acc@5   9.50 (  5.00)
[TRAIN] E: [132][249/250]	Loss 1.8477e-06 (1.7560e-06)	Acc@1   0.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [132][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [132][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.02592332905006647 -- best acc so far 53.46
***[2023-04-24 18:04:05]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [133][  0/250]	Loss 1.7285e-06 (1.7285e-06)	Acc@1   1.00 (  1.00)	Acc@5   7.00 (  7.00)
[TRAIN] E: [133][100/250]	Loss 3.7551e-06 (2.1039e-06)	Acc@1   2.00 (  0.99)	Acc@5   8.00 (  4.86)
[TRAIN] E: [133][200/250]	Loss 3.0398e-06 (2.5470e-06)	Acc@1   0.50 (  0.98)	Acc@5   6.00 (  4.92)
[TRAIN] E: [133][249/250]	Loss 2.3246e-06 (2.5752e-06)	Acc@1   0.00 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [133][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [133][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.02321927123471412 -- best acc so far 53.46
***[2023-04-24 18:05:45]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [134][  0/250]	Loss 2.5630e-06 (2.5630e-06)	Acc@1   0.50 (  0.50)	Acc@5   2.50 (  2.50)
[TRAIN] E: [134][100/250]	Loss 2.2054e-06 (2.2018e-06)	Acc@1   1.50 (  1.01)	Acc@5   4.50 (  5.06)
[TRAIN] E: [134][200/250]	Loss 2.4438e-06 (2.2027e-06)	Acc@1   1.00 (  1.03)	Acc@5   6.50 (  5.08)
[TRAIN] E: [134][249/250]	Loss 2.0266e-06 (2.2006e-06)	Acc@1   1.00 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [134][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [134][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.02062090472084719 -- best acc so far 53.46
***[2023-04-24 18:07:25]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [135][  0/250]	Loss 2.3246e-06 (2.3246e-06)	Acc@1   1.00 (  1.00)	Acc@5   2.50 (  2.50)
[TRAIN] E: [135][100/250]	Loss 2.3246e-06 (2.2089e-06)	Acc@1   0.50 (  0.95)	Acc@5   4.50 (  5.02)
[TRAIN] E: [135][200/250]	Loss 2.0266e-06 (2.2012e-06)	Acc@1   0.50 (  0.99)	Acc@5   5.50 (  5.00)
[TRAIN] E: [135][249/250]	Loss 4.4107e-06 (2.2912e-06)	Acc@1   0.50 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [135][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [135][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.018138484074015165 -- best acc so far 53.46
***[2023-04-24 18:09:04]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [136][  0/250]	Loss 4.5300e-06 (4.5300e-06)	Acc@1   0.00 (  0.00)	Acc@5   3.00 (  3.00)
[TRAIN] E: [136][100/250]	Loss 4.6492e-06 (4.6332e-06)	Acc@1   2.00 (  0.98)	Acc@5   7.50 (  4.81)
[TRAIN] E: [136][200/250]	Loss 2.5034e-06 (3.9606e-06)	Acc@1   0.50 (  0.99)	Acc@5   6.00 (  4.92)
[TRAIN] E: [136][249/250]	Loss 2.9206e-06 (3.7415e-06)	Acc@1   1.00 (  1.00)	Acc@5   9.50 (  5.00)
[EVAL] E: [136][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [136][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.015781806274400994 -- best acc so far 53.46
***[2023-04-24 18:10:45]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [137][  0/250]	Loss 3.0994e-06 (3.0994e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [137][100/250]	Loss 1.9073e-06 (2.6202e-06)	Acc@1   0.50 (  0.99)	Acc@5   7.00 (  4.98)
[TRAIN] E: [137][200/250]	Loss 1.9073e-06 (2.2632e-06)	Acc@1   2.00 (  0.96)	Acc@5   5.50 (  4.95)
[TRAIN] E: [137][249/250]	Loss 2.0266e-06 (2.1937e-06)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [137][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [137][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.01356017205261605 -- best acc so far 53.46
***[2023-04-24 18:12:28]*** [Post-train] [Student] EVALUATION loss = 4.605170, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [138][  0/250]	Loss 1.8477e-06 (1.8477e-06)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [138][100/250]	Loss 3.3975e-06 (2.7371e-06)	Acc@1   1.00 (  1.01)	Acc@5   3.00 (  5.06)
[TRAIN] E: [138][200/250]	Loss 3.2187e-06 (2.9696e-06)	Acc@1   0.50 (  0.99)	Acc@5   4.50 (  4.96)
[TRAIN] E: [138][249/250]	Loss 3.0994e-06 (3.0146e-06)	Acc@1   0.50 (  1.00)	Acc@5   7.50 (  5.00)
[EVAL] E: [138][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [138][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.011482349183965603 -- best acc so far 53.46
***[2023-04-24 18:14:09]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [139][  0/250]	Loss 3.0398e-06 (3.0398e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [139][100/250]	Loss 2.5630e-06 (3.0741e-06)	Acc@1   1.50 (  0.95)	Acc@5   7.50 (  5.07)
[TRAIN] E: [139][200/250]	Loss 1.9073e-06 (2.5117e-06)	Acc@1   0.50 (  0.96)	Acc@5   4.00 (  4.97)
[TRAIN] E: [139][249/250]	Loss 1.6093e-06 (2.3682e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [139][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [139][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.009556537886045241 -- best acc so far 53.46
***[2023-04-24 18:15:49]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [140][  0/250]	Loss 1.6689e-06 (1.6689e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [140][100/250]	Loss 1.9073e-06 (1.7799e-06)	Acc@1   1.50 (  0.93)	Acc@5   6.50 (  4.84)
[TRAIN] E: [140][200/250]	Loss 1.7285e-06 (1.7899e-06)	Acc@1   1.00 (  0.99)	Acc@5   9.00 (  4.91)
[TRAIN] E: [140][249/250]	Loss 2.0862e-06 (1.7929e-06)	Acc@1   1.50 (  1.00)	Acc@5   8.00 (  5.00)
[EVAL] E: [140][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [140][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.007790338456228368 -- best acc so far 53.46
***[2023-04-24 18:17:29]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [141][  0/250]	Loss 1.9073e-06 (1.9073e-06)	Acc@1   0.50 (  0.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [141][100/250]	Loss 1.4305e-06 (1.8029e-06)	Acc@1   2.00 (  0.99)	Acc@5   7.00 (  5.17)
[TRAIN] E: [141][200/250]	Loss 2.0266e-06 (1.8039e-06)	Acc@1   1.50 (  1.02)	Acc@5   5.00 (  5.09)
[TRAIN] E: [141][249/250]	Loss 1.7881e-06 (1.8041e-06)	Acc@1   0.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [141][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [141][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.006190721276764699 -- best acc so far 53.46
***[2023-04-24 18:19:07]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [142][  0/250]	Loss 1.8477e-06 (1.8477e-06)	Acc@1   1.50 (  1.50)	Acc@5   8.50 (  8.50)
[TRAIN] E: [142][100/250]	Loss 1.7881e-06 (1.8023e-06)	Acc@1   0.50 (  0.97)	Acc@5   4.00 (  4.95)
[TRAIN] E: [142][200/250]	Loss 1.7285e-06 (1.8050e-06)	Acc@1   2.50 (  1.00)	Acc@5   5.50 (  4.93)
[TRAIN] E: [142][249/250]	Loss 2.0862e-06 (1.8063e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [142][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [142][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.004763999305866018 -- best acc so far 53.46
***[2023-04-24 18:20:49]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [143][  0/250]	Loss 2.2054e-06 (2.2054e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [143][100/250]	Loss 1.6689e-06 (1.8017e-06)	Acc@1   1.50 (  1.06)	Acc@5   7.00 (  5.00)
[TRAIN] E: [143][200/250]	Loss 1.5497e-06 (1.7997e-06)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
[TRAIN] E: [143][249/250]	Loss 1.7285e-06 (1.8001e-06)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [143][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [143][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.003515803163344161 -- best acc so far 53.46
***[2023-04-24 18:22:28]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [144][  0/250]	Loss 1.9073e-06 (1.9073e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  4.00)
[TRAIN] E: [144][100/250]	Loss 1.5497e-06 (1.8058e-06)	Acc@1   0.50 (  1.04)	Acc@5   4.00 (  5.07)
[TRAIN] E: [144][200/250]	Loss 1.6689e-06 (1.8086e-06)	Acc@1   1.00 (  1.02)	Acc@5   5.50 (  5.00)
[TRAIN] E: [144][249/250]	Loss 1.7285e-06 (1.8051e-06)	Acc@1   1.50 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [144][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [144][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.00245105890912713 -- best acc so far 53.46
***[2023-04-24 18:24:10]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [145][  0/250]	Loss 1.9670e-06 (1.9670e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.00 (  3.00)
[TRAIN] E: [145][100/250]	Loss 1.7285e-06 (1.8100e-06)	Acc@1   0.00 (  1.07)	Acc@5   5.00 (  5.04)
[TRAIN] E: [145][200/250]	Loss 1.5497e-06 (1.8068e-06)	Acc@1   1.50 (  0.99)	Acc@5   6.50 (  4.95)
[TRAIN] E: [145][249/250]	Loss 1.7881e-06 (1.8063e-06)	Acc@1   0.50 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [145][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [145][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.001573968602350906 -- best acc so far 53.46
***[2023-04-24 18:25:50]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [146][  0/250]	Loss 1.8477e-06 (1.8477e-06)	Acc@1   1.50 (  1.50)	Acc@5   5.00 (  5.00)
[TRAIN] E: [146][100/250]	Loss 2.0862e-06 (1.8029e-06)	Acc@1   0.50 (  1.06)	Acc@5   6.00 (  5.03)
[TRAIN] E: [146][200/250]	Loss 1.7285e-06 (1.8053e-06)	Acc@1   0.50 (  1.01)	Acc@5   3.00 (  5.05)
[TRAIN] E: [146][249/250]	Loss 1.8477e-06 (1.8041e-06)	Acc@1   1.50 (  1.00)	Acc@5   5.00 (  5.00)
[EVAL] E: [146][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [146][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.000887993717751906 -- best acc so far 53.46
***[2023-04-24 18:27:33]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [147][  0/250]	Loss 1.9670e-06 (1.9670e-06)	Acc@1   1.50 (  1.50)	Acc@5   4.50 (  4.50)
[TRAIN] E: [147][100/250]	Loss 1.6093e-06 (1.7976e-06)	Acc@1   2.00 (  1.08)	Acc@5   4.50 (  5.10)
[TRAIN] E: [147][200/250]	Loss 1.9670e-06 (1.8024e-06)	Acc@1   0.50 (  1.00)	Acc@5   5.00 (  5.07)
[TRAIN] E: [147][249/250]	Loss 2.0266e-06 (1.8044e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [147][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [147][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.0003958414848075243 -- best acc so far 53.46
***[2023-04-24 18:29:13]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [148][  0/250]	Loss 2.0266e-06 (2.0266e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [148][100/250]	Loss 1.4901e-06 (1.7828e-06)	Acc@1   1.00 (  1.03)	Acc@5   7.50 (  5.38)
[TRAIN] E: [148][200/250]	Loss 1.7285e-06 (1.7878e-06)	Acc@1   0.50 (  1.03)	Acc@5   4.00 (  5.03)
[TRAIN] E: [148][249/250]	Loss 1.3709e-06 (1.7858e-06)	Acc@1   1.50 (  1.00)	Acc@5   3.00 (  5.00)
[EVAL] E: [148][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [148][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=9.945420353821844e-05 -- best acc so far 53.46
***[2023-04-24 18:30:52]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [149][  0/250]	Loss 2.1458e-06 (2.1458e-06)	Acc@1   1.50 (  1.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [149][100/250]	Loss 2.7418e-06 (1.9675e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.24)
[TRAIN] E: [149][200/250]	Loss 4.3511e-06 (2.6069e-06)	Acc@1   1.00 (  0.99)	Acc@5   6.00 (  5.07)
[TRAIN] E: [149][249/250]	Loss 4.3511e-06 (2.9488e-06)	Acc@1   2.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [149][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [149][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=1.57913669363019e-09 -- best acc so far 53.46
***[2023-04-24 18:32:38]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [150][  0/250]	Loss 4.3511e-06 (4.3511e-06)	Acc@1   0.00 (  0.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [150][100/250]	Loss 1.3113e-06 (1.6447e-06)	Acc@1   1.00 (  0.94)	Acc@5   2.00 (  5.00)
[TRAIN] E: [150][200/250]	Loss 3.0994e-06 (1.7101e-06)	Acc@1   0.00 (  0.96)	Acc@5   5.00 (  4.99)
[TRAIN] E: [150][249/250]	Loss 1.1325e-06 (1.7209e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [150][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [150][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   3.50 (  5.00)
		 LR=0.09990212389432412 -- best acc so far 53.46
***[2023-04-24 18:34:30]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [151][  0/250]	Loss 1.9670e-06 (1.9670e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [151][100/250]	Loss 1.9073e-06 (1.8153e-06)	Acc@1   1.00 (  1.10)	Acc@5   5.50 (  5.13)
[TRAIN] E: [151][200/250]	Loss 3.1590e-06 (1.8128e-06)	Acc@1   3.50 (  0.99)	Acc@5   5.50 (  4.97)
[TRAIN] E: [151][249/250]	Loss 1.4305e-06 (1.8034e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.03)
[EVAL] E: [151][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [151][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.09960730848288585 -- best acc so far 53.46
***[2023-04-24 18:36:20]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [152][  0/250]	Loss 2.2650e-06 (2.2650e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [152][100/250]	Loss 1.6093e-06 (1.8165e-06)	Acc@1   1.00 (  1.04)	Acc@5   5.00 (  5.04)
[TRAIN] E: [152][200/250]	Loss 1.7285e-06 (1.8139e-06)	Acc@1   3.00 (  0.98)	Acc@5   5.50 (  4.97)
[TRAIN] E: [152][249/250]	Loss 1.4901e-06 (1.8094e-06)	Acc@1   1.50 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [152][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [152][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.09911671568828909 -- best acc so far 53.46
***[2023-04-24 18:38:07]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [153][  0/250]	Loss 1.6689e-06 (1.6689e-06)	Acc@1   0.50 (  0.50)	Acc@5   3.50 (  3.50)
[TRAIN] E: [153][100/250]	Loss 1.6689e-06 (1.8041e-06)	Acc@1   0.00 (  0.96)	Acc@5   4.50 (  5.05)
[TRAIN] E: [153][200/250]	Loss 1.3113e-06 (1.8042e-06)	Acc@1   2.50 (  1.03)	Acc@5   5.50 (  5.08)
[TRAIN] E: [153][249/250]	Loss 1.7285e-06 (1.8029e-06)	Acc@1   2.00 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [153][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [153][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.0984322816561636 -- best acc so far 53.46
***[2023-04-24 18:40:00]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [154][  0/250]	Loss 1.6093e-06 (1.6093e-06)	Acc@1   1.50 (  1.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [154][100/250]	Loss 1.6689e-06 (1.8088e-06)	Acc@1   0.50 (  1.03)	Acc@5   3.00 (  4.90)
[TRAIN] E: [154][200/250]	Loss 1.9670e-06 (1.8077e-06)	Acc@1   0.00 (  0.99)	Acc@5   2.50 (  4.98)
[TRAIN] E: [154][249/250]	Loss 1.9670e-06 (1.8051e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [154][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [154][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.097556707534946 -- best acc so far 53.46
***[2023-04-24 18:41:39]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [155][  0/250]	Loss 1.7881e-06 (1.7881e-06)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [155][100/250]	Loss 2.0862e-06 (1.8141e-06)	Acc@1   1.50 (  1.04)	Acc@5   5.00 (  5.20)
[TRAIN] E: [155][200/250]	Loss 1.8477e-06 (1.8059e-06)	Acc@1   1.00 (  1.02)	Acc@5   6.50 (  5.03)
[TRAIN] E: [155][249/250]	Loss 1.8477e-06 (1.8044e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [155][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [155][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.09649344881568098 -- best acc so far 53.46
***[2023-04-24 18:43:25]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [156][  0/250]	Loss 1.7285e-06 (1.7285e-06)	Acc@1   1.00 (  1.00)	Acc@5   4.50 (  4.50)
[TRAIN] E: [156][100/250]	Loss 2.0266e-06 (1.8094e-06)	Acc@1   0.50 (  1.00)	Acc@5   8.00 (  4.97)
[TRAIN] E: [156][200/250]	Loss 1.6093e-06 (1.8042e-06)	Acc@1   0.00 (  1.00)	Acc@5   4.00 (  4.95)
[TRAIN] E: [156][249/250]	Loss 1.7285e-06 (1.8027e-06)	Acc@1   2.00 (  1.00)	Acc@5   4.50 (  5.00)
[EVAL] E: [156][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [156][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.09524670169477677 -- best acc so far 53.46
***[2023-04-24 18:45:03]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [157][  0/250]	Loss 1.7881e-06 (1.7881e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.50)
[TRAIN] E: [157][100/250]	Loss 1.7881e-06 (1.8041e-06)	Acc@1   1.00 (  0.96)	Acc@5   6.50 (  4.98)
[TRAIN] E: [157][200/250]	Loss 1.6093e-06 (1.8053e-06)	Acc@1   0.50 (  1.01)	Acc@5   3.00 (  5.02)
[TRAIN] E: [157][249/250]	Loss 1.9670e-06 (1.8051e-06)	Acc@1   1.50 (  1.00)	Acc@5   7.00 (  5.00)
[EVAL] E: [157][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [157][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.093821386513535 -- best acc so far 53.46
***[2023-04-24 18:46:54]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [158][  0/250]	Loss 1.9670e-06 (1.9670e-06)	Acc@1   0.50 (  0.50)	Acc@5   6.00 (  6.00)
[TRAIN] E: [158][100/250]	Loss 1.4901e-06 (1.8035e-06)	Acc@1   0.00 (  1.04)	Acc@5   3.50 (  5.18)
[TRAIN] E: [158][200/250]	Loss 1.5497e-06 (1.8044e-06)	Acc@1   1.50 (  1.00)	Acc@5   6.50 (  4.93)
[TRAIN] E: [158][249/250]	Loss 1.7881e-06 (1.8027e-06)	Acc@1   1.50 (  1.00)	Acc@5   6.00 (  5.00)
[EVAL] E: [158][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [158][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.09222312833981146 -- best acc so far 53.46
***[2023-04-24 18:48:41]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [159][  0/250]	Loss 2.1458e-06 (2.1458e-06)	Acc@1   1.00 (  1.00)	Acc@5   7.50 (  7.50)
[TRAIN] E: [159][100/250]	Loss 1.9670e-06 (1.8094e-06)	Acc@1   1.50 (  1.03)	Acc@5   6.50 (  4.91)
[TRAIN] E: [159][200/250]	Loss 1.6689e-06 (1.8062e-06)	Acc@1   0.50 (  0.97)	Acc@5   5.50 (  4.90)
[TRAIN] E: [159][249/250]	Loss 1.4901e-06 (1.8053e-06)	Acc@1   2.50 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [159][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [159][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.09045823476844314 -- best acc so far 53.46
***[2023-04-24 18:50:25]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [160][  0/250]	Loss 1.3709e-06 (1.3709e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.00 (  5.00)
[TRAIN] E: [160][100/250]	Loss 1.7285e-06 (1.8076e-06)	Acc@1   1.50 (  1.05)	Acc@5   5.00 (  4.95)
[TRAIN] E: [160][200/250]	Loss 2.0266e-06 (1.8053e-06)	Acc@1   1.00 (  1.01)	Acc@5   6.00 (  4.97)
[TRAIN] E: [160][249/250]	Loss 1.6093e-06 (1.8022e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [160][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [160][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.08853367102805305 -- best acc so far 53.46
***[2023-04-24 18:52:16]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [161][  0/250]	Loss 1.7881e-06 (1.7881e-06)	Acc@1   0.50 (  0.50)	Acc@5   4.00 (  4.00)
[TRAIN] E: [161][100/250]	Loss 1.9073e-06 (1.8094e-06)	Acc@1   1.00 (  1.03)	Acc@5   5.00 (  5.00)
[TRAIN] E: [161][200/250]	Loss 1.4305e-06 (1.8062e-06)	Acc@1   0.00 (  1.04)	Acc@5   5.00 (  5.03)
[TRAIN] E: [161][249/250]	Loss 1.4901e-06 (1.8055e-06)	Acc@1   1.00 (  1.00)	Acc@5   5.50 (  5.00)
[EVAL] E: [161][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [161][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.08645703249247498 -- best acc so far 53.46
***[2023-04-24 18:53:59]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [162][  0/250]	Loss 1.4901e-06 (1.4901e-06)	Acc@1   2.50 (  2.50)	Acc@5  10.00 ( 10.00)
[TRAIN] E: [162][100/250]	Loss 1.9073e-06 (1.8088e-06)	Acc@1   0.50 (  0.97)	Acc@5   7.00 (  4.97)
[TRAIN] E: [162][200/250]	Loss 1.9670e-06 (1.8042e-06)	Acc@1   0.50 (  0.96)	Acc@5   6.50 (  4.96)
[TRAIN] E: [162][249/250]	Loss 1.7881e-06 (1.8024e-06)	Acc@1   0.50 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [162][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [162][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.08423651470528294 -- best acc so far 53.46
***[2023-04-24 18:55:49]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [163][  0/250]	Loss 1.7285e-06 (1.7285e-06)	Acc@1   1.00 (  1.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [163][100/250]	Loss 1.6093e-06 (1.8088e-06)	Acc@1   1.00 (  1.12)	Acc@5   6.00 (  5.11)
[TRAIN] E: [163][200/250]	Loss 1.5497e-06 (1.8065e-06)	Acc@1   1.50 (  1.04)	Acc@5   5.50 (  5.05)
[TRAIN] E: [163][249/250]	Loss 1.7285e-06 (1.8053e-06)	Acc@1   2.00 (  1.00)	Acc@5   8.00 (  5.00)
[EVAL] E: [163][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [163][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.08188088103572491 -- best acc so far 53.46
***[2023-04-24 18:57:38]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [164][  0/250]	Loss 1.7285e-06 (1.7285e-06)	Acc@1   3.00 (  3.00)	Acc@5   6.00 (  6.00)
[TRAIN] E: [164][100/250]	Loss 1.6093e-06 (1.8076e-06)	Acc@1   2.00 (  1.02)	Acc@5   5.50 (  5.05)
[TRAIN] E: [164][200/250]	Loss 1.5497e-06 (1.8065e-06)	Acc@1   1.50 (  1.01)	Acc@5   4.50 (  5.06)
[TRAIN] E: [164][249/250]	Loss 1.7881e-06 (1.8041e-06)	Acc@1   0.00 (  1.00)	Acc@5   6.50 (  5.00)
[EVAL] E: [164][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [164][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.07939942809370798 -- best acc so far 53.46
***[2023-04-24 18:59:27]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [165][  0/250]	Loss 1.5497e-06 (1.5497e-06)	Acc@1   1.00 (  1.00)	Acc@5   3.50 (  3.50)
[TRAIN] E: [165][100/250]	Loss 1.8477e-06 (1.8058e-06)	Acc@1   1.00 (  0.97)	Acc@5   3.50 (  4.87)
[TRAIN] E: [165][200/250]	Loss 1.3709e-06 (1.8047e-06)	Acc@1   0.50 (  1.02)	Acc@5   2.00 (  5.05)
[TRAIN] E: [165][249/250]	Loss 1.8477e-06 (1.8024e-06)	Acc@1   0.00 (  1.00)	Acc@5   3.50 (  5.00)
[EVAL] E: [165][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [165][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.07680194904032628 -- best acc so far 53.46
***[2023-04-24 19:01:14]*** [Post-train] [Student] EVALUATION loss = 4.605171, accuracy@1 = 1.00, accuracy@5 = 5.00, error@1 = 99.00, error@5 = 95.00
[TRAIN] E: [166][  0/250]	Loss 2.2054e-06 (2.2054e-06)	Acc@1   1.50 (  1.50)	Acc@5   5.50 (  5.50)
[TRAIN] E: [166][100/250]	Loss 1.9073e-06 (1.8129e-06)	Acc@1   0.50 (  0.98)	Acc@5   5.50 (  4.96)
[TRAIN] E: [166][200/250]	Loss 1.4901e-06 (1.8071e-06)	Acc@1   2.00 (  0.98)	Acc@5   4.50 (  4.94)
[TRAIN] E: [166][249/250]	Loss 1.5497e-06 (1.8046e-06)	Acc@1   0.00 (  1.00)	Acc@5   4.00 (  5.00)
[EVAL] E: [166][ 0/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  0.50)	Acc@5   3.00 (  3.00)
[EVAL] E: [166][49/50]	Loss 4.6052e+00 (4.6052e+00)	Acc@1   0.50 (  1.00)	Acc@5   4.50 (  5.00)
		 LR=0.07409869493872817 -- best acc so far 53.46
