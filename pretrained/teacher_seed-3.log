Main Function with logger : Logger(dir=pretrained, use-tf=False, writer=None)
Arguments : -------------------------------
batch_size       : 800
cutout_length    : 16
data_path        : /home/prathamesh/code/data/cifar/
dataset          : cifar100
epochs           : 200
eval_batch_size  : 800
file_name        : teacher_seed-3
global_rand_seed : -1
lr               : 0.1
model_name       : ResNet10_l
momentum         : 0.9
print_freq       : 100
print_freq_eval  : 100
rand_seed        : 3
save_dir         : ./pretrained
sched_cycles     : 4
wd               : 0.0005
workers          : 8
Python  Version  : 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0]
Pillow  Version  : 9.2.0
PyTorch Version  : 1.13.1
cuDNN   Version  : 8500
CUDA available   : True
CUDA GPU numbers : 1
CUDA_VISIBLE_DEVICES : 0
Namespace(batch_size=800, class_num=100, cutout_length=16, data_path='/home/prathamesh/code/data/cifar/', dataset='cifar100', epochs=200, eval_batch_size=800, file_name='teacher_seed-3', global_rand_seed=-1, lr=0.1, model_name='ResNet10_l', momentum=0.9, print_freq=100, print_freq_eval=100, rand_seed=3, save_dir='./pretrained', sched_cycles=4, wd=0.0005, workers=8)
Train:45000	, Valid:5000	, Test:10000

--------------------------------------------------
Model: ResNet10_l
Scheduling LR update model 4 time at 50-epoch intervals
model information : EfficientNetV2_s (CIFAR)
--------------------------------------------------
[Model] Params=1.19 MB, FLOPs=63.82 M ... = 0.06 G

Started EPOCH:0
[TRAIN] E: [0][ 0/57]	Loss 4.6734e+00 (4.6734e+00)	Acc@1   1.00 (  1.00)	Acc@5   3.75 (  3.75)
[TRAIN] E: [0][56/57]	Loss 4.2187e+00 (4.3631e+00)	Acc@1   7.50 (  4.30)	Acc@5  21.00 ( 16.09)
